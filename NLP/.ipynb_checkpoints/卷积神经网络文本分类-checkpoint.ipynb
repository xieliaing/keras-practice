{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分类与打标签\n",
    "\n",
    "本章内容\n",
    "\n",
    "1. 本章内容概述\n",
    "2. 基于卷积神经网络的文本分类模型详解\n",
    "3. 基于RNN/LSTM的文本分类模型详解\n",
    "4. 构建卷积神经网络完成影评褒贬分类\n",
    "5. 构建LSTM模型完成新闻文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本章内容概述\n",
    "\n",
    "文本分类是一个常见的人工智能任务。通常我们需要对"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于卷积神经网络的文本分类模型\n",
    "\n",
    "在这一节里，我们将介绍如何使用卷积神经网络（CNN）模型进行文本分类。\n",
    "\n",
    "- 我们会首先介绍卷积神经网络的原理及相关的概念，比如池化等。\n",
    "- 其次我们介绍一维卷积网络在文字上的应用。\n",
    "- 随后，通过与图像数据的对比引入如何将二维卷积神经网络方法运用到文本信息建模中。\n",
    "- 最后，我们将拓展单通道二维卷积神经网络到多通道卷积神经网络模型。\n",
    "\n",
    "### 什么是卷积神经网络\n",
    "卷积神经网络模型是利用卷积滤子对输入数据进行分析的技术。在数学里，卷积一词的含义是指通过两个函数f和g生成第三个函数h的操作，产出函数f经过函数g变换后的形态。通常函数g会对原始函数进行平移或者翻转操作。卷积既指代这个操作，也指代这个操作的结果函数。卷积还可以被看作是“加权移动平均”的推广。 我们利用下面这个wiki的图来演示卷积操作。\n",
    "<img src=\"./pics/Convolution3.png\" width=\"450\">\n",
    "这个图中有五行图片。\n",
    "- 第一行的两幅图分别是原始函数f(t)和g(t)。假设两个函数都用 ${\\tau }$ 来表示，从而得到f( $\\tau$ )和g( $ \\tau$ )。\n",
    "- 第二行的图片希纳是将函数g($\\tau$)向右移动t个单位并翻转后得到函数g( $\\tau -t$)的图像。将g( $\\tau -t$)翻转至纵轴另一侧，得到g(-($\\tau$  -t))即g(t- $\\tau$ )的图像。\n",
    "- 第三行的图片显示了当时间变量$\\tau$取不同值时，函数g(t-$\\tau$ ) 沿着时间轴$\\tau$“滑动”的动作。\n",
    "- 第四行的图片显示了当f(t)和g(t)两函数交会时,两函数乘积的积分值。这个积分值可以理解为使用g(t-$\\tau$)做为加权函数，来对f($\\tau$)取加权值的结果。\n",
    "- 第五行的图片显示了这个加权平均的持续过程。\n",
    "\n",
    "最后得到的加权平均的结果就是f和g的卷积。如果f（t）是一个单位脉冲，我们得到的乘积就是g（t）本身，称为冲激响应。\n",
    "\n",
    "<img src=\"./pics/Convolution_self.gif\" width=\"450\">\n",
    "以上来自wiki的图显示了两个方形脉冲波的卷积。其中\n",
    "函数\"g\"首先对 $\\tau =0$反射，接着平移\"t\"，成为 $ g(t-\\tau )$。那么重叠部分的面积就相当于\"t\"处的卷积，其中横坐标代表待变量 $ \\tau $以及新函数 $ f\\ast g$的自变量\"t\"。\n",
    "\n",
    "<img src=\"./pics/Convolution_spiky.gif\" width=\"450\">\n",
    "以上来自wiki的图显示了方形脉冲波和指数衰退的脉冲波的卷积，同样地重叠部分面积就相当于\"t\"处的卷积。注意到因为\"g\"是对称的，所以在这两张图中，反射并不会改变它的形状。\n",
    "\n",
    "以上是对一维卷积的解释。卷积神经网络最常见于图像识别中，因此通常是使用二维卷积。下面简要说明（图片来源：http:www.wildml.com）。\n",
    "<img src=\"./pics/CNNconcept.png\" width=\"500\">\n",
    "\n",
    "二维卷积网络通常使用在与图像相关的建模工作中。在一个二维卷积网络里面，滤子是一个小的矩阵，比如一个$2\\times 2$或者$3 \\times 3$的矩阵。这个小的滤子对于输入的代表图像的矩阵的相应局部进行元素级别的乘积与求和，输出的矩阵即是二维卷积的结果。我们使用下图来解释。\n",
    "\n",
    "<img src=\"./pics/Convolution_operation.png\" width=\"500\">\n",
    "\n",
    "在上图中，左边较大的矩阵是原始输入图像的矩阵，中间蓝色边框的小矩阵代表滤子。在这个例子中，左边矩阵红框的局部与蓝色边框的滤子进行对应位置的元素级别的乘积操作：\n",
    "$$\n",
    "1 \\times 1 + 0 \\times 0 + 0 \\times 1  + 1\\times 0 + 1\\times 1 + 0\\times 0 + 1\\times 1 + 1\\times 0 + 1\\times 1 = 4\n",
    "$$\n",
    "得到右边矩阵绿色框内的数据。\n",
    "\n",
    "与上面提到的一维空间的例子类似，滤子会在原始矩阵内按照一定规律移动，每移动到一个新的位置就与该位置的相应元素进行类似的操作，得到卷积后的结果。过滤器以多大的跨度上下或左右平移地扫描移动的规律叫做“步长”（Stride）。在上例中，步长为1，即每完成一次卷积的操作后，滤子往右或者往下移动一个格子的距离，再进行卷积操作，直到移动到边界为止。当然，步长也可以为别的数字。卷积可以有效降低输入数据的维度，在保留核心信息的时候突出特定特征。\n",
    "\n",
    "我们看到，一个滤子通过数值的排列，可以突出某种特定数据模式，从而帮助模型寻找所需要的特征。以下面的例子为例。左边的图展示了一个曲线特征。这个特征可以对应于各类图片的外凸曲线，比如车轮的一部分轮廓，数字0的一部分，等等，本身是一个抽象的特征。右边的图是对应于该特征的滤子矩阵，中间的图是输入的图。当滤子掠过这幅图片的区域，卷积计算会得到一个很大的数值输出，从而凸显图片里具备这个曲线轮廓特征。\n",
    "<img src=\"./pics/CNNcurve.png\" width=\"500\">\n",
    "\n",
    "滤子在图像领域应用历史悠久，有很多经典的滤子，通过不同的数值组合，可以产生不同的过滤效果。下图展示了三种典型的图像处理领域的滤子。\n",
    "<img src=\"./pics/Convolution_filters.png\" width=\"500\">\n",
    "\n",
    "在卷积神经网络模型中，滤子不是预先定义好的，而是作为参数在模型训练中优化得到的，因此相比预先定义好的滤子，卷积神经网络模型能够抓取更有效的图像特征。这些特征通常反映了抽象的概念，比如一个物体的边界，或者两个物体之间的距离，等。通过叠加卷积层，可以实现不停抽象的过程。比如在人脸侦测的任务中，第一层卷积神经网络可以将人脸的边界抽象出来，而第二层卷积神经网络可以将人眼之间的距离抽象出来，从而实现层级的特征抽象。这点非常类似于人脑的工作原理。\n",
    "\n",
    "除了卷积滤子和步长之外，卷积神经网络里面还有一个概念叫“池化”（Pooling）。池化层将给定的特征图像中的几个空间上相邻的数据通过特定的函数输出，能显著降低模型参数的数量。池化有时也被称为subsampling或者downsampling。池化能在降低参数数量的同时尽可能地保留重要信息。池化对应的函数通常有三种：\n",
    "\n",
    "- 最大 ：MaxPooling，取相邻格子中最大的值\n",
    "- 平均 ：Average Pooling，取相邻格子中所有值的平均值\n",
    "- 求和 ： Sum Pooling，取相邻格子中所有制的总和\n",
    "\n",
    "下图显示了采用最大池化方法的结果，因为采用了$2\\times 2$矩阵，步长为2的池化过程，因此池化后的结果为$2\\times 2$的矩阵，保留了每个区域最大的数值。\n",
    "<img src=\"./pics/MaxPooling2.png\" width=\"500\">\n",
    "\n",
    "\n",
    "对于经由过滤器局部扫描后的卷积层图像，由于处理边界不同，一般有两种方式，对应于“补齐”（padding）这个概念。补齐有两种方法，一种方法是在局部扫描过程中对图像边界以外的一层或多层填上0，平移的时候可以移出边界外到达0的区域。这样的好处是在以1 为步长的局部扫描完以后，所得的新图像和原图像长宽一致，被称作zero padding(same padding)。另一种是不对边界外做任何0 的假定，所有平移都在边界内，被称作valid padding，使用这种方式通常扫描完的图像尺寸会比原来的小。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们先展示手工滤子的效果\n",
    "\n",
    "这里我们先用Python读入一个图片，再指定一个滤子，将该滤子运行于图片上，并输出结果。这里我们展示如何在keras中方便地进行这个操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten\n",
    "import keras.backend as K\n",
    "import scipy, imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from IPython.display import SVG, display\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize']=(15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'D:\\git\\keras-practice\\NLP\\pics\\wranglerJK2.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b3d4a835f54e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#  这时我曾经拥有的牧马人\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./pics/wranglerJK2.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#img_data = imageio.imread('./pics/fighters.jpeg')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'D:\\git\\keras-practice\\NLP\\pics\\wranglerJK2.jpg'"
     ]
    }
   ],
   "source": [
    "# 首先将图片读入为矩阵\n",
    "# 我们可以用pyplot的imshow()方法来展示图片\n",
    "#  这时我曾经拥有的牧马人\n",
    "#\n",
    "img_data = imageio.imread('./pics/wranglerJK2.jpg')\n",
    "#img_data = imageio.imread('./pics/fighters.jpeg')\n",
    "print(img_data.data.shape)\n",
    "\n",
    "img = Image.fromarray(img_data, 'RGB')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape, dtype=None):\n",
    "    new_mat = np.zeros((shape[0], shape[1], 3, 3))\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            if j==shape[0]:\n",
    "                new_mat[:, :, i, j]=0\n",
    "            else:\n",
    "                new_mat[:, :, i, j] = filter_mat\n",
    "    return np.array(new_mat, dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "def MyFilter(image_data):\n",
    "    img_data = image_data\n",
    "    print(len(filter_mat.shape))\n",
    "    if len(filter_mat.shape)!=2:\n",
    "        print('Invalid filter matrix. It must be 2-D')\n",
    "        return []\n",
    "    else:\n",
    "        kernel_size=filter_mat.shape\n",
    "        row, col, depth = img_data.shape\n",
    "        input_shape=img_data.shape\n",
    "        filter_size = row*col*depth\n",
    "        print(filter_size)\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(depth, \n",
    "                         kernel_size=kernel_size, \n",
    "                         input_shape=input_shape, \n",
    "                         strides=1,\n",
    "                         padding='same', \n",
    "                         activation='linear', \n",
    "                         data_format='channels_last',\n",
    "                         kernel_initializer=my_init,\n",
    "                         name='Conv')                         \n",
    "                  )\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(optimizer='sgd', loss='mse')\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        inX = model.input                                          \n",
    "        outputs = [layer.output for layer in model.layers \n",
    "                   if layer.name=='Conv']     \n",
    "        functions = [K.function([inX], [out]) for out in outputs]   \n",
    "        layer_outs = [func([img_data.reshape(1, row, col, depth)]) \n",
    "                      for func in functions]\n",
    "        activationLayer = layer_outs[0][0]\n",
    "        \n",
    "        temp = (activationLayer-np.min(activationLayer))\n",
    "        normalized_activationLayer = temp/np.max( np.max(temp))\n",
    "        \n",
    "        filter_out = model.layers[0].get_weights()[0]\n",
    "        return normalized_activationLayer.reshape(row, col, depth), filter_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -2 -1]\n",
      " [ 0  0  0]\n",
      " [ 1  2  1]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MyFilter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a42627bcc183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfilter_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msober_mat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0moutLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutFilter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyFilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#print(outFilter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MyFilter' is not defined"
     ]
    }
   ],
   "source": [
    "blur_mat = np.array([1, 1, 1, 1, 1, 1, 1,  1, 1]).reshape(3, 3)/9\n",
    "edge_mat = np.array([-1, -1, -1, -1, 8, -1, -1, -1, -1]).reshape(3, 3)\n",
    "gaussian_mat = np.array([1, 2, 1, 2, 4, 2, 1, 2, 1]).reshape(3, 3)\n",
    "sober_mat = np.array([-1, -2, -1, 0, 0, 0, 1, 2, 1]).reshape(3, 3)\n",
    "sober_matX = sober_mat.T\n",
    "sharpen_mat = np.array([0, -1, 0, -1, 5, -1, 0, -1, 0]).reshape(3, 3)\n",
    "filter_mat=sober_mat\n",
    "print(filter_mat)\n",
    "outLayer, outFilter = MyFilter(img_data)\n",
    "#print(outFilter)\n",
    "plt.imshow(outLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 960, 3)\n",
      "====================\n",
      "[[181 199 196 ... 194 194 176]\n",
      " [123 123 123 ... 126 125 125]\n",
      " [123 123 123 ... 127 126 125]\n",
      " ...\n",
      " [124 124 124 ... 128 126 125]\n",
      " [124 124 124 ... 127 123 122]\n",
      " [ 40  12  12 ...  48  45  62]]\n",
      "====================\n",
      "[[181 199 196 ... 194 194 176]\n",
      " [123 123 123 ... 126 125 125]\n",
      " [123 123 123 ... 127 126 125]\n",
      " ...\n",
      " [124 124 124 ... 128 126 125]\n",
      " [124 124 124 ... 127 123 122]\n",
      " [ 40  12  12 ...  48  45  62]]\n"
     ]
    }
   ],
   "source": [
    "print(outLayer.shape)\n",
    "#print(img_data)\n",
    "img2=np.array(outLayer*255, dtype=np.int)\n",
    "print(\"====================\")\n",
    "print(img2[:, :, 0])\n",
    "print(\"====================\")\n",
    "print(img2[:, :, 2])\n",
    "#plt.imshow(np.array(outLayer*255, dtype=np.int)[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00\n",
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "input_data0 = np.array([1,2,3,4,5,6,7,8,9,10,11,12]) \n",
    "input_data = input_data0.reshape(1, 4, 3)\n",
    "target_data = input_data0.reshape(1,12)\n",
    "input_shape=input_data.shape\n",
    "\n",
    "def build_model(input_data, padding_type='same'):\n",
    "    input_shape = input_data.shape\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape[1:]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    return(model)\n",
    "\n",
    "model = build_model(input_data)\n",
    "print(model.summary())\n",
    "model.fit(input_data, target_data, batch_size=1)\n",
    "y = model.predict(input_data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用一维卷积神经网络进行文本分类模型\n",
    "\n",
    "我们从前面了解到，卷积神经网络具备优异的特征萃取能力，但是通常用在图像数据的建模中，如何用在文本数据中呢？下面我们就来解开谜底。\n",
    "\n",
    "在实际使用中，一句话都是以单词索引下标表示的列表，长短不一，因此先要对其进行补齐，将每一句话补齐为同样长度，才方便使用。这时可以选择的补齐长度不一，既可以选择最大的句子长度作为需要补齐的长度，也可以选择所有句子长度的中位值来补齐。\n",
    "\n",
    "把句子补齐之后，每一句话就称为一个整数的时间序列，是一串连续的信号。在使用卷积层的时机上，可以有两种选择。一是直接在这个时候使用，将卷积操作应用于连续的单词下标列表，直接抽取特征；二是先将补齐后的每一句话通过嵌入层映射到一个稍微低维度的致密空间，再对该致密空间的连续信号使用卷积算子，抽取特征。第一种方法因为单词的下标顺序并无特定含义，因此效果不一定好。\n",
    "\n",
    "在keras中，我们可以使用Embedding层来引入嵌入层，通常直接用在输入层后。我们使用Conv1D来引入一维卷积层。我们甚至可以对信号进行多次卷积。下面分别介绍这两者用法。\n",
    "\n",
    "\n",
    "\n",
    "Embedding层的作用是将输入的代表文字的单词索引下标转化为固定长度向量，只能用作除开输入层之后的第一层。比如输入的一句话以其单词对应的索引下标表示为一个整数列表：[3， 9， 11， 478， 3， 2]，Embedding层经过计算可能将其转化为[0.45， 1.98， 2.11， 0.04， 0.31]的形式，其中这个向量的大小（5个元素）是作为一个参数输入模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们使用上一节使用过的对酒店的褒贬评价作为样例展示实际操作。作为展示，我们这个模型较为简单，结构上是一个嵌入层接上一个一维卷积后再由一个全连接层输出褒贬概率。更为复杂的模型可以在卷积层方面进行复杂化，比如嵌套多个卷积层等。下图展示了一个简单的一维卷积神经网络模型的建模流程：\n",
    "\n",
    "<img src=\"./pics/text_CNN_1D.png\" width=700>\n",
    "\n",
    "在数据处理上，我们将把停止词从训练用文本中剔除，主要体现在用于建模的单词下标不包含那些未被纳入的单词集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', '商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', '早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。']\n"
     ]
    }
   ],
   "source": [
    "def load_hotel_data():\n",
    "    documents2 = []\n",
    "    stopword = []\n",
    "    label = []\n",
    "    datafile_pos = './nlp_data/hotel_reviews_data/1000_pos.txt'\n",
    "    datafile_neg = './nlp_data/hotel_reviews_data/1000_neg.txt'\n",
    "    stopwordfile = './nlp_data/hotel_reviews_data/stopWord.txt'\n",
    "\n",
    "    # 先读入停止词    \n",
    "    with open(stopwordfile, encoding='UTF-8') as fo:\n",
    "        for line in fo:\n",
    "            stopword.append(line.strip('\\n'))\n",
    "\n",
    "    # 再读入原始评论文档\n",
    "    with open(datafile_pos, encoding='UTF-8') as fo:\n",
    "        for line in fo:\n",
    "            documents2.append(line.strip('\\n'))\n",
    "            label.append(1)\n",
    "\n",
    "    with open(datafile_neg, encoding='UTF-8') as fo:\n",
    "        for line in fo:\n",
    "            documents2.append(line.strip('\\n'))    \n",
    "            label.append(0)\n",
    "            \n",
    "    return documents2, label, stopword\n",
    "\n",
    "documents2, label, stopwords = load_hotel_data();\n",
    "print(documents2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['：', '；', '？', '人民', '末##末', '啊', '阿', '哎', '哎呀', '哎哟']\n",
      "” 《 》 ！ ， ： ； ？ 人民 末##末 啊 阿 哎 哎呀 哎哟 唉 俺 \n",
      "['：', '；', '？', '人民', '末##末', '啊', '阿', '哎', '哎呀', '哎哟']\n"
     ]
    }
   ],
   "source": [
    "stopwords_lst = stopwords; print(stopwords_lst[10:20])\n",
    "stopwords_str = ' '.join(stopwords); print(stopwords_str[10:50])\n",
    "stopwords_lst2 = stopwords_str.split(' '); print(stopwords_lst2[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要先将停止词从文本中删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from keras.preprocessing import sequence\n",
    "import cntext \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.7 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "max_words = 3000\n",
    "stopwords_str = ' '.join(stopwords)\n",
    "tokenizer = cntext.cnTokenizer(num_words=max_words, \n",
    "                               filters=stopwords_str, \n",
    "                               char_level=False)\n",
    "tokenizer.fit_on_cntexts(documents2)\n",
    "text_sequences=tokenizer.cntexts_to_sequences(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', ? 、 。 “ ” 《 》 ！ ， '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_str[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。\n",
      "早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。\n",
      "['早餐', '太', '无论', '多少', '那边', '不加', '食品', '酒店', '应该', '重视', '一下', '这个', '问题']\n"
     ]
    }
   ],
   "source": [
    "text=documents2[2]\n",
    "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "filters2 = filters + stopwords_str\n",
    "filters2_lst = ' '.join(filters2)\n",
    "translate_dict = dict((c, ' ') for c in filters)\n",
    "translate_map = str.maketrans(translate_dict)\n",
    "text = text.translate(translate_map)\n",
    "words = jieba.lcut(text.strip())\n",
    "words_filtered = [w for w in words if w not in filters2_lst]\n",
    "print(documents2[2])\n",
    "print(text)\n",
    "print(words_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计单词数：8929\n",
      "最大建模用索引下标:2999 \n",
      "\n",
      "    counts  index\n",
      "酒店    1840      1\n",
      "房间    1398      2\n",
      "住      675      3\n",
      "服务     646      4\n",
      "不错     589      5\n",
      "没有     545      6\n",
      "入住     499      7\n",
      "比较     422      8\n",
      "可以     397      9\n",
      "感觉     376     10\n"
     ]
    }
   ],
   "source": [
    "index_word_df = pd.DataFrame.from_dict(tokenizer.index_word, \n",
    "                                       orient='index')\n",
    "print('总计单词数：%s' % index_word_df.shape[0])\n",
    "print('最大建模用索引下标:%s' % \n",
    "      np.max([np.max(t) for t in text_sequences]), '\\n')\n",
    "word_counts_df = pd.DataFrame.from_dict(tokenizer.word_counts, \n",
    "                                        orient='index', \n",
    "                                        columns=['counts'])\n",
    "word_index_df = pd.DataFrame.from_dict(tokenizer.word_index, \n",
    "                                       orient='index', \n",
    "                                       columns=['index'])\n",
    "temp=pd.merge(word_counts_df, word_index_df, \n",
    "              left_index=True, right_index=True)\n",
    "print(temp.sort_values(by='counts', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'酒店非常棒，，环境一流，。。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents2[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp=' '.join('距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.')\n",
    "#cntext.cntext_to_word_sequence(temp)\n",
    "#temp2=jieba.cut(temp.strip())\n",
    "#temp3 = [x for x in temp2 if x!=' ']\n",
    "np.max([len(x) for x in text_sequences] )\n",
    "#print(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3000)\n",
      "(2000, 220)\n"
     ]
    }
   ],
   "source": [
    "max_len = 220\n",
    "text_sequences_padded = sequence.pad_sequences(text_sequences, maxlen=max_len)\n",
    "x_binary_coding = tokenizer.sequences_to_matrix(text_sequences)\n",
    "print(x_binary_coding.shape)\n",
    "print(text_sequences_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...   210   211   212  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    58  2924   200   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    28     2    88   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...   568   967  1191   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...   129   103   205   \n",
      "\n",
      "    213   214   215  216   217   218   219  \n",
      "0    11   888   112  506  2266     2  2925  \n",
      "1  2926  2267   330   10   507   454     5  \n",
      "2  1328     1   104  889   156    27   145  \n",
      "3    30  2927   122  319   339  1786    60  \n",
      "4   455    63  2928  650    43   809   103  \n",
      "\n",
      "[5 rows x 220 columns] (2000, 220)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.DataFrame(text_sequences_padded)\n",
    "print(X.head(), X.shape)\n",
    "Y = pd.get_dummies(label)\n",
    "\n",
    "ids = [i for i in range(2000)]\n",
    "model_sample = np.random.choice(ids, 1500, replace=False)\n",
    "test_sample = [i for i in ids if i not in model_sample]\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.250, random_state = 8798797)\n",
    "X_train, Y_train = X.iloc[model_sample, :], Y.iloc[model_sample, :]\n",
    "X_test, Y_test = X.iloc[test_sample, :], Y.iloc[test_sample, :]\n",
    "\n",
    "#Xb_train, Xb_test, Yb_train, Yb_test = train_test_split(x_binary_coding, Y, test_size=0.25, random_state=138723)\n",
    "Xb_train, Yb_train = x_binary_coding[model_sample, :], Y.iloc[model_sample, :]\n",
    "Xb_test, Yb_test = x_binary_coding[test_sample, :], Y.iloc[test_sample, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 220) (500, 220)\n",
      "[ 810  846 1465 ... 1541 1896 1431]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(model_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_binary_coding[test_sample,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, SpatialDropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 220, 1500)         4498500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 220, 1500)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 220, 250)          1125250   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               128512    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 5,884,104\n",
      "Trainable params: 5,884,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentence_length = X_train.shape[1]\n",
    "max_features = np.max([np.max(t) for t in text_sequences_padded])\n",
    "embedding_dims = 1500\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 512\n",
    "out_dim=2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=sentence_length))\n",
    "model.add(SpatialDropout(0.5))\n",
    "\n",
    "model.add(Conv1D(filters, kernel_size, padding='same',\n",
    "                 activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_dims//2, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(out_dim, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "0 (InputLayer)                  (None, 220)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "1 (Embedding)                   (None, 220, 16)      47984       0[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "2A (Conv1D)                     (None, 218, 256)     12544       1[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "2B (Conv1D)                     (None, 216, 256)     20736       1[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "3A (GlobalMaxPooling1D)         (None, 256)          0           2A[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "3B (GlobalMaxPooling1D)         (None, 256)          0           2B[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "4 (Concatenate)                 (None, 512)          0           3A[0][0]                         \n",
      "                                                                 3B[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "5 (Dense)                       (None, 2)            1026        4[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 82,290\n",
      "Trainable params: 82,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 348.00 410.00\" width=\"348pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-406 344,-406 344,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2327103404296 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2327103404296</title>\n",
       "<polygon fill=\"none\" points=\"124,-365.5 124,-401.5 215,-401.5 215,-365.5 124,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-379.8\">0: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2327103404408 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2327103404408</title>\n",
       "<polygon fill=\"none\" points=\"122.5,-292.5 122.5,-328.5 216.5,-328.5 216.5,-292.5 122.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-306.8\">1: Embedding</text>\n",
       "</g>\n",
       "<!-- 2327103404296&#45;&gt;2327103404408 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2327103404296-&gt;2327103404408</title>\n",
       "<path d=\"M169.5,-365.313C169.5,-357.289 169.5,-347.547 169.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"173,-338.529 169.5,-328.529 166,-338.529 173,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327101492696 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2327101492696</title>\n",
       "<polygon fill=\"none\" points=\"55,-219.5 55,-255.5 142,-255.5 142,-219.5 55,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-233.8\">2A: Conv1D</text>\n",
       "</g>\n",
       "<!-- 2327103404408&#45;&gt;2327101492696 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2327103404408-&gt;2327101492696</title>\n",
       "<path d=\"M152.313,-292.313C143.417,-283.417 132.409,-272.409 122.672,-262.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125.075,-260.125 115.529,-255.529 120.125,-265.075 125.075,-260.125\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327102033256 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2327102033256</title>\n",
       "<polygon fill=\"none\" points=\"197.5,-219.5 197.5,-255.5 283.5,-255.5 283.5,-219.5 197.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240.5\" y=\"-233.8\">2B: Conv1D</text>\n",
       "</g>\n",
       "<!-- 2327103404408&#45;&gt;2327102033256 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2327103404408-&gt;2327102033256</title>\n",
       "<path d=\"M186.687,-292.313C195.583,-283.417 206.591,-272.409 216.328,-262.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"218.875,-265.075 223.471,-255.529 213.925,-260.125 218.875,-265.075\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327103404352 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2327103404352</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 161,-182.5 161,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-160.8\">3A: GlobalMaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 2327101492696&#45;&gt;2327103404352 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2327101492696-&gt;2327103404352</title>\n",
       "<path d=\"M94.1427,-219.313C92.0865,-211.202 89.5851,-201.336 87.2884,-192.277\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"90.6674,-191.362 84.8172,-182.529 83.882,-193.082 90.6674,-191.362\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327103405360 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2327103405360</title>\n",
       "<polygon fill=\"none\" points=\"179,-146.5 179,-182.5 340,-182.5 340,-146.5 179,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-160.8\">3B: GlobalMaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 2327102033256&#45;&gt;2327103405360 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2327102033256-&gt;2327103405360</title>\n",
       "<path d=\"M245.099,-219.313C247.27,-211.202 249.91,-201.336 252.334,-192.277\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"255.739,-193.094 254.943,-182.529 248.977,-191.284 255.739,-193.094\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327102058848 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2327102058848</title>\n",
       "<polygon fill=\"none\" points=\"120,-73.5 120,-109.5 219,-109.5 219,-73.5 120,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-87.8\">4: Concatenate</text>\n",
       "</g>\n",
       "<!-- 2327103404352&#45;&gt;2327102058848 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2327103404352-&gt;2327102058848</title>\n",
       "<path d=\"M102.044,-146.313C113.523,-137.156 127.808,-125.76 140.273,-115.816\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"142.519,-118.501 148.154,-109.529 138.154,-113.029 142.519,-118.501\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327103405360&#45;&gt;2327102058848 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2327103405360-&gt;2327102058848</title>\n",
       "<path d=\"M237.714,-146.313C226.106,-137.156 211.661,-125.76 199.055,-115.816\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"201.105,-112.975 191.086,-109.529 196.769,-118.47 201.105,-112.975\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2327102045712 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2327102045712</title>\n",
       "<polygon fill=\"none\" points=\"137,-0.5 137,-36.5 202,-36.5 202,-0.5 137,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-14.8\">5: Dense</text>\n",
       "</g>\n",
       "<!-- 2327102058848&#45;&gt;2327102045712 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2327102058848-&gt;2327102045712</title>\n",
       "<path d=\"M169.5,-73.3129C169.5,-65.2895 169.5,-55.5475 169.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"173,-46.5288 169.5,-36.5288 166,-46.5289 173,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同样的模型，用函数式方式表示：\n",
    "\n",
    "_input = Input(shape=(sentence_length, ), dtype='int32', name='0')\n",
    "_embedding = Embedding(input_dim=max_features, \n",
    "                       output_dim=embedding_dim, \n",
    "                       input_length=sentence_length,\n",
    "                       name='1')(_input)\n",
    "\n",
    "_conv_0 = Conv1D(num_filters, kernel_size=3, \n",
    "                 activation='relu', name='2A')(_embedding)\n",
    "_pooling_0 = GlobalMaxPooling1D(name='3A')(_conv_0)\n",
    "\n",
    "_conv_1 = Conv1D(num_filters, kernel_size=5, \n",
    "                 activation='selu', name='2B')(_embedding)\n",
    "_pooling_1 = GlobalMaxPooling1D(name='3B')(_conv_1)\n",
    "\n",
    "_concatenated = Concatenate(axis=1, \n",
    "                            name='4')([_pooling_0, _pooling_1])\n",
    "\n",
    "_output = Dense(2, activation='softmax', name='5')(_concatenated)\n",
    "\n",
    "model_2 = Model(inputs=_input, outputs=_output)\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "SVG(model_to_dot(model_2).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6886 - acc: 0.6033 - val_loss: 0.4513 - val_acc: 0.8080\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 884us/step - loss: 0.3598 - acc: 0.8580 - val_loss: 0.3713 - val_acc: 0.8560\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 883us/step - loss: 0.0961 - acc: 0.9687 - val_loss: 0.4740 - val_acc: 0.8580\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 886us/step - loss: 0.0225 - acc: 0.9927 - val_loss: 0.5780 - val_acc: 0.8640\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 890us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6670 - val_acc: 0.8540\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6916 - val_acc: 0.8520\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 887us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7061 - val_acc: 0.8660\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 8.8149e-04 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.8640\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 894us/step - loss: 4.6544e-04 - acc: 1.0000 - val_loss: 0.7525 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 897us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7745 - val_acc: 0.8620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d86b08f28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data = (X_test, Y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为比较，我们下面执行两个常见得分类模型：\n",
    "1. 四层全连接层的深度模型\n",
    "2. 一个带L2正则项得逻辑斯特回归。L2正则项已经经过挑选。\n",
    "\n",
    "我们先看这个全连接深度模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              3073024   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 3,762,306\n",
      "Trainable params: 3,762,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Dense(1024, input_shape=(Xb_train.shape[1],), activation='tanh'))\n",
    "model0.add(Dropout(0.5))\n",
    "model0.add(Dense(512, activation='tanh'))\n",
    "model0.add(Dropout(0.5))\n",
    "model0.add(Dense(256, activation='tanh'))\n",
    "model0.add(Dropout(0.5))\n",
    "model0.add(Dense(128, activation='tanh'))\n",
    "model0.add(Dropout(0.5))\n",
    "model0.add(Dense(2, activation='softmax'))\n",
    "model0.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.5913 - acc: 0.6767 - val_loss: 0.3857 - val_acc: 0.8180\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3117 - acc: 0.8733 - val_loss: 0.3864 - val_acc: 0.8620\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.1464 - acc: 0.9460 - val_loss: 0.4458 - val_acc: 0.8480\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0790 - acc: 0.9753 - val_loss: 0.5872 - val_acc: 0.8440\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.0483 - acc: 0.9860 - val_loss: 0.7316 - val_acc: 0.8420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d86e74c50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "model0.fit(Xb_train, Yb_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(Xb_test, Yb_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果非常不错，下面再来看逻辑斯特回归的效果。逻辑斯特回归的输入不能是单词小标的句子组合，而应该是独热编码后的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n",
      "0.856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "y = np.array(label)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', C=1.05, n_jobs=-1,\n",
    "                          multi_class='multinomial').fit(Xb_train, Yb_train.iloc[:, 0])\n",
    "\n",
    "clf.predict_proba(Xb_train[:2, :]) \n",
    "print(clf.score(Xb_train, Yb_train.iloc[:, 0]))\n",
    "print(clf.score(Xb_test, Yb_test.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pseudo-logistic (Dense)      (None, 2)                 6002      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,002\n",
      "Trainable params: 6,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 2.4235 - acc: 0.6173 - val_loss: 0.4457 - val_acc: 0.8540\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.3016 - acc: 0.7547 - val_loss: 0.3849 - val_acc: 0.8640\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.2908 - acc: 0.7933 - val_loss: 0.3496 - val_acc: 0.8640\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.1506 - acc: 0.8227 - val_loss: 0.3308 - val_acc: 0.8680\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.3287 - acc: 0.8220 - val_loss: 0.3186 - val_acc: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d8e4eeda0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(2, input_shape=(Xb_train.shape[1],), activation='softmax', name='pseudo-logistic'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "model1.fit(Xb_train, Yb_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(Xb_test, Yb_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接深度模型和逻辑斯特回归的效果都不错，比用卷积的神经网络模型效果好。这是因为该数据集太小，仅仅有1500个样本供训练，对于卷积神经网络这个稍微复杂的结构来说，还不太够。逻辑斯特回归的鲁棒性在这里表现得比较突出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用二维卷积神经网络进行文本分类模型\n",
    "\n",
    "我们也可以使用二维卷积神经网络对文本建模。这是因为，我们可以将一个文本中相邻的单词对应的词向量叠加起来，那么对于任意给定的窗口，这些叠加的词向量就构成一个类似图片的二维“面板”数据。\n",
    "\n",
    "从《词嵌入与词向量》这节课中我们了解到可以将一组文本中的任意单词映射到一个指定维度的新的空间。这个指定的维度通常比文本中全部单词所需要的维度低很多，但是通常仍然需要数百维。我们需要将使用卷积神经网络将这数百维的向量再次压缩到更低的向量中。对于这样一个一维的连续信号，完全可以使用上面提到的一维卷积方法，一方面可以将维度从数百维降为更低维度，另一方面又能尽可能萃取最有用的信号。\n",
    "\n",
    "在前面的Conv1D的例子中，我们先通过嵌入层依次读入输入的单词下标后，在一句话读完后，输出一个(样本，句子长度，嵌入层维度)的三维张量，这个张量与一维卷积层需要的维度正好相符，其结构要求为(样本，步数，频道)。一维卷积层在嵌入层这个维度进行卷积操作，生成一个新的(样本，步数，滤子数)的张量供下游网络层使用。\n",
    "\n",
    "如果要使用二维卷积网络，我们需要将嵌入层输入的数据进行一些维度上的修改，因为Conv2D卷积层接受的输入维度是(样本，行，列，频道数)。这里的行可以对应数据的句子的长度，而列就是嵌入层的维度，我们只需要再告诉程序输入的每一个样本数据是只有一个频道的张量即可：(句子长度，嵌入层维度，1)。这一步可以通过以下代码实现。\n",
    "\n",
    "使用二维卷积的时候，程序考虑的不仅仅是每一个单词在低维空间映射的维度的卷积，而且也包含了相邻的单词之间的卷积操作，可以挖掘更丰富的信息。\n",
    "\n",
    "<code>\n",
    "reshape = Reshape((sequence_length, embedding_dim, 1))(embedding)    \n",
    "</code>\n",
    "\n",
    "下图展示了2D卷积神经网络结构的建模流程：\n",
    "\n",
    "<img src=\"./pics/text_CNN_2D.png\" width=700>\n",
    "\n",
    "我们仍然以上面的2000条酒店评论数据为例。数据的处理与一维卷积网络模型没有差别，需要注入模型的仍然是一个(样本数，句子长度)的矩阵，每列对应的是在句子该顺序位出现的单词下标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 220, 1024)         3070976   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 220, 1024)         0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 220, 1024, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 71, 334, 256)      49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 3,219,330\n",
      "Trainable params: 3,219,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentence_length = X_train.shape[1]\n",
    "max_features = np.max([np.max(t) for t in text_sequences_padded])\n",
    "\n",
    "embedding_dim = 1024\n",
    "filter_size = 8\n",
    "num_filters = 256\n",
    "hidden_dim=256\n",
    "out_dim=2\n",
    "droprate = 0.5\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "# 先用一个嵌入层将下标映射到一个致密空间\n",
    "# 从而每一句话为一个(句长，嵌入维)的矩阵\n",
    "\n",
    "model2.add(Embedding(max_features,\n",
    "                     embedding_dim,\n",
    "                     input_length=sentence_length)\n",
    "          )\n",
    "model2.add(Dropout( droprate/2 ))\n",
    "model2.add(Reshape( (sentence_length, \n",
    "                     embedding_dim, \n",
    "                     1) )\n",
    "          )\n",
    "\n",
    "# we add a Convolution2D\n",
    "model2.add(Conv2D(num_filters, \n",
    "                  kernel_size=(filter_size, filter_size*3), \n",
    "                  kernel_initializer='he_uniform',\n",
    "                  padding='valid', \n",
    "                  activation='relu',\n",
    "                  strides=3))\n",
    "# 使用全局最大池化约束维度:\n",
    "model2.add(GlobalMaxPooling2D())\n",
    "\n",
    "# 标准得全连接层\n",
    "model2.add(Dense(hidden_dim, activation='tanh'))\n",
    "model2.add(Dropout( droprate ))\n",
    "model2.add(Dense(hidden_dim//2, activation='tanh'))\n",
    "model2.add(Dropout( droprate/2 ))\n",
    "\n",
    "# 二分类模型得标准做法\n",
    "model2.add(Dense(out_dim, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Model...\n",
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 0.8414 - acc: 0.5073 - val_loss: 0.6986 - val_acc: 0.4900\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.7801 - acc: 0.4927 - val_loss: 0.7467 - val_acc: 0.4900\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.7598 - acc: 0.4853 - val_loss: 0.7038 - val_acc: 0.4920\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.5919 - acc: 0.6667 - val_loss: 0.3915 - val_acc: 0.8380\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2432 - acc: 0.9173 - val_loss: 0.3908 - val_acc: 0.8560\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1035 - acc: 0.9707 - val_loss: 0.5653 - val_acc: 0.7700\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0545 - acc: 0.9833 - val_loss: 0.6735 - val_acc: 0.8220\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0688 - acc: 0.9787 - val_loss: 0.5269 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0559 - acc: 0.9807 - val_loss: 0.6562 - val_acc: 0.8220\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0474 - acc: 0.9867 - val_loss: 0.5706 - val_acc: 0.8360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d999eab00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "print(\"Traning Model...\")\n",
    "model2.fit(X_train, Y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           validation_data = (X_test, Y_test),\n",
    "           verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于RNN/LSTM的文本分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import types\n",
    "import numpy as np\n",
    "import cntext \n",
    "import jieba\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Movie_Name_EN</th>\n",
       "      <th>Movie_Name_CN</th>\n",
       "      <th>Crawl_Date</th>\n",
       "      <th>Number</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Star</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>然潘</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>3</td>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>2</td>\n",
       "      <td>更深的白色</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>2</td>\n",
       "      <td>非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、...</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>3</td>\n",
       "      <td>有意识的贱民</td>\n",
       "      <td>2015-04-26</td>\n",
       "      <td>2</td>\n",
       "      <td>2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出...</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>4</td>\n",
       "      <td>不老的李大爷耶</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于...</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>5</td>\n",
       "      <td>ZephyrO</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>虽然从头打到尾，但是真的很无聊啊。</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           Movie_Name_EN Movie_Name_CN  Crawl_Date  Number Username  \\\n",
       "0   0  Avengers Age of Ultron        复仇者联盟2  2017-01-22       1       然潘   \n",
       "1   1  Avengers Age of Ultron        复仇者联盟2  2017-01-22       2    更深的白色   \n",
       "2   2  Avengers Age of Ultron        复仇者联盟2  2017-01-22       3   有意识的贱民   \n",
       "3   3  Avengers Age of Ultron        复仇者联盟2  2017-01-22       4  不老的李大爷耶   \n",
       "4   4  Avengers Age of Ultron        复仇者联盟2  2017-01-22       5  ZephyrO   \n",
       "\n",
       "         Date  Star                                            Comment  Like  \n",
       "0  2015-05-13     3                                      连奥创都知道整容要去韩国。  2404  \n",
       "1  2015-04-24     2   非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、...  1231  \n",
       "2  2015-04-26     2   2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出...  1052  \n",
       "3  2015-04-23     4   《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于...  1045  \n",
       "4  2015-04-22     2                                  虽然从头打到尾，但是真的很无聊啊。   723  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = './nlp_data/douban_moview_reviews/DMSC.csv'\n",
    "raw = pd.read_csv(file, header=0)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125056\n",
      " 连奥创都知道整容要去韩国。\n",
      " 非常失望，剧本完全敷衍了事，主线剧情没突破大家可以理解，可所有的人物都缺乏动机，正邪之间、妇联内部都没什么火花。团结-分裂-团结的三段式虽然老套但其实也可以利用积攒下来的形象魅力搞出意思，但剧本写得非常肤浅、平面。场面上调度混乱呆板，满屏的铁甲审美疲劳。只有笑点算得上差强人意。\n",
      " 2015年度最失望作品。以为面面俱到，实则画蛇添足；以为主题深刻，实则老调重弹；以为推陈出新，实则俗不可耐；以为场面很high，实则high劲不足。气！上一集的趣味全无，这集的笑点明显刻意到心虚。全片没有任何片段给我有紧张激动的时候，太弱了，跟奥创一样。\n",
      " 《铁人2》中勾引钢铁侠，《妇联1》中勾引鹰眼，《美队2》中勾引美国队长，在《妇联2》中终于……跟绿巨人表白了，黑寡妇用实际行动告诉了我们什么叫忠贞不二；而且为了治疗不孕不育连作战武器都变成了两支验孕棒(坚决相信快银没有死，后面还得回来)\n"
     ]
    }
   ],
   "source": [
    "documents = raw.Comment.tolist()\n",
    "documents2 = documents[:100000]\n",
    "print(len(documents))\n",
    "\n",
    "for i in range(4):\n",
    "    print(documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['———', '》），', '）÷（１－', '”，', '）、']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读入标准的中文停止词：\n",
    "stopwords = []\n",
    "with open('stopwords_std.txt', encoding='UTF-8') as fo:\n",
    "    for line in fo:\n",
    "        for w in line.split():\n",
    "            stopwords.append(line.strip())\n",
    "        \n",
    "stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 49s\n",
      "Wall time: 7min 6s\n"
     ]
    }
   ],
   "source": [
    "num_words = 8000\n",
    "stopwords_str = ' '.join(stopwords)\n",
    "stopwords_set = set(stopwords_str.split())\n",
    "tokenizer = cntext.cnTokenizer(num_words=num_words, \n",
    "                               filters=stopwords_set, \n",
    "                               char_level=False, \n",
    "                               min_len=2)\n",
    "%time tokenizer.fit_on_cntexts(documents)\n",
    "%time text_sequences=tokenizer.cntexts_to_sequences(documents)\n",
    "V = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( set(' '.join(stopwords_str).split() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长句子单词数 ： 70\n",
      "Wall time: 8.43 s\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "temp = list(text_sequences[:2])\n",
    "sentence_length = np.max( [len(w) for w in text_sequences])\n",
    "print('最长句子单词数 ： %s' % sentence_length)\n",
    "%time text_sequences_padded = sequence.pad_sequences(text_sequences, \n",
    "                                                     maxlen=sentence_length)\n",
    "total_sample = len(text_sequences_padded)\n",
    "\n",
    "ids = [i for i in range(total_sample)]\n",
    "model_sample = np.random.choice(ids, 1500000, replace=False)\n",
    "model_sample_set = set(model_sample)\n",
    "%time test_sample = [i for i in ids if i not in model_sample_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = to_categorical((raw.Star>4)*1)\n",
    "\n",
    "Y_train, Y_test = target[model_sample], target[test_sample]\n",
    "X_train, X_test = text_sequences_padded[model_sample], text_sequences_padded[test_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, SpatialDropout1D, SpatialDropout2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = num_words\n",
    "batch_size = 64\n",
    "embedding_dims = 500\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "out_dim=1\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 70, 64)            512000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 34, 256)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               142800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 710,802\n",
      "Trainable params: 710,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 70, 128)           1024000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 70, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,115,802\n",
      "Trainable params: 1,115,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, lstm_dim, hidden_dim = 64, 100, 64\n",
    "filters, kernel_size = 256, 3\n",
    " \n",
    "# 构建LSTM网络完成评分分析\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(num_words, embedding_dim, \n",
    "                         input_length = sentence_length))\n",
    "model_lstm.add(Conv1D(filters, \n",
    "                      kernel_size, \n",
    "                      padding='valid',\n",
    "                      activation='relu',\n",
    "                      strides=2))\n",
    "model_lstm.add(LSTM(lstm_dim, \n",
    "                    dropout=0.2, \n",
    "                    recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(hidden_dim, activation='tanh'))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(2,activation='softmax'))\n",
    "model_lstm.compile(loss = 'categorical_crossentropy', \n",
    "                   optimizer='adam',\n",
    "                   metrics = ['accuracy'])\n",
    "model_lstm.summary()\n",
    "#=====================================================\n",
    "embed_dim, lstim_dim = 128, 100\n",
    "# 构建LSTM网络完成评分分析\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embed_dim, \n",
    "                    input_length = X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500000 samples, validate on 625056 samples\n",
      "Epoch 1/5\n",
      "1500000/1500000 [==============================] - 263s 175us/step - loss: 0.4793 - acc: 0.7686 - val_loss: 0.4612 - val_acc: 0.7782\n",
      "Epoch 2/5\n",
      "1500000/1500000 [==============================] - 262s 175us/step - loss: 0.4576 - acc: 0.7797 - val_loss: 0.4568 - val_acc: 0.7803\n",
      "Epoch 3/5\n",
      "1500000/1500000 [==============================] - 263s 175us/step - loss: 0.4508 - acc: 0.7834 - val_loss: 0.4548 - val_acc: 0.7813\n",
      "Epoch 4/5\n",
      "1500000/1500000 [==============================] - 262s 175us/step - loss: 0.4458 - acc: 0.7859 - val_loss: 0.4535 - val_acc: 0.7822\n",
      "Epoch 5/5\n",
      "1500000/1500000 [==============================] - 257s 171us/step - loss: 0.4415 - acc: 0.7883 - val_loss: 0.4525 - val_acc: 0.7824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202b452fe10>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size= 1024\n",
    "epochs = 5\n",
    "# 拟合与训练模型\n",
    "model.fit(X_train, Y_train, batch_size =batch_size, validation_data=(X_test, Y_test), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500000 samples, validate on 625056 samples\n",
      "Epoch 1/5\n",
      "1500000/1500000 [==============================] - 108s 72us/step - loss: 0.5150 - acc: 0.7488 - val_loss: 0.4972 - val_acc: 0.7583\n",
      "Epoch 2/5\n",
      "1500000/1500000 [==============================] - 106s 71us/step - loss: 0.4928 - acc: 0.7612 - val_loss: 0.4940 - val_acc: 0.7600\n",
      "Epoch 3/5\n",
      "1500000/1500000 [==============================] - 106s 71us/step - loss: 0.4847 - acc: 0.7654 - val_loss: 0.4927 - val_acc: 0.7611\n",
      "Epoch 4/5\n",
      "1500000/1500000 [==============================] - 106s 71us/step - loss: 0.4770 - acc: 0.7695 - val_loss: 0.4938 - val_acc: 0.7602\n",
      "Epoch 5/5\n",
      "1500000/1500000 [==============================] - 106s 71us/step - loss: 0.4689 - acc: 0.7739 - val_loss: 0.4963 - val_acc: 0.7593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202b452fda0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "epochs = 5\n",
    "model_lstm.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999\n"
     ]
    }
   ],
   "source": [
    "print(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.273432"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
