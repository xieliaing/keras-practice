{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词向量与词嵌入\n",
    "\n",
    "本章介绍词嵌入（word embedding）方法。依次有如下内容：\n",
    "1. 概述\n",
    "2. 机器学习对于词的表示方法\n",
    "3. 神经网络语言模型（Neural Network Language Model）\n",
    "4. word2vec构造词向量\n",
    "5. 使用keras完成词向量的训练与可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习对于词的表示方法\n",
    "\n",
    "在NLP建模中，最重要和最根本的任务就是在模型中对输入的单词进行表示，方便模型识别单词之间的相似性和差异性。词的表达主要有两大类：早期的NLP工作中，词的表示大多是基于基本符号（atomic symbol）；而在现代NLP中，更多的是以词向量（word vector）的方法来表示，从而使得词间相似性计算更加便捷。下面先简要介绍早期的词表示方法，再着重解释现代的词向量方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 词向量方法\n",
    "\n",
    "在真实世界中，单词的数量是巨大的。比如根据现代汉语词典，中文里常用的基本词和词组大约有5万6千多个，加上现在网络上新兴的各种单词及其组合，则无人有过精确统计；至于英语，韦伯斯特词典则大约收录了1百万个英语单词。当然，汉语的词数量不适宜跟英语相比，中文的词主要是一个词根作用，加上其各种组合应该数量也是巨大的。\n",
    "\n",
    "这些单词之间并不是完全独立的，也不是每一个单词都代表一个完全独立的概念。我们可以认为我们在谈话时所表达的实际语义实际更少，是在一个数量更低的维度上。比如性别（男 vs 女）；交通工具（汽车 vs 飞机），食品（宫保鸡丁 vs 火锅）等等。\n",
    "\n",
    "我们下面介绍几种常见的词向量表示方法：\n",
    "1. 独热编码（One Hot Encoding）\n",
    "2. 基于SVD的编码\n",
    "3. 迭代编码方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 独热编码 （One Hot Encoding）\n",
    "\n",
    "独热编码是对于当前单词表中的单词使用一个向量进行表达的简单方式。假如当前的单词表有10个不同的单词，那么独热编码使用10位的0、1数字来对该单词表进行编码，出现每个单词在对应的序号位标为1，否则为0。下面举例说明：\n",
    "\n",
    "假设我们的文档分词后产生如下的单词表：[“中国”，“国家”，“主席”，“习近平”，“北京”，“钓鱼台”，“会见”，“到”，“访”，“日本”，“首相”]，共11个单词，并且单词序号也按照上面的次序，那么我们的独热编码$w$就使用一个11个0、1数字的向量来表示这些单词：\n",
    "\n",
    "w(“中国”)：1000000000； w(“国家”)：01000000000，......，w(“首相”)：00000000001\n",
    "\n",
    "一般说来，对于一个具有N个元素的单词表，独热编码将每一个单词映射为$R^{1\\times|N|}$的向量，向量中对应单词序号的位置数值为1，其余为0。\n",
    "\n",
    "当然，独热编码虽然简单，但是其有几个问题：\n",
    "1. 存储效率极低\n",
    "2. 每个单词是完全独立的存在，之间并无联系。比如$w （“中国”）^T w（“日本”）=0$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于SVD的编码\n",
    "我们看到，独热编码虽然简单，但是对于建模来说并不是较好的选择。研究者探索了可以解决存储效率和单词之间关系问题的方法，其中基于SVD的编码便是较常见的一种。这种方法依赖于通过word-document矩阵生成的共生矩阵（cooccurance matrix），下面分别介绍：\n",
    "1. 词-文矩阵（word-document matrix）。这是以单词为行，以文本为列的矩阵，反映一个文本中以0、1编码表示的所有单词；\n",
    "2. 基于滑动窗的共生矩阵（window based co-occurance matrix）。该矩阵是一个“词-词矩阵”（word-word matrix），反映的是在一个给定的窗口中两个单词同时出现的频次统计；\n",
    "\n",
    "直接按照逻辑来实现对以上矩阵的生产并不难，但是sklearn里面已经有现成的方法可供调用，直接对以列表形式出现的文本集合进行操作，非常方便。下面先举一个简单示例说明逻辑，再展示实践中可用的生产性代码。在英文文档中，可以直接使用sklearn的文字处理模块进行操作，但是中文需要先进行分词再使用sklearn的模块进行处理。\n",
    "\n",
    "下面，我们：\n",
    "- 首先展示如何生成**词-文矩阵**；\n",
    "- 再展示如何生成基于滑动窗的**共生矩阵**；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'cat', 'dog', 'fight', 'good', 'is', 'this']\n",
      "[[1 0 0 0 1 1 1]\n",
      " [0 1 0 0 1 1 2]\n",
      " [0 1 1 1 0 0 0]]\n",
      "{'this': 6, 'is': 5, 'good': 4, 'book': 0, 'cat': 1, 'dog': 2, 'fight': 3}\n"
     ]
    }
   ],
   "source": [
    "# 对于英文文档列表，可以直接使用sklearn工具生成 WORD-DOCUMENT Matrix \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = ['this is a good book',\n",
    "        'this cat is this good',\n",
    "        'cat dog fight']\n",
    "count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
    "X = count_model.fit_transform(docs)\n",
    "print(count_model.get_feature_names())\n",
    "print(X.todense())\n",
    "print(count_model.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对中文进行“词-文矩阵”生成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "jieba.initialize()  \n",
    "# 简单示例\n",
    "documents = [u'独热编码是对于当前单词表中的单词使用1个向量进行表达的简单方式，独热编码有自身的缺点和有点。', \n",
    "             u'假如当前的单词表有10个不同的单词，并且每个单词都不一样', \n",
    "             u'研究者探索了可以解决存储效率和单词之间关系问题的方法', \n",
    "             u'独热编码虽然简单']\n",
    "\n",
    "vocabulary = {}\n",
    "documents_after = []\n",
    "\n",
    "\n",
    "# 先构造使用jieba分词后的文本列表，我们构造一个函数来进行操作\n",
    "\n",
    "def cn_list_seg(documents, removeDigits=True):\n",
    "    vocabulary = {}\n",
    "    documents_after = []\n",
    "    documents = list(documents)\n",
    "    for doc in documents:\n",
    "        # 每一个文本的分句要单独拎出来进行分词处理，\n",
    "        sentences = doc.split(',.，。；')\n",
    "        seg_doc = ''\n",
    "        for sentence in sentences:\n",
    "            result=jieba.tokenize(sentence)\n",
    "            # 如果分词出来的结果包含数字，就扔掉\n",
    "            for word in result:\n",
    "                if (removeDigits) & bool(re.search('\\d+', word[0])):\n",
    "                    pass\n",
    "                else:\n",
    "                    seg_doc = seg_doc + ' ' + word[0]\n",
    "                    if word in vocabulary.keys():\n",
    "                        vocabulary[word[0]] += 1\n",
    "                    else:\n",
    "                        vocabulary[word[0]] = 1\n",
    "        documents_after.append(seg_doc)    \n",
    "    return documents_after, vocabulary\n",
    "    \n",
    "documents_after, vocabulary = cn_list_seg(documents[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面进行矩阵构建操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文分词后的文档：\n",
      "[' 独热 编码 是 对于 当前 单词表 中 的 单词 使用 个 向量 进行 表达 的 简单 方式 ， 独热 编码 有 自身 的 缺点 和 有点 。', ' 假如 当前 的 单词表 有 个 不同 的 单词 ， 并且 每个 单词 都 不 一样', ' 研究者 探索 了 可以 解决 存储 效率 和 单词 之间 关系 问题 的 方法', ' 独热 编码 虽然 简单']\n",
      "\n",
      "\n",
      "标注化（Tokenized）后的特征列表：\n",
      "['不同 单词', '之间 关系', '使用 向量', '假如 当前', '关系 问题', '单词 一样', '单词 之间', '单词 使用', '单词 并且', '单词表 不同', '单词表 单词', '可以 解决', '向量 进行', '存储 效率', '对于 当前', '并且 每个', '当前 单词表', '探索 可以', '效率 单词', '方式 独热', '每个 单词', '独热 编码', '研究者 探索', '简单 方式', '编码 对于', '编码 自身', '编码 虽然', '缺点 有点', '自身 缺点', '虽然 简单', '表达 简单', '解决 存储', '进行 表达', '问题 方法']\n",
      "\n",
      "\n",
      "词-文矩阵：\n",
      "[[0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 2 0 1 1 1 0 1 1 0 1 0 1 0]\n",
      " [1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0]]\n",
      "\n",
      "\n",
      "词-文矩阵对应的特征索引号（矩阵列的序号）：\n",
      "{'独热 编码': 21, '编码 对于': 24, '对于 当前': 14, '当前 单词表': 16, '单词表 单词': 10, '单词 使用': 7, '使用 向量': 2, '向量 进行': 12, '进行 表达': 32, '表达 简单': 30, '简单 方式': 23, '方式 独热': 19, '编码 自身': 25, '自身 缺点': 28, '缺点 有点': 27, '假如 当前': 3, '单词表 不同': 9, '不同 单词': 0, '单词 并且': 8, '并且 每个': 15, '每个 单词': 20, '单词 一样': 5, '研究者 探索': 22, '探索 可以': 17, '可以 解决': 11, '解决 存储': 31, '存储 效率': 13, '效率 单词': 18, '单词 之间': 6, '之间 关系': 1, '关系 问题': 4, '问题 方法': 33, '编码 虽然': 26, '虽然 简单': 29}\n",
      "\n",
      "\n",
      "带标签的词-文矩阵:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>不同 单词</th>\n",
       "      <th>之间 关系</th>\n",
       "      <th>使用 向量</th>\n",
       "      <th>假如 当前</th>\n",
       "      <th>关系 问题</th>\n",
       "      <th>单词 一样</th>\n",
       "      <th>单词 之间</th>\n",
       "      <th>单词 使用</th>\n",
       "      <th>单词 并且</th>\n",
       "      <th>单词表 不同</th>\n",
       "      <th>...</th>\n",
       "      <th>编码 对于</th>\n",
       "      <th>编码 自身</th>\n",
       "      <th>编码 虽然</th>\n",
       "      <th>缺点 有点</th>\n",
       "      <th>自身 缺点</th>\n",
       "      <th>虽然 简单</th>\n",
       "      <th>表达 简单</th>\n",
       "      <th>解决 存储</th>\n",
       "      <th>进行 表达</th>\n",
       "      <th>问题 方法</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   不同 单词  之间 关系  使用 向量  假如 当前  关系 问题  单词 一样  单词 之间  单词 使用  单词 并且  单词表 不同  \\\n",
       "0      0      0      1      0      0      0      0      1      0       0   \n",
       "1      1      0      0      1      0      1      0      0      1       1   \n",
       "2      0      1      0      0      1      0      1      0      0       0   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "   ...    编码 对于  编码 自身  编码 虽然  缺点 有点  自身 缺点  虽然 简单  表达 简单  解决 存储  进行 表达  问题 方法  \n",
       "0  ...        1      1      0      1      1      0      1      0      1      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      1      0      1  \n",
       "3  ...        0      0      1      0      0      1      0      0      0      0  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(u'中文分词后的文档：')\n",
    "print(documents_after)\n",
    "print('\\n')\n",
    "\n",
    "# 再使用sklearn模块生成word-document矩阵\n",
    "cn_count_model = CountVectorizer(ngram_range=(2,2)) # default unigram model\n",
    "cnX = cn_count_model.fit_transform(documents_after)\n",
    "\n",
    "print(u'标注化（Tokenized）后的特征列表：')\n",
    "print(cn_count_model.get_feature_names())\n",
    "print('\\n')\n",
    "\n",
    "print(u'词-文矩阵：')\n",
    "print(cnX.todense())\n",
    "print('\\n')\n",
    "\n",
    "print(u'词-文矩阵对应的特征索引号（矩阵列的序号）：')\n",
    "print(cn_count_model.vocabulary_)\n",
    "print('\\n')\n",
    "\n",
    "# 将词-文矩阵的列打上标签：\n",
    "voc_df=pd.DataFrame.from_dict(cn_count_model.vocabulary_, columns=['idx'], orient='index').sort_values(by=['idx'])\n",
    "cols = list(voc_df.index)\n",
    "print('带标签的词-文矩阵:')\n",
    "pd.DataFrame(cnX.todense(), columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是在实际工作中存在大量文本，我们会发现不同词的出现频率非常不同。这时候单纯使用词-文矩阵里面的频率计数到模型中会造成有偏差的结果。事实上，如果一个不常见的词在某一个文本中出现，那么其携带的信息量反而是非常高的。一种常见的变换方法就是TF-IDF（term-frequency inverse document frequency）。这个方法将高频词按照在所有文本中出现的频次进行降低权重的操作，从而来“突出”低频词的作用。tfidf使得文本相对更可比，计算文本之间的相似性的时候更有意义。\n",
    "\n",
    "TFIDF在sklearn里面有现成的工具进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一样', '不同', '之间', '使用', '假如', '关系', '单词', '单词表', '可以', '向量', '存储', '对于', '并且', '当前', '探索', '效率', '方式', '方法', '有点', '每个', '独热', '研究者', '简单', '编码', '缺点', '自身', '虽然', '表达', '解决', '进行', '问题']\n",
      "(4, 31)\n",
      "带标签的词-文矩阵:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>一样</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>不同</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>之间</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>使用</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>假如</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>关系</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>单词</th>\n",
       "      <td>0.158364</td>\n",
       "      <td>0.454968</td>\n",
       "      <td>0.197854</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>单词表</th>\n",
       "      <td>0.195611</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>可以</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>向量</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>存储</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>对于</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>并且</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当前</th>\n",
       "      <td>0.195611</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>探索</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>效率</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>方式</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>方法</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有点</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>每个</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>独热</th>\n",
       "      <td>0.391223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>研究者</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>简单</th>\n",
       "      <td>0.195611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>编码</th>\n",
       "      <td>0.391223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>缺点</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>自身</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>虽然</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>表达</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>解决</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>进行</th>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>问题</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "一样   0.000000  0.356398  0.000000  0.000000\n",
       "不同   0.000000  0.356398  0.000000  0.000000\n",
       "之间   0.000000  0.000000  0.309976  0.000000\n",
       "使用   0.248108  0.000000  0.000000  0.000000\n",
       "假如   0.000000  0.356398  0.000000  0.000000\n",
       "关系   0.000000  0.000000  0.309976  0.000000\n",
       "单词   0.158364  0.454968  0.197854  0.000000\n",
       "单词表  0.195611  0.280988  0.000000  0.000000\n",
       "可以   0.000000  0.000000  0.309976  0.000000\n",
       "向量   0.248108  0.000000  0.000000  0.000000\n",
       "存储   0.000000  0.000000  0.309976  0.000000\n",
       "对于   0.248108  0.000000  0.000000  0.000000\n",
       "并且   0.000000  0.356398  0.000000  0.000000\n",
       "当前   0.195611  0.280988  0.000000  0.000000\n",
       "探索   0.000000  0.000000  0.309976  0.000000\n",
       "效率   0.000000  0.000000  0.309976  0.000000\n",
       "方式   0.248108  0.000000  0.000000  0.000000\n",
       "方法   0.000000  0.000000  0.309976  0.000000\n",
       "有点   0.248108  0.000000  0.000000  0.000000\n",
       "每个   0.000000  0.356398  0.000000  0.000000\n",
       "独热   0.391223  0.000000  0.000000  0.465809\n",
       "研究者  0.000000  0.000000  0.309976  0.000000\n",
       "简单   0.195611  0.000000  0.000000  0.465809\n",
       "编码   0.391223  0.000000  0.000000  0.465809\n",
       "缺点   0.248108  0.000000  0.000000  0.000000\n",
       "自身   0.248108  0.000000  0.000000  0.000000\n",
       "虽然   0.000000  0.000000  0.000000  0.590819\n",
       "表达   0.248108  0.000000  0.000000  0.000000\n",
       "解决   0.000000  0.000000  0.309976  0.000000\n",
       "进行   0.248108  0.000000  0.000000  0.000000\n",
       "问题   0.000000  0.000000  0.309976  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cn_tf_model = TfidfVectorizer()\n",
    "X = cn_tf_model.fit_transform(documents_after)\n",
    "print(cn_tf_model.get_feature_names())\n",
    "print(X.shape)\n",
    "\n",
    "voc_df=pd.DataFrame.from_dict(cn_tf_model.vocabulary_, columns=['idx'], orient='index').sort_values(by=['idx'])\n",
    "cols = list(voc_df.index)\n",
    "print('带标签的词-文矩阵:')\n",
    "Xdf=pd.DataFrame(X.todense(), columns=cols)\n",
    "Xdf.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 滑动窗口的共生矩阵生成\n",
    "滑动窗口的共生矩阵因为包含了两个单词在一定相邻距离上同时出现的频次，因此反映了单词之间的相关程度。在上面的例子中因为信息量较小，两个词同时出现多次的情况没有，因此这里使用较大的外部数据来进行展示。我们使用的是1000条酒店评论数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['除非', '除了', '此', '此间', '此外', '从', '从而', '打', '待', '但', '但是', '当', '当着', '到', '得', '的', '的话']\n",
      "['距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', '商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', '早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。', '宾馆在小街道上，不大好找，但还好北京热心同胞很多~']\n"
     ]
    }
   ],
   "source": [
    "#XTX=np.dot(cnX.todense().T, cnX.todense())\n",
    "#XTX.shape\n",
    "documents = []\n",
    "stopword = []\n",
    "datafile = './nlp_data/hotel_reviews_data/1000_pos.txt'\n",
    "stopwordfile = './nlp_data/hotel_reviews_data/stopWord.txt'\n",
    "\n",
    "# 先读入stopword\n",
    "#fo=open(stopwordfile, encoding='UTF-8')\n",
    "with open(stopwordfile, encoding='UTF-8') as fo:\n",
    "    for line in fo:\n",
    "       stopword.append(line.strip('\\n'))\n",
    "\n",
    "print(stopword[70:87])\n",
    "\n",
    "# 再读入原始评论文档\n",
    "#fo=open(datafile, encoding='UTF-8')\n",
    "with open(datafile, encoding='UTF-8') as fo:\n",
    "    for line in fo:\n",
    "       documents.append(line.strip('\\n'))\n",
    "    \n",
    "print(documents[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果滑动窗口大小设为1，则考虑全局的共生矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标注化（Tokenized）后的特征列表：\n",
      "\n",
      "\n",
      "词-文矩阵：\n",
      "Wall time: 15.6 ms\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint(u'词-文矩阵对应的特征索引号（矩阵列的序号）：')\\nprint(cn_count_model.vocabulary_)\\nprint('\\n')\\n\\n# 将共生矩阵的列打上标签：\\nvoc_df=pd.DataFrame.from_dict(cn_count_model.vocabulary_, columns=['idx'], orient='index').sort_values(by=['idx'])\\ncols = list(voc_df.index)\\nprint('带标签的词-文矩阵:')\\npd.DataFrame(cnX.todense(), columns=cols)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_after, vocabulary = cn_list_seg(documents)\n",
    "\n",
    "# 再使用sklearn模块生成word-document矩阵\n",
    "min_n = 1\n",
    "max_n = 1\n",
    "cn_count_model = CountVectorizer(ngram_range=(min_n, max_n), stop_words = stopword) # default unigram model\n",
    "cnX = cn_count_model.fit_transform(documents_after)\n",
    "\n",
    "print(u'标注化（Tokenized）后的特征列表：')\n",
    "#print(cn_count_model.get_feature_names())\n",
    "print('\\n')\n",
    "\n",
    "print(u'词-文矩阵：')\n",
    "#print(cnX.todense())\n",
    "#cnXdense = cnX.todense()\n",
    "#XTX = np.dot(cnXdense.T, cnXdense)\n",
    "%time XTX = cnX.T * cnX\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "print(u'词-文矩阵对应的特征索引号（矩阵列的序号）：')\n",
    "print(cn_count_model.vocabulary_)\n",
    "print('\\n')\n",
    "\n",
    "# 将共生矩阵的列打上标签：\n",
    "voc_df=pd.DataFrame.from_dict(cn_count_model.vocabulary_, columns=['idx'], orient='index').sort_values(by=['idx'])\n",
    "cols = list(voc_df.index)\n",
    "print('带标签的词-文矩阵:')\n",
    "pd.DataFrame(cnX.todense(), columns=cols)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accor', 'always', 'amberleyhotel', 'and', 'angel', 'anyone', 'ask', 'bay', 'bed', 'body', 'bus', 'can', 'cheak', 'check', 'checkin', 'cnn', 'copy', 'ctrip', 'dfs', 'did']\n"
     ]
    }
   ],
   "source": [
    "# 再使用sklearn模块生成word-document矩阵\n",
    "min_n = 1\n",
    "max_n = 1\n",
    "cn_count_model = CountVectorizer(ngram_range=(min_n, max_n), stop_words=stopword) # default unigram model\n",
    "cnX = cn_count_model.fit_transform(documents_after)\n",
    "features = cn_count_model.get_feature_names()\n",
    "\n",
    "print(features[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _word_ngrams(tokens, stop_words=None):\n",
    "        \"\"\"Turn tokens into a sequence of n-grams after stop words filtering\"\"\"\n",
    "        # handle stop words\n",
    "        if stop_words is not None:\n",
    "            tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "        # handle token n-grams\n",
    "        min_n, max_n = 3, 3\n",
    "        if max_n != 1:\n",
    "            original_tokens = tokens\n",
    "            if min_n == 1:\n",
    "                # no need to do any slicing for unigrams\n",
    "                # just iterate through the original tokens\n",
    "                tokens = list(original_tokens)\n",
    "                min_n += 1\n",
    "            else:\n",
    "                tokens = []\n",
    "\n",
    "            n_original_tokens = len(original_tokens)\n",
    "\n",
    "            # bind method outside of loop to reduce overhead\n",
    "            tokens_append = tokens.append\n",
    "            space_join = \" \".join\n",
    "\n",
    "            for n in range(min_n,\n",
    "                            min(max_n + 1, n_original_tokens + 1)):\n",
    "                for i in range(n_original_tokens - n + 1):\n",
    "                    tokens_append(space_join(original_tokens[i: i + n]))\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accor', 'always', 'amberleyhotel', 'and', 'angel', 'anyone', 'ask', 'bay', 'bed', 'body', 'bus', 'can', 'cheak', 'check', 'checkin', 'cnn', 'copy', 'ctrip', 'dfs', 'did', 'else', 'even', 'excellent', 'floor', 'floors', 'for', 'hk', 'hour', 'house', 'housekeeping', 'iia', 'in', 'it', 'keeping', 'kfc', 'ktv', 'ld', 'lg', 'match', 'mini', 'my', 'nice', 'no', 'not', 'novotel', 'ok', 'on', 'other', 'out', 'panda', 'quarry', 'ramada', 'recommend', 'rmb', 'room', 'sasa', 'schedule', 'see', 'shop', 'shopping', 'shuttle', 'soho', 'soup', 'stay', 'suggest', 'sweet', 'taxi', 'the', 'there', 'though', 'to', 'top', 'tt', 'twin', 'upgrade', 'very', 'was', 'xx', 'ymca', '一一', '一下', '一下床', '一丝', '一个', '一些', '一件', '一份', '一伙', '一会', '一伸', '一位', '一住', '一侧', '一共', '一再', '一出', '一分钟', '一副', '一半', '一句', '一台', '一向', '一周', '一圈', '一块', '一城', '一夜', '一大', '一天', '一如既往', '一定', '一家', '一家人', '一对', '一小', '一小块', '一层', '一床', '一店', '一张', '一律', '一把', '一指', '一排', '一支', '一日', '一早', '一是', '一晚', '一望无际', '一期', '一本正经', '一朵', '一条', '一条街', '一杯', '一栋', '一根', '一楼', '一次', '一次性', '一步之遥', '一段', '一段距离', '一流', '一点', '一点点', '一片', '一班', '一瓶', '一番', '一瘸一拐', '一盒', '一直', '一看', '一碗', '一种', '一種', '一笔', '一类', '一级', '一线', '一股', '一行', '一袋', '一览无余', '一角', '一试', '一说', '一课', '一起', '一趟', '一路', '一路上', '一边', '一部', '一间', '一面', '一项', '一顿', '丁香', '万怡', '万石', '万豪', '三个', '三人间', '三倍', '三分钟', '三口', '三天', '三层', '三星', '三星级', '三晋', '三晚', '三月', '三楼', '三江', '三点', '三送', '三道', '三间房', '上个星期', '上前', '上升', '上午', '上帝', '上档次', '上楼', '上次', '上海', '上海市', '上班', '上網', '上网', '上网费', '上菜', '上要', '上订', '上车', '上面', '下午', '下午茶', '下去', '下回', '下定', '下手', '下旬', '下来', '下楼', '下楼去', '下榻', '下次', '下水', '下水道', '下班', '下着雨', '下调', '下车', '下部', '下雨', '下面', '不严', '不低', '不住', '不佳', '不便', '不值', '不像', '不入流', '不写', '不划算', '不到', '不加', '不厌其烦', '不及', '不变', '不可', '不含', '不吭声', '不多见', '不够', '不夠', '不大不小', '不大好', '不太', '不太凉', '不太好', '不太爱', '不失', '不好', '不如意', '不小', '不差', '不幸', '不快', '不怎么样', '不想', '不愧', '不成问题', '不收', '不敢', '不敢恭维', '不断', '不新', '不易', '不是太好', '不次', '不灵', '不爽', '不用', '不相称', '不知', '不符', '不算', '不紧', '不缺', '不肯', '不能容忍', '不能自己', '不行', '不论是', '不该', '不说', '不豪華', '不贵', '不足', '不足之处', '不近', '不远', '不远处', '不逊于', '不通', '不過', '不錯', '不错', '不错呀', '不难', '不靠', '不高', '专业', '专卖', '专卖店', '专线', '专车接送', '专门', '世界名牌', '世纪', '业务', '东东', '东到', '东南亚', '东方', '东方女性', '东晖楼', '东楼', '东海路', '东站', '东街口', '东西', '丝绸', '丢脸', '两三天', '两个', '两人', '两件', '两分钟', '两到', '两句', '两只', '两台', '两大', '两天', '两头', '两套', '两小块', '两张床', '两晚', '两朵', '两杯', '两次', '两点', '两瓶', '两百多', '两部', '两间', '两间房', '两面', '两顿', '並不', '个人感觉', '个别', '个子', '中午', '中取', '中国', '中國', '中央', '中央空调', '中小', '中山', '中山公园', '中州', '中帮', '中式', '中心', '中心地带', '中心地段', '中心广场', '中心站', '中意', '中旅', '中煤', '中环', '中等', '中經過', '中西', '中規', '中规中矩', '中距', '中远', '中间', '中餐', '中餐厅', '中高', '丰富', '丰田', '丰盛', '临时', '临河', '临海', '临湖', '临街', '临街房', '临近', '为主', '为佳', '为例', '主任', '主动', '主妇', '主意', '主机', '主楼', '主管', '主要', '举动', '举手投足', '久远', '之上', '之下', '之举', '之内', '之前', '之后', '之处', '之好', '之感', '之星', '之极', '之行', '之选', '之间', '之餘', '乌龙茶', '乐山', '乐心', '乘坐', '乘火车', '乘车', '九月份', '九江', '九点钟', '九龙', '九龙城', '也許', '也许', '习惯', '书籍', '买点', '乱乱的', '乱哄哄', '乳酪', '乾净', '了解', '予以', '事件', '事宜', '事情', '二三', '二十', '二十几', '二十几个', '二十块', '二号', '二字', '二星级', '二晚', '二期', '二楼', '二次', '二点', '云南', '云南白药', '云吞面', '云霄', '五一', '五个', '五买', '五分钟', '五号', '五四', '五天', '五日游', '五星', '五星级', '五点', '五脏', '亚运村', '交涉', '交警', '交通', '交通不便', '享受', '享用', '京都', '亮丽', '亲切', '亲和力', '亲善', '人住', '人员', '人士', '人多时', '人大', '人往', '人性化', '人才', '人文', '人来', '人民币', '人民广场', '人气', '人管', '人订', '人间', '什刹海', '什麼', '仁民', '仅憩', '仅猁', '仅竭', '今后', '今天', '今年', '今晚', '介绍', '仍会', '从事', '从容', '仔细', '他們', '他家', '付款', '付清', '代买', '代步', '令人', '令人满意', '以上', '以下', '以为', '以内', '以前', '以后', '以外', '以往', '以掛', '以此', '以禮', '价优', '价位', '价值', '价廉', '价廉物美', '价格', '价格便宜', '价格合理', '价格比', '价钱', '任食', '休息', '休闲', '休闲游', '众口', '众多', '优势', '优惠', '优点', '优秀', '优质服务', '优越', '优越性', '优雅', '会住', '会员', '会展', '会展中心', '会收', '会议', '会选', '传真机', '传统', '估计', '伸手不见五指', '似乎', '但床', '但离', '位于', '位置', '低些', '低点', '住入', '住宅', '住宅区', '住宅楼', '住客', '住宿', '住店', '住满', '住裕达', '住进', '住過', '体会', '体现', '体贴', '体验', '作用', '你好', '使人', '使用', '使用费', '供餐', '依山傍水', '依旧', '侧头', '侯车', '便于', '便利', '便利店', '便宜', '便捷', '促销价', '俄罗斯', '保养', '保安', '保护', '保留', '保险箱', '保龄球', '信息', '信用卡', '修好', '修桥', '修路', '俱乐部', '倍儿', '倪萍', '值得', '值得一提的是', '值班员', '假期', '偏低', '偏僻', '偏小', '偏差', '偏贵', '偏高', '做个', '做事', '做到', '做大', '做好', '做饭', '停止', '停满', '停車場', '停车', '停车场', '停车费', '停電', '停靠', '健身', '健身房', '偶有', '傅家庄', '僅僅', '像是', '價格置', '儿子', '元住', '元旦', '充满', '充电', '充电器', '先交', '先前', '先生', '先订', '先进', '光线', '免税店', '免費', '免费', '免费打', '兑成', '兜来', '入住', '入住率', '入口', '入座', '入时', '入睡', '全世界', '全城', '全天', '全市', '全是', '全湿', '全球', '全程', '全部', '全面', '八折', '八月', '八百多', '公交', '公交站', '公交线路', '公交车', '公交车站', '公司', '公园', '公寓楼', '公用', '公路', '公车', '公道', '六个', '六层', '六楼', '兰桂坊', '兰桂枋', '兰桂芳', '共住', '共计', '关上', '关掉', '关注', '关系', '关键', '关门', '兴趣', '其環境', '具全', '具有', '典雅', '兼顾', '内地', '内部', '内里', '再也', '再住', '再接再厉', '再次', '再续', '再选', '写字楼', '写意', '写订', '农村', '冤枉', '冬天', '冰水', '冰箱', '冲剂', '冲洗', '冲浪', '冲澡', '冲着', '决定', '冷水', '冷淡', '冷漠', '准备', '准确', '凉快', '凉爽', '凌晨', '凑合', '几个', '几位', '几分钟', '几口', '几号楼', '几处', '几天', '几家', '几年', '几张', '几支', '几文', '几栋', '几次', '几步', '几种', '出乎意料', '出于', '出入', '出发', '出口', '出名', '出品', '出家', '出差', '出水', '出租车', '出行', '出门', '出门时', '分别', '分到', '分离', '分量', '分鐘', '分钟', '切身感受', '划算', '列入', '刚刚', '刚到', '刚去', '刚要', '刚过', '刚进', '创意', '初期', '利用', '利益', '别住', '别具匠心', '别墅', '别扭', '别是', '别有情趣', '别涨', '别致', '刮胡子', '到位', '到弥墩', '到津滨', '到达', '制服', '刷卡', '刻意', '前一天', '前住', '前住過', '前台', '前往', '前有', '前端', '前面', '剥落', '副理', '办事', '办公台', '办好', '办手续', '办法', '办理', '功能', '加冰', '加强', '加盟店', '加装', '加钱', '务必', '动工', '动物园', '努力', '勉强', '勝在', '勤人員', '勤快', '包小包', '包括', '包河', '匆忙', '化妆棉', '北九水', '北京', '北到', '北师大', '北房', '北海', '匹萨', '匹配', '区别', '区区小事', '区域', '区有', '区较', '医院', '十一', '十元', '十全十美', '十分', '十分钟', '十多元', '十月', '十点', '千万别', '升为', '升到', '升旗仪式', '升级', '午餐', '午饭', '半个', '半到', '半夜', '半天', '半小时', '半山', '半岛', '半截', '半日', '半死', '华旗', '华苑', '华融', '华贵', '华阳', '协程', '协程定', '协议', '协议价', '协调', '協助', '单人', '单人间', '单位', '单床', '单独', '单行', '单行线', '单调', '单间', '卖场', '卖点', '南京', '南京路', '南到', '南北', '南山', '南方', '南普陀', '南湖', '博物馆', '博览', '占地面积', '卡拉', '卡片', '卫生', '卫生条件', '卫生间', '印象', '危险', '即可', '却是', '历史', '厉害', '压抑', '厕所', '厕纸', '厚实', '厚度', '原先', '原因', '原来', '原色', '厦大', '厦门', '去处', '去年', '去年底', '去过', '县城', '参加', '参展', '参观', '又续', '及时', '友善', '友好', '双人房', '双人间', '双层', '双床', '双早', '双标', '反应', '反应速度', '反映', '反正', '反馈', '发呆', '发现', '发生', '发觉', '发车', '发送', '发霉', '取境', '取暖', '取来', '取款机', '取消', '取阶', '取静', '受不了', '受到', '受宠若惊', '受骗', '变化', '变成', '口味', '口袋', '古典', '古城', '古都', '另一家', '另人', '另加', '另有', '只住', '只值', '只好', '只敢', '只求', '只能', '只花', '叫口', '叫车', '召开', '叮叮', '叮当声', '可乘', '可买', '可住', '可口', '可否', '可怕', '可怜', '可惜', '可爱', '可至', '可言', '可说', '可谓', '台借', '台前', '台湾', '台盆', '右边', '号数', '号楼', '号称', '司机', '吃住行', '吃过饭', '吃饭', '各地', '各处', '各有特色', '各类', '各项', '合力', '合口', '合并', '合庆', '合格', '合理', '合算', '合适', '吉之島', '同一', '同事', '同价位', '同去', '同学', '同志', '同意', '同感', '同样', '同级', '同胞', '同行', '名不虚传', '名义', '名人', '名字', '名气', '名牌', '名过其实', '后山', '后悔', '后海', '后者', '后要', '后边', '后门', '后面', '吐出来', '向下', '向前', '向海', '吓人', '吝啬', '含早', '听到', '听取', '听说', '启动', '吵醒', '吵闹', '吸取', '吸尘', '吸尘器', '吸引', '吸烟', '吸烟区', '吹风机', '告知', '告诉', '员工', '周全', '周到', '周四', '周围', '周围环境', '周日', '周末', '周边', '周边环境', '周遭', '周邊', '味美', '味道', '呵呵', '呼叫', '呼呼', '和煦', '和蔼', '和蔼可亲', '咖啡', '咖啡厅', '咨询', '咳嗽', '咳嗽声', '咸涩', '咽炎', '品位', '品尝', '品牌', '品种', '品质', '哈哈哈', '哈哈哈哈', '哈尔滨', '响得', '售完', '唯一', '商业中心', '商业区', '商务', '商务中心', '商务人士', '商务旅行', '商务酒店', '商品', '商场', '商城', '商店', '商旅', '商業區', '商铺', '問題', '啤酒', '啤酒节', '喜庆', '喜欢', '喜歡', '喝点', '喝热', '喧闹', '喷头', '喷泉', '嘈杂', '嘉福', '嘉逸', '嘿嘿', '噪声', '噪音', '四十分钟', '四大', '四天', '四星', '四星级', '四晚', '四楼', '四次', '四通八达', '四道', '四面', '回事', '回到', '回去', '回头一看', '回家', '回应', '回来', '回程', '回答', '回选', '回顾', '因在', '因為', '因离', '因要', '团队', '困扰', '困难', '围挡', '国内', '国内长途', '国外', '国家', '国宾', '国宾馆', '国庆', '国贸', '国际', '国际品牌', '国际展览中心', '在外', '在意', '在我看来', '地为', '地区', '地名', '地图', '地址', '地处', '地头', '地带', '地方', '地板', '地段', '地毯', '地漏', '地点', '地理', '地理位置', '地角', '地道', '地铁', '地铁站', '均匀', '坐在', '坐地铁', '坐得', '坐惯', '坐火车', '坐船', '坐落', '坐车', '块钱', '坚定不移', '垂下来', '型号', '城市', '城门', '培养', '培訓', '培训', '堂皇', '堅持', '堪称', '堵塞', '堵水', '堵车', '塌塌米', '塑料薄膜', '塔尔寺', '填写', '墙上', '墙壁', '壁纸', '壮观', '声明', '声音', '处于', '处在', '处理', '处理速度', '夏利车', '夏天', '夏日', '外出', '外国', '外国人', '外墙', '外套', '外宾', '外有', '外望', '外表', '外观', '外资', '外边', '外部', '外部环境', '外面', '多一晚', '多一点', '多人', '多余', '多元', '多功能', '多加', '多拉', '多数', '多样', '多点', '多能', '夜床', '夜总会', '夜晚', '夜景', '夜色', '夜里', '夜间', '够得上', '够星', '大上', '大众化', '大佛', '大便', '大厅', '大厦', '大商', '大块头', '大型', '大型超市', '大堂', '大大的', '大家乐', '大小', '大巴', '大巴车', '大年初一', '大床', '大房', '大打折扣', '大方', '大明湖', '大楼', '大气', '大海', '大润发', '大片', '大理', '大碍', '大窗', '大而无当', '大街', '大观园', '大连', '大连港', '大道', '大酒店', '大酒点', '大门口', '大陆', '大雨', '大面積', '大饭店', '天天', '天文', '天星', '天桥', '天气', '天河城', '天津', '天然', '天色已晚', '天花板', '太低', '太偏', '太冷', '太原', '太原市', '太吵', '太多', '太大', '太太', '太好', '太子', '太小', '太少', '太差', '太开', '太慢', '太挤', '太旧', '太早', '太有', '太湖', '太滑', '太短', '太老', '太贵', '太软', '太远', '太长', '太高', '失望', '头一回', '头上', '头发', '头衔', '夸张', '夹被', '奇怪', '奇怪的是', '奇贵', '奉來', '套房', '套装', '套间', '套餐', '奢侈', '奢华', '奥运', '奥迪', '女士', '女孩', '女性', '好不好', '好不容易', '好久', '好些', '好像', '好几个', '好几年', '好去处', '好又多', '好友', '好吃', '好听', '好多', '好太多', '好奇', '好好', '好容易', '好小叻', '好心', '好找', '好歹', '好看', '好觉', '好评', '好象', '好酒', '好长', '好长时间', '好闻', '如同', '如家', '如心', '如新', '如是', '如能', '委實', '委屈', '姜汤', '威海', '威海市', '娱乐', '嫌小', '子太硬', '存包', '存在', '存放', '学校', '孩子', '宁夏', '安全', '安庆', '安徽', '安排', '安逸', '安静', '完全', '完善', '完备', '完好', '完成', '完璧', '完美', '宏基', '定位', '定单', '定去', '定园', '定点', '宝宝', '实在', '实地', '实惠', '实用', '实际', '实际上', '客人', '客户', '客户关系', '客户经理', '客房', '客房部', '客气', '客观', '客运站', '宣传', '室内', '室内环境', '室温', '害得', '家人', '家具', '家庭', '家近', '容易', '宽大', '宽带', '宽敞', '宾至如归', '宾馆', '寄存', '密码', '富丽华', '富豪', '寒山寺', '寒磣', '对不起', '对外', '对待', '对得起', '对此', '对比', '对海', '对门', '对面', '对骂', '导致', '封门', '将园', '專業', '小且', '小东西', '小些', '小伙', '小伙子', '小便', '小卖部', '小吃', '小吃店', '小吃街', '小型', '小姐', '小孩', '小孩子', '小小', '小小的', '小屋', '小山', '小岛', '小巴', '小店', '小弟', '小得', '小心', '小时', '小时候', '小是', '小有名气', '小朋友', '小河', '小点', '小点心', '小片', '小盘', '小童', '小米粥', '小花', '小贵', '小费', '小资', '小路', '小车', '小轮', '小雨', '小青岛', '小食店', '少有', '少量', '尖东', '尖沙咀', '尚佳', '尚可', '尚差', '尚需', '尝尝', '尝试', '尤其', '就可以看', '就行', '就要', '就餐', '尴尬', '尺度', '尼敦路', '尽兴', '尽收眼底', '尾数', '层后', '层次', '居住', '居民', '居民区', '屈臣氏', '屋外', '屋子', '屋里', '展会', '展览会', '展馆', '属于', '屯门', '山上', '山东', '山庄', '山景', '山水', '山脚', '山西', '山顶', '峨眉', '崩溃', '川妹子', '川沙', '巡逻', '工人', '工作', '工作人员', '工作失误', '工作效率', '工号', '工地', '工夫', '工程师', '左右', '左手边', '巧克力', '差一', '差不太远', '差异', '差得远', '差悦华', '差点', '差距', '己经', '已帮', '已显', '已有', '已算', '已經', '已经', '巴士', '巴士站', '市中心', '市内电话', '市区', '市场', '市委', '市政府', '市景', '市民', '布局', '布置', '希尔顿', '希望', '帐号', '帝京', '带个', '带些', '带够', '带来', '带给', '带路', '席梦丝', '帮助', '帮忙', '帮送', '常住', '常客', '常驻', '幕顶', '干净', '干洗', '干活', '平台', '平吧', '平常', '平平', '平心', '平方', '平时', '平米', '平肝', '年代', '年前', '年纪', '年终', '年轻人', '年青', '并不大', '并未', '幸亏', '幸无', '幸运', '幽静', '幾分鐘', '幾十到', '幾度陽', '广场', '广州', '广泛', '床上', '床上用品', '床位', '床单', '床垫', '床房', '床有', '床沿', '床间', '庐山', '应是', '应有尽有', '应该', '底部', '店到', '店前', '店去', '店离', '店里', '度假', '度假型', '度假村', '座位', '庭院', '康乐', '延住', '延期', '延路', '延长', '建材', '建筑', '建議', '建议', '建设', '开业', '开了个', '开关', '开冷', '开发区', '开封', '开得', '开心', '开放', '开水', '开穿', '开窗', '开箱', '开线', '开车', '开通', '开门', '开阔', '异味', '异国情调', '异常', '异物', '引发', '引导', '弟兄们', '张小床', '张床', '张裕', '弥敦道', '弥补', '強求', '弹簧', '强化', '强烈建议', '强烈推荐', '归照', '归航', '当地', '当地人', '当大', '当天', '当局', '当心', '当日', '当时', '当晚', '当面', '形容', '形形色色', '形象大使', '彩条', '影响', '往下', '往前走', '往来', '往来于', '往返', '待人', '待遇', '很会', '很值', '很厚', '很多年', '很大', '很小', '很差', '很强', '很快', '很怪', '很早以前', '很旺', '很棒', '很气', '很漂亮', '很灵', '很破', '很累', '很脏', '很贵', '很足', '很近', '很长', '很难', '徒步', '得出', '得到', '得来', '得知', '得象', '得闲', '微笑', '心中', '心地', '心差', '心态', '心情', '心態', '心有余悸', '心理准备', '心里', '必住', '必答', '必要', '忍忍', '忍无可忍', '忘带', '忘记', '忙碌', '快捷', '快樂', '快活', '快线', '快轨', '快递', '快餐店', '忽冷忽热', '忽略', '怀疑', '态度', '怡东', '怡和', '怡情', '急忙', '性价比', '性價', '怪味', '总体', '总体水平', '总体而言', '总共', '总台', '总在', '总店', '总是', '总机', '总理', '总的来讲', '总站', '总算', '总经理', '总结', '总能', '总部', '恐怖', '恒基', '恰當', '恶心', '悄悄', '悦华', '悦来', '悬崖', '情侣', '情况', '情况不明', '情愿', '情景', '情调', '惊喜', '惊扰', '惊讶', '惟独', '惠康', '惡劣', '惨不忍睹', '惬意', '想不到', '想不通', '想像中', '想到', '想必', '想想', '想法', '想要', '想象', '想起', '愉快', '意义', '意外', '意思', '意见', '意识', '感冒', '感到', '感动', '感动不已', '感動', '感受', '感受一下', '感同身受', '感想', '感覺', '感觉', '感觉得到', '感触', '感谢', '愧对', '愿意', '態度', '慢性', '憋屈', '應該', '成为', '成就', '成标间', '成正比', '成熟', '我們', '我加', '我姐', '我定', '我带', '我来', '我要', '我订', '我过', '或茵胆', '户外', '房价', '房前', '房务', '房卡', '房型', '房大', '房子', '房屋', '房床', '房时', '房给', '房订', '房费', '房里', '房間', '房门', '房间', '房间内', '房难订', '所急', '所有', '所说', '所谓', '所驱', '手机', '手机号', '手机电池', '手续', '才定', '打不开', '打个', '打出', '打开', '打扫', '打扫卫生', '打扮', '打扰', '打招呼', '打死', '打法', '打渔', '打烊', '打理', '打电话', '打算', '打表', '打车', '打高尔夫', '执勤', '找到', '找遍', '承认', '技術', '把守', '把握', '投入', '折算', '抢钱', '护国寺', '报刊', '报国寺', '报摊', '报纸', '披巾', '抱怨', '抱有', '抱歉', '抵价券', '抹杀', '押金', '担保', '担心', '拆迁', '拉上', '拉开', '拉開', '拍摄', '拐右', '拐角处', '拒绝', '拖延', '拖拉', '拖鞋', '招呼', '招商', '招待所', '拜访', '拥堵', '拥挤', '拼成', '拼车', '拿出', '拿来', '挂牌', '指定', '指示', '按摩', '挑剔', '挑选', '挥之不去', '挺不错', '挺全', '挺大', '挺好吃', '挺快', '挺火', '挺热', '挺舒服', '挺远', '换乘', '换到', '换后', '换房', '换楼', '换气', '换汇', '换算', '授权', '掉线', '掏钱', '排档', '排水', '排队', '排除', '接到', '接受', '接客', '接待', '接收', '接机', '接水', '接站', '接线板', '接车', '接近', '接送', '接送车', '推介', '推开', '推荐', '提了', '提交', '提供', '提出', '提前', '提升', '提着', '提示', '提醒', '提高', '插头', '插座', '搞定', '搞错', '携城', '携带', '携程', '携程网', '摄影', '摆在', '摆放', '摆设', '摊主', '摔了一跤', '摩登', '撑开', '操作', '攜程', '支付', '支持', '支架', '收入', '收到', '收取', '收好', '收拾', '收看', '收视', '收费', '收走', '收钱', '收银', '改住', '改变', '改名', '改善', '改水单', '改过来', '改进', '放下', '放在', '放心', '放手', '放新', '放松', '放水', '放眼望去', '政府', '故障', '效果', '效率', '敏感', '教唆', '敞亮', '敞舒適', '散奥祥', '散散步', '散步', '敦煌', '敬业', '数字电视', '数码产品', '数码港', '敲诈', '敲门', '整个', '整体', '整套', '整整齐齐', '整洁', '整点', '整理', '整齐', '文件', '文化', '文字', '文庙', '料理', '斜对面', '新华', '新城', '新城区', '新大陆', '新开', '新来', '新界', '新翼', '新街口', '新装', '新装修', '新鲜', '方便', '方便面', '方向', '方式', '方方面面', '方法', '方面', '施工', '旁边', '旅友', '旅客', '旅店', '旅游', '旅游景点', '旅行', '旅行团', '旅行者', '旋转', '旗下', '无人不知', '无处可去', '无太大', '无意', '无意间', '无愧于', '无所谓', '无扬', '无敌', '无法', '无法忍受', '无烟', '无疑', '无知', '无线', '无论是', '无证', '无话可说', '无锡', '日住', '日出', '日小假', '日常', '日文', '日期', '日本', '日用品', '日至', '旧些', '旧旧', '旧款', '早上', '早上好', '早就', '早已', '早晚', '早晨', '早点', '早睡', '早茶', '早起', '早醒', '早餐', '早饭', '时代广场', '时住', '时光', '时冷时热', '时刻', '时尚', '时想', '时才', '时有', '时机', '时段', '时用', '时要', '时说', '时问', '时间', '时间延迟', '时隔', '旺季', '旺角', '昆明', '明亮', '明天', '明年', '明日', '明明', '明显', '明牌', '明白', '昏暗', '星光', '星星', '星期一', '星期六', '星湖', '星級', '星级', '星级宾馆', '星要', '星里', '春暖花开', '春节', '是不是', '是否', '是因为', '是非', '显得', '显然', '显示器', '显示屏', '時候', '晃荡', '晒太阳', '晓得', '晚上', '晚安', '晚点', '晚间', '晚餐', '普通', '普通话', '景区', '景房', '景点', '景美', '景色', '景观', '景象', '暂时', '暑假', '暖和', '暖气', '暖气片', '暗暗', '暗示', '更上一层楼', '更不愁', '更好', '更换', '更新', '更是', '更近', '曾住', '曾经', '替个', '替代', '最后', '最多', '最大', '最好', '最新', '最深', '最深处', '最绝', '最美', '最贵', '最赞', '最起码', '最近', '最长', '最高', '月份', '月初', '月底', '有个', '有人', '有吉之岛', '有名', '有大', '有大床', '有天', '有如', '有家', '有山', '有待', '有所提高', '有所改善', '有效率', '有方', '有时', '有晨泳', '有景', '有梅', '有段', '有求', '有没有', '有油点', '有海', '有点', '有点像', '有点累', '有着', '有礼', '有禮地', '有种', '有股', '有误', '有车', '有轨电车', '有过', '有重', '有静', '有飘窗', '有點', '朋友', '朋友家', '服务', '服务业', '服务中心', '服务台', '服务员', '服务周到', '服务态度', '服务水平', '服务生', '服务行业', '服务设施', '服务质量', '服务费', '服務', '服務員', '服務員為', '服務員還', '服務態度', '服用', '朗庭', '望远镜', '朝南', '朝右', '朝向', '朝阳', '朝鲜', '期间', '木头', '木板', '木炭', '未眠', '未退', '本来', '本次', '朱熔基', '朴实', '机会', '机关', '机器声', '机场', '机票', '机车', '杂志', '李南滨路', '李朝', '条件', '来到', '来回', '来电', '来自', '来说', '松软', '板上', '极力推荐', '极差', '极贵', '枕头', '果汁', '果盘', '果篮', '某某', '柜台', '柜后', '柠檬茶', '查找', '查看', '查询', '标准', '标准配置', '标准间', '标志', '标房', '标示', '标间', '栈桥', '树立', '样子', '核实', '根本', '格调', '桌上', '桌子', '桌椅', '桑拿', '档次', '桥到', '桶装', '桶装水', '检查', '森林', '椅子', '植得', '植物园', '楼上', '楼下', '楼层', '楼市', '楼梯', '楼道', '楼顶', '概念', '榴莲', '標準', '横向', '機構', '橡木', '檔次', '欠缺', '次住', '次日', '次晨泳', '欢迎', '欣赏', '欧式', '款式', '歌舞', '正中', '正在', '正大', '正好', '正宗', '正对', '正常', '正式', '正是', '正朝', '正赶上', '正门', '此次', '此起彼伏', '步行', '步行街', '步骤', '歧视', '死板', '殊堪嘉許', '残留', '殡仪馆', '殷勤', '每个', '每人', '每位', '每周三', '每天', '每天晚上', '每家', '每年', '每房', '每晚', '每月', '每次', '每间房', '比不上', '比住', '比做', '比悦华', '比标间', '比汉庭', '比較', '比较', '比较复杂', '比较满意', '毛巾', '毛病', '毛笔', '毛衣', '毛裤', '民居', '民族风情', '气味', '气息', '气愤', '气氛', '气派', '气韵', '水仙花', '水准', '水力', '水壶', '水平', '水散', '水果', '水果摊', '水果盘', '水温', '水量', '水龙头', '永远', '汉口', '汕头', '江苏', '江边', '污渍', '污迹', '汤山', '汽车', '汽车站', '沈阳', '沐浴', '沐浴露', '沒有', '沒泡', '沙发', '沙发床', '沙嘴', '沙滩', '沙田', '沙發', '沟通', '没买成', '没事', '没人', '没什么', '没住', '没关', '没到', '没大床', '没套', '没得说', '没想到', '没房', '没睡', '没说的', '河南', '河畔', '河鲜', '油污', '油漆', '油麻', '沿海', '沿途', '泉城', '泉州', '泉州市', '泉酒', '泊车', '法式', '泛海', '泡吧', '泡面', '注意', '注明', '注重', '泳池', '洁净', '洋货', '洋酒', '洗个', '洗发膏', '洗发露', '洗完', '洗手间', '洗漱', '洗漱间', '洗澡', '洗澡水', '洗澡间', '洗脸盆', '洗衣', '洗衣店', '洗衣服', '洗面盆', '洛阳', '洲际', '活动', '活该', '流畅', '浅水湾', '济南', '浓烈', '浓重', '浙江', '浪漫', '浪费', '浴室', '浴室用品', '浴缸', '浴袍', '海天', '海宁', '海带', '海景', '海景房', '海标', '海水', '海河', '海洋公园', '海港', '海滩', '海边', '海逸', '海都', '海风', '海鲜', '海鲜城', '海鲜酒楼', '涂个', '消夜', '消毒', '消费', '消费水平', '涉嫌', '润肤霜', '涨潮', '液晶', '液晶屏', '液晶电脑', '液晶电视', '淋坏', '淋浴', '淋浴房', '淑女', '淡季', '深刻', '混乱', '清凉', '清凉寺', '清幽', '清新', '清早', '清晰', '清楚', '清泥洼', '清洁', '清洁工', '清清楚楚', '清澈', '清爽', '清理', '清醒', '清静', '清香', '渔港', '渡假', '温和', '温度', '温情', '温暖', '温泉', '温泉水', '温馨', '港元', '港币', '港澳', '游个泳', '游回来', '游客', '游泳', '游泳池', '游泳馆', '游玩', '游艇', '游览', '湖州', '湖州市', '湖景大床', '湖笔', '湖边', '湮散', '準間', '溫文', '溫泉', '滇腔', '满好', '满意', '满足', '滿意', '漂亮', '漂浮', '漏水', '演奏', '漫步', '漳州', '潮气', '火车', '火车票', '火车站', '火锅', '灭蚊器', '灯光', '灯光设计', '灵活', '炮台', '点到', '点前', '点名', '点多', '点多到', '点心', '点点', '点至', '点评', '点钟', '烘干', '烟台', '烟台山', '烟味', '烟酒', '烧来', '烧水', '烧烤', '热得', '热心', '热情', '热情周到', '热水', '热水器', '热水袋', '热醒', '热闹', '热风', '焦点', '照常', '照相机', '照顾', '熄灯', '熟悉', '熱情', '熱茶', '燕窝', '爆慢', '爱人', '爱理不理', '父女', '片仔癀', '牌号', '牌子', '牙刷', '牛奶', '牛气', '牛肉', '牡丹', '物价', '物品', '物有所值', '物美', '物美价廉', '物超所值', '牵强', '特产', '特别', '特别强调', '特别感谢', '特地', '特多', '特意', '特点', '特色', '特色小吃', '特色菜', '特质', '犹豫', '狂喜', '狠心', '独立', '狭小', '狼狈', '王一品', '王府井', '王杰', '玩得', '玩耍', '玫瑰', '环境', '环境优美', '环境保护', '现代', '现在', '现象', '现金', '玻璃', '玻璃幕墙', '班机', '班次', '班车', '理念', '理想', '理由', '理解', '瑕疵', '瑜珈', '環境', '甜品', '甜品店', '甜美', '生动', '生就', '生意', '生日', '生活', '生记', '用具', '用品', '用手', '用过', '用餐', '田园', '申明', '申请', '电冰箱', '电吹风', '电器', '电控', '电梯', '电梯间', '电脑', '电脑桌', '电视', '电视塔', '电视机', '电话', '电话费', '电车', '电车站', '畅谈', '畅通', '留下', '留园', '留在', '留好', '留意', '留言', '略显', '當然', '疑惑', '疑祥', '疑问请', '疲劳', '痊愈', '痛苦', '登記時', '登记', '發電外', '發電機', '白天', '白问', '百佳', '百元', '百叶窗', '百家', '百樂來', '百米', '百货商场', '百问不厌', '的士', '的紅', '的關', '皇冠', '皇后', '皇帝', '皇潮', '皮夹', '皱着眉头', '盆在', '盛开', '目前', '盯上', '直到', '直接', '直白', '直达', '直达车', '直面', '相信', '相关', '相对', '相对来说', '相差', '相应', '相当', '相当于', '相比', '相符', '相送', '相邻', '省事', '省点', '省钱', '看不到', '看出', '看到', '看得出', '看得出来', '看海', '看电视', '看看', '看着', '看见', '看过', '真不叫', '真不错', '真切', '真实', '真心诚意', '真是', '真是太', '真有', '真正', '真爽', '真的', '真诚', '眼光', '眼睛', '着想', '睡不着', '睡得', '睡懒觉', '睡眠', '睡着', '睡觉', '知名度', '知道', '短信', '短途', '石家庄', '矿泉水', '码头', '破例', '破旧', '破烂', '破财', '破败', '硬件', '确实', '确认', '碧波', '碰到', '確實', '磨砂玻璃', '礼品', '礼宾', '礼拜', '礼貌', '福州', '福建', '禮儀', '离上', '离东百', '离后', '离太', '离店', '离开', '离新', '离海', '离琶洲', '离门', '私人', '私密', '种类', '科学馆', '秦皇岛', '积水', '积水潭', '称为', '称作', '称赞', '稍差', '稍微', '稍慢', '稍旧', '稍贵', '稍远', '稳定', '空气', '空气流通', '空气清新', '空調', '空调', '空间', '穿梭', '穿过', '突出', '窗口', '窗台上', '窗外', '窗头', '窗子', '窗帘', '窗户', '窗簾', '窗边', '窝心', '立即', '立着', '竞争力', '竭船', '端庄', '竹炭', '笑容', '笑脸', '笔记本', '符合', '第一', '第一天', '第一条', '第一次', '第一流', '第三', '第二天', '第二次', '第四', '笼头', '等于', '等候', '等待', '答复', '答案', '签约', '简但', '简单', '简洁', '简约', '简陋', '算了', '算大', '算好', '算新', '算是', '算高', '管家', '管理', '管理水平', '箱包', '簡直', '粤式', '粥品', '精神', '精致', '糖浆', '糟糕', '系统', '素菜', '素质', '索取', '索菲特', '紧张', '紧靠', '累个', '給人', '綠化', '緊張', '繁华', '红头', '红旗路', '红灯笼', '红砖', '红茶', '级别', '纸鹤', '线路', '练习场', '细察', '细心', '细致', '细节', '终点', '经历', '经济', '经济型', '经理', '经营', '经贸', '经路', '经路店', '经验', '结帐', '结束', '结构', '结账', '给予', '给我发', '络腮胡子', '绝佳', '继续', '续订', '维修', '维多利亚', '维护', '维港', '综合', '绿豆汤', '缆车', '编写', '缘故', '缺乏', '缺少', '缺点', '网上', '网友', '网吧', '网络', '网评', '网速', '网速慢', '网页', '罗湖', '罢工', '羊杂', '美中不足', '美丽', '美味', '美国', '美好', '美心', '美景', '美极了', '美梦', '美的', '美食', '美食街', '群山', '羽绒被', '翻新', '老人', '老先生', '老公', '老化', '老城区', '老外', '老妈', '老婆', '老字号', '老实', '老年', '老式', '老态', '老旧', '老款', '老爷爷', '老牌', '老虎滩', '考察', '考慮', '考虑', '考虑一下', '而論', '耐心', '耽搁', '耽误时间', '聊天', '职业化', '联系', '聚会', '肇庆', '肇庆市', '肉片', '肥皂', '肯定', '胃病', '胃药', '胃黏膜', '背山面', '胡同', '胶囊', '能住', '能力', '能否', '能回', '能够', '能比', '脚面', '腿脚', '膏药', '自动扶梯', '自助', '自助游', '自助餐', '自助餐厅', '自带', '自然', '自然环境', '自然风', '自由', '自行车', '自驾', '自驾游', '自驾车', '臭气熏天', '至上', '至少', '致命', '舍得', '舒心', '舒服', '舒畅', '舒适', '航班', '航空', '船票', '船腔挲', '船菜', '良好', '色调', '艺术性', '艾美', '节假日', '花园', '花园式', '花园街', '花園', '花样', '花洒', '花生米', '花盆', '花花', '花花草草', '苍蝇', '苦心', '英国', '英式', '范围', '茶水', '茶餐厅', '荃湾', '荒凉', '药店', '药片', '莫高窟', '莲香楼', '获赠', '菜品', '菜市场', '菜汤', '菜肴', '营业', '营业时间', '落伍', '落地窗', '落差', '著作', '著名', '葡萄酒', '董事长', '蒙蒙细雨', '蓝天', '蔚蓝', '蔡陆线', '藏独', '蘑菇', '虎丘', '號和', '號樓', '虹口', '虽不像', '虽小', '虽达', '蚊子', '蛋糕', '蛮高', '蜜月旅行', '行带', '行政', '行李', '行李房', '行李架', '行程', '行走', '街上', '街口', '街头', '街道', '衛生潔淨', '衛生間', '衡量', '衢州', '衣服', '衣柜', '补上', '表扬', '表演', '表现', '表示歉意', '被动', '被单', '被子', '被扣', '被褥', '装修', '装备', '装潢', '装璜', '装袋', '装设', '装饰', '裝修', '裝修過', '裡用', '裤兜', '西到', '西北', '西单', '西南', '西四', '西坝', '西宁', '西宁市', '西式', '西方', '西楼', '西环', '西直门', '西藏', '西街', '西路', '西门子', '西餐', '西餐厅', '要不得', '要出', '要定', '要收', '要求', '要花费', '覆盖', '視野空間', '親切', '覺得', '见不着', '见到', '见效', '观景', '观看电视', '规定', '规模', '规范', '视而不见', '视野', '觉得', '角度', '角落', '解决', '解决困难', '解决问题', '解放北路', '解渴', '解答', '言语', '設備', '設施', '調試', '謝謝', '警察', '警惕', '警觉性', '计较', '订一晚', '订单', '订如家', '订房', '订票', '订过', '订餐', '认为', '认真', '认识', '讨厌', '训练有素', '记住', '记录', '记得', '记性', '讲究', '许多', '设备', '设施', '设有', '设法', '设置', '设计', '访客', '证明', '评价', '评论', '试图', '试试', '试试看', '询问', '该店', '该换', '该死', '详细', '语气', '诱导', '说不过去', '说个', '说声', '说好', '说实话', '说得过去', '说明', '说离', '说话', '说起', '请勿打扰', '诸多', '调到', '调整', '调节', '调解', '谈不上', '谈谈', '谢谢', '豁口', '豆腐', '豆腐干', '象个', '豪华', '豪華標', '購物區', '负责', '质数', '质素', '质量', '购买', '购物', '购物中心', '购物点', '贴心', '贴着', '贵上', '贵在', '贵太', '贵宾楼', '费时', '费用', '资料', '赏心悦目', '赘述', '赚钱', '赠送', '赤柱', '赫赫', '走上', '走出', '走动', '走廊', '走法', '走走', '走路', '走过', '走进', '赶上', '赶巧', '赶紧', '起到', '起床', '起步', '起步价', '起码', '超一流', '超值', '超出', '超前', '超多', '超大', '超好', '超市', '超慢', '超爽', '超级', '超赞', '超软', '超过', '超近', '足够', '足夠', '跑上来', '跑马', '跑马地', '距离', '跟不上', '跟前', '路上车', '路况', '路到', '路口', '路标', '路段', '路程', '路窄', '路线', '路线图', '路费', '路车', '路边', '路过', '路面', '跳闸', '踏實', '身体', '躺上去', '車程', '车位', '车到', '车场', '车头', '车库', '车快', '车接', '车程', '车站', '车费', '车里', '车门', '轨道交通', '转角', '转身', '轮渡', '软件', '软硬', '软饮', '轻声', '较为简单', '较全', '较大', '较差', '较散', '较晚', '较近', '较远', '辉映', '辉煌', '输错', '边上', '边能', '达到', '达车', '迅速', '过厅', '过去', '过夜', '过得去', '过时', '过来', '过节', '过账', '过车', '迎宾', '迎面', '运动', '运气', '近在咫尺', '近期', '近海', '近火車', '还会', '还会来', '还会订', '还会选', '还好', '还算', '还给', '还花', '还要', '还贵', '还过得去', '还选', '这位', '这家', '这才', '这方面', '这是', '这次', '这段', '这点', '这种', '这间', '这项', '进一步', '进入', '进出', '进口', '进屋', '进步', '进站', '进行', '进门', '进餐', '远不如', '远处', '远洲', '远点', '远眺', '远远', '连卡佛', '连接', '迟到', '迟钝', '迪士尼', '迪斯尼', '迷你', '迷宫', '迷糊', '退房', '送上', '送入', '送到', '送机', '送来', '送餐', '适中', '适合', '适时地', '选了', '选在', '选择', '透过', '這一項', '這家', '這次', '通常', '通病', '通知', '通话', '通达', '通风', '通风管道', '逛街', '逛逛', '速度', '速度慢', '造成', '遇上', '遇到', '過於用', '道歉', '道理', '道路', '道逢', '遗憾', '遗漏', '遥控器', '遥远', '適中', '遺憾', '避免', '避暑', '還是', '還有', '那一刻', '那位', '那天', '那条', '那片', '那种', '邮件', '邮局', '邻湖', '邻近', '郁闷', '郊区', '郑州', '部分', '都市', '配套', '配有', '配置', '配送', '酒吧', '酒吧街', '酒家', '酒巴', '酒店', '酒店设备', '酒店设施', '酒楼', '酒气', '酸酸的', '醉醺醺', '醒目', '采光', '采用', '里外', '里头', '里望', '里面', '重庆', '重新', '重装', '重要', '重视', '野外', '野花', '金华', '金卡', '金嗓子喉宝', '金水路', '金玉', '金紫荆', '金融中心', '金钟', '金门', '金额', '针线包', '钓鱼', '钟头', '钢琴演奏', '钥匙', '铜锣湾', '银子', '银川', '银座', '银联', '银联卡', '销售部', '锁好', '错误', '锦江', '键盘', '镜子', '长住', '长廊', '长时间', '长春', '长江', '长话', '长途', '长途电话', '长途车', '開心', '门前', '门卫', '门口', '门外', '门童', '门铃', '问一答', '问候', '问卷调查', '问路', '问过', '问问', '问题', '间隔', '闹中取静', '闹市', '闹市区', '阳台', '阳朔', '阴霾', '阿三', '阿姨', '阿拉', '附近', '陆家嘴', '陈列', '陈旧', '降低', '降雪', '陽朔', '随便', '随口', '随叫随到', '随处可见', '随时', '隔壁', '隔开', '隔海', '隔离', '隔音', '隧道', '难以', '难吃', '难看', '难闻', '难题', '雄厚实力', '集团', '集散', '雖然', '離大', '雨伞', '雨水', '雪茄', '零距离', '零食', '電力', '需求', '需要', '震撼', '霉味', '露台', '露天', '青山绿水', '青岛', '青年会', '青春', '青海', '青菜', '静心', '非常感谢', '非常适合', '非常高兴', '靠山', '靠江', '靠海', '靠近', '面临', '面向', '面对', '面巾纸', '面带微笑', '面是', '面海', '面积', '面積', '韩国', '韩式', '音乐', '顧客', '顶楼', '项链', '顺便', '顺利', '顺道', '顾客', '预先', '预定', '预期', '预留', '预订', '预订单', '领导人', '领略', '领走', '颜色', '额外', '颠倒黑白', '風景', '風機給', '风光', '风吹', '风味', '风大则', '风扇', '风景', '风格', '风范', '风趣', '风采', '飘飘', '飞天', '飞快', '飞机', '飞机场', '飞机票', '食品', '食物', '餐具', '餐券', '餐厅', '餐点', '餐饮', '餐饮部', '餐馆', '饭店', '饭菜', '饮料', '饮用水', '饮茶', '饼干', '馊臭', '首场', '首屈一指', '首日', '首选', '香格里拉', '香港', '香港站', '香港艺术馆', '香舌', '马可', '马桶', '马自达', '马路', '马路上', '马马虎虎', '驴友', '驶向', '驾车', '驾车者', '骗人', '骚扰', '骚扰电话', '高些', '高兴', '高尔夫', '高尔夫球场', '高尚', '高峰', '高效率', '高登', '高级', '高速', '高高', '高高的', '鲜花', '鳕鱼', '鸟瞰', '鸡尾酒', '麦凯乐', '麦当劳', '麻烦', '黄山', '黄河', '黄金周', '黑椒', '黑车', '點就', '鼓励', '鼓浪屿', '齐全', '齐备', '龙城', '龙头', '龙门石窟']\n",
      "['accor always amberleyhotel', 'always amberleyhotel and', 'amberleyhotel and angel', 'and angel anyone', 'angel anyone ask', 'anyone ask bay', 'ask bay bed', 'bay bed body', 'bed body bus', 'body bus can', 'bus can cheak', 'can cheak check', 'cheak check checkin', 'check checkin cnn', 'checkin cnn copy', 'cnn copy ctrip', 'copy ctrip dfs', 'ctrip dfs did', 'dfs did else', 'did else even', 'else even excellent', 'even excellent floor', 'excellent floor floors', 'floor floors for', 'floors for hk', 'for hk hour', 'hk hour house', 'hour house housekeeping', 'house housekeeping iia', 'housekeeping iia in', 'iia in it', 'in it keeping', 'it keeping kfc', 'keeping kfc ktv', 'kfc ktv ld', 'ktv ld lg', 'ld lg match', 'lg match mini', 'match mini my', 'mini my nice', 'my nice no', 'nice no not', 'no not novotel', 'not novotel ok', 'novotel ok on', 'ok on other', 'on other out', 'other out panda', 'out panda quarry', 'panda quarry ramada', 'quarry ramada recommend', 'ramada recommend rmb', 'recommend rmb room', 'rmb room sasa', 'room sasa schedule', 'sasa schedule see', 'schedule see shop', 'see shop shopping', 'shop shopping shuttle', 'shopping shuttle soho', 'shuttle soho soup', 'soho soup stay', 'soup stay suggest', 'stay suggest sweet', 'suggest sweet taxi', 'sweet taxi the', 'taxi the there', 'the there though', 'there though to', 'though to top', 'to top tt', 'top tt twin', 'tt twin upgrade', 'twin upgrade very', 'upgrade very was', 'very was xx', 'was xx ymca', 'xx ymca 一一', 'ymca 一一 一下', '一一 一下 一下床', '一下 一下床 一丝', '一下床 一丝 一个', '一丝 一个 一些', '一个 一些 一件', '一些 一件 一份', '一件 一份 一伙', '一份 一伙 一会', '一伙 一会 一伸', '一会 一伸 一位', '一伸 一位 一住', '一位 一住 一侧', '一住 一侧 一共', '一侧 一共 一再', '一共 一再 一出', '一再 一出 一分钟', '一出 一分钟 一副', '一分钟 一副 一半', '一副 一半 一句', '一半 一句 一台', '一句 一台 一向', '一台 一向 一周', '一向 一周 一圈', '一周 一圈 一块', '一圈 一块 一城', '一块 一城 一夜', '一城 一夜 一大', '一夜 一大 一天', '一大 一天 一如既往', '一天 一如既往 一定', '一如既往 一定 一家', '一定 一家 一家人', '一家 一家人 一对', '一家人 一对 一小', '一对 一小 一小块', '一小 一小块 一层', '一小块 一层 一床', '一层 一床 一店', '一床 一店 一张', '一店 一张 一律', '一张 一律 一把', '一律 一把 一指', '一把 一指 一排', '一指 一排 一支', '一排 一支 一日', '一支 一日 一早', '一日 一早 一是', '一早 一是 一晚', '一是 一晚 一望无际', '一晚 一望无际 一期', '一望无际 一期 一本正经', '一期 一本正经 一朵', '一本正经 一朵 一条', '一朵 一条 一条街', '一条 一条街 一杯', '一条街 一杯 一栋', '一杯 一栋 一根', '一栋 一根 一楼', '一根 一楼 一次', '一楼 一次 一次性', '一次 一次性 一步之遥', '一次性 一步之遥 一段', '一步之遥 一段 一段距离', '一段 一段距离 一流', '一段距离 一流 一点', '一流 一点 一点点', '一点 一点点 一片', '一点点 一片 一班', '一片 一班 一瓶', '一班 一瓶 一番', '一瓶 一番 一瘸一拐', '一番 一瘸一拐 一盒', '一瘸一拐 一盒 一直', '一盒 一直 一看', '一直 一看 一碗', '一看 一碗 一种', '一碗 一种 一種', '一种 一種 一笔', '一種 一笔 一类', '一笔 一类 一级', '一类 一级 一线', '一级 一线 一股', '一线 一股 一行', '一股 一行 一袋', '一行 一袋 一览无余', '一袋 一览无余 一角', '一览无余 一角 一试', '一角 一试 一说', '一试 一说 一课', '一说 一课 一起', '一课 一起 一趟', '一起 一趟 一路', '一趟 一路 一路上', '一路 一路上 一边', '一路上 一边 一部', '一边 一部 一间', '一部 一间 一面', '一间 一面 一项', '一面 一项 一顿', '一项 一顿 丁香', '一顿 丁香 万怡', '丁香 万怡 万石', '万怡 万石 万豪', '万石 万豪 三个', '万豪 三个 三人间', '三个 三人间 三倍', '三人间 三倍 三分钟', '三倍 三分钟 三口', '三分钟 三口 三天', '三口 三天 三层', '三天 三层 三星', '三层 三星 三星级', '三星 三星级 三晋', '三星级 三晋 三晚', '三晋 三晚 三月', '三晚 三月 三楼', '三月 三楼 三江', '三楼 三江 三点', '三江 三点 三送', '三点 三送 三道', '三送 三道 三间房', '三道 三间房 上个星期', '三间房 上个星期 上前', '上个星期 上前 上升', '上前 上升 上午', '上升 上午 上帝', '上午 上帝 上档次', '上帝 上档次 上楼', '上档次 上楼 上次', '上楼 上次 上海', '上次 上海 上海市', '上海 上海市 上班', '上海市 上班 上網', '上班 上網 上网', '上網 上网 上网费', '上网 上网费 上菜', '上网费 上菜 上要', '上菜 上要 上订', '上要 上订 上车', '上订 上车 上面', '上车 上面 下午', '上面 下午 下午茶', '下午 下午茶 下去', '下午茶 下去 下回', '下去 下回 下定', '下回 下定 下手', '下定 下手 下旬', '下手 下旬 下来', '下旬 下来 下楼', '下来 下楼 下楼去', '下楼 下楼去 下榻', '下楼去 下榻 下次', '下榻 下次 下水', '下次 下水 下水道', '下水 下水道 下班', '下水道 下班 下着雨', '下班 下着雨 下调', '下着雨 下调 下车', '下调 下车 下部', '下车 下部 下雨', '下部 下雨 下面', '下雨 下面 不严', '下面 不严 不低', '不严 不低 不住', '不低 不住 不佳', '不住 不佳 不便', '不佳 不便 不值', '不便 不值 不像', '不值 不像 不入流', '不像 不入流 不写', '不入流 不写 不划算', '不写 不划算 不到', '不划算 不到 不加', '不到 不加 不厌其烦', '不加 不厌其烦 不及', '不厌其烦 不及 不变', '不及 不变 不可', '不变 不可 不含', '不可 不含 不吭声', '不含 不吭声 不多见', '不吭声 不多见 不够', '不多见 不够 不夠', '不够 不夠 不大不小', '不夠 不大不小 不大好', '不大不小 不大好 不太', '不大好 不太 不太凉', '不太 不太凉 不太好', '不太凉 不太好 不太爱', '不太好 不太爱 不失', '不太爱 不失 不好', '不失 不好 不如意', '不好 不如意 不小', '不如意 不小 不差', '不小 不差 不幸', '不差 不幸 不快', '不幸 不快 不怎么样', '不快 不怎么样 不想', '不怎么样 不想 不愧', '不想 不愧 不成问题', '不愧 不成问题 不收', '不成问题 不收 不敢', '不收 不敢 不敢恭维', '不敢 不敢恭维 不断', '不敢恭维 不断 不新', '不断 不新 不易', '不新 不易 不是太好', '不易 不是太好 不次', '不是太好 不次 不灵', '不次 不灵 不爽', '不灵 不爽 不用', '不爽 不用 不相称', '不用 不相称 不知', '不相称 不知 不符', '不知 不符 不算', '不符 不算 不紧', '不算 不紧 不缺', '不紧 不缺 不肯', '不缺 不肯 不能容忍', '不肯 不能容忍 不能自己', '不能容忍 不能自己 不行', '不能自己 不行 不论是', '不行 不论是 不该', '不论是 不该 不说', '不该 不说 不豪華', '不说 不豪華 不贵', '不豪華 不贵 不足', '不贵 不足 不足之处', '不足 不足之处 不近', '不足之处 不近 不远', '不近 不远 不远处', '不远 不远处 不逊于', '不远处 不逊于 不通', '不逊于 不通 不過', '不通 不過 不錯', '不過 不錯 不错', '不錯 不错 不错呀', '不错 不错呀 不难', '不错呀 不难 不靠', '不难 不靠 不高', '不靠 不高 专业', '不高 专业 专卖', '专业 专卖 专卖店', '专卖 专卖店 专线', '专卖店 专线 专车接送', '专线 专车接送 专门', '专车接送 专门 世界名牌', '专门 世界名牌 世纪', '世界名牌 世纪 业务', '世纪 业务 东东', '业务 东东 东到', '东东 东到 东南亚', '东到 东南亚 东方', '东南亚 东方 东方女性', '东方 东方女性 东晖楼', '东方女性 东晖楼 东楼', '东晖楼 东楼 东海路', '东楼 东海路 东站', '东海路 东站 东街口', '东站 东街口 东西', '东街口 东西 丝绸', '东西 丝绸 丢脸', '丝绸 丢脸 两三天', '丢脸 两三天 两个', '两三天 两个 两人', '两个 两人 两件', '两人 两件 两分钟', '两件 两分钟 两到', '两分钟 两到 两句', '两到 两句 两只', '两句 两只 两台', '两只 两台 两大', '两台 两大 两天', '两大 两天 两头', '两天 两头 两套', '两头 两套 两小块', '两套 两小块 两张床', '两小块 两张床 两晚', '两张床 两晚 两朵', '两晚 两朵 两杯', '两朵 两杯 两次', '两杯 两次 两点', '两次 两点 两瓶', '两点 两瓶 两百多', '两瓶 两百多 两部', '两百多 两部 两间', '两部 两间 两间房', '两间 两间房 两面', '两间房 两面 两顿', '两面 两顿 並不', '两顿 並不 个人感觉', '並不 个人感觉 个别', '个人感觉 个别 个子', '个别 个子 中午', '个子 中午 中取', '中午 中取 中国', '中取 中国 中國', '中国 中國 中央', '中國 中央 中央空调', '中央 中央空调 中小', '中央空调 中小 中山', '中小 中山 中山公园', '中山 中山公园 中州', '中山公园 中州 中帮', '中州 中帮 中式', '中帮 中式 中心', '中式 中心 中心地带', '中心 中心地带 中心地段', '中心地带 中心地段 中心广场', '中心地段 中心广场 中心站', '中心广场 中心站 中意', '中心站 中意 中旅', '中意 中旅 中煤', '中旅 中煤 中环', '中煤 中环 中等', '中环 中等 中經過', '中等 中經過 中西', '中經過 中西 中規', '中西 中規 中规中矩', '中規 中规中矩 中距', '中规中矩 中距 中远', '中距 中远 中间', '中远 中间 中餐', '中间 中餐 中餐厅', '中餐 中餐厅 中高', '中餐厅 中高 丰富', '中高 丰富 丰田', '丰富 丰田 丰盛', '丰田 丰盛 临时', '丰盛 临时 临河', '临时 临河 临海', '临河 临海 临湖', '临海 临湖 临街', '临湖 临街 临街房', '临街 临街房 临近', '临街房 临近 为主', '临近 为主 为佳', '为主 为佳 为例', '为佳 为例 主任', '为例 主任 主动', '主任 主动 主妇', '主动 主妇 主意', '主妇 主意 主机', '主意 主机 主楼', '主机 主楼 主管', '主楼 主管 主要', '主管 主要 举动', '主要 举动 举手投足', '举动 举手投足 久远', '举手投足 久远 之上', '久远 之上 之下', '之上 之下 之举', '之下 之举 之内', '之举 之内 之前', '之内 之前 之后', '之前 之后 之处', '之后 之处 之好', '之处 之好 之感', '之好 之感 之星', '之感 之星 之极', '之星 之极 之行', '之极 之行 之选', '之行 之选 之间', '之选 之间 之餘', '之间 之餘 乌龙茶', '之餘 乌龙茶 乐山', '乌龙茶 乐山 乐心', '乐山 乐心 乘坐', '乐心 乘坐 乘火车', '乘坐 乘火车 乘车', '乘火车 乘车 九月份', '乘车 九月份 九江', '九月份 九江 九点钟', '九江 九点钟 九龙', '九点钟 九龙 九龙城', '九龙 九龙城 也許', '九龙城 也許 也许', '也許 也许 习惯', '也许 习惯 书籍', '习惯 书籍 买点', '书籍 买点 乱乱的', '买点 乱乱的 乱哄哄', '乱乱的 乱哄哄 乳酪', '乱哄哄 乳酪 乾净', '乳酪 乾净 了解', '乾净 了解 予以', '了解 予以 事件', '予以 事件 事宜', '事件 事宜 事情', '事宜 事情 二三', '事情 二三 二十', '二三 二十 二十几', '二十 二十几 二十几个', '二十几 二十几个 二十块', '二十几个 二十块 二号', '二十块 二号 二字', '二号 二字 二星级', '二字 二星级 二晚', '二星级 二晚 二期', '二晚 二期 二楼', '二期 二楼 二次', '二楼 二次 二点', '二次 二点 云南', '二点 云南 云南白药', '云南 云南白药 云吞面', '云南白药 云吞面 云霄', '云吞面 云霄 五一', '云霄 五一 五个', '五一 五个 五买', '五个 五买 五分钟', '五买 五分钟 五号', '五分钟 五号 五四', '五号 五四 五天', '五四 五天 五日游', '五天 五日游 五星', '五日游 五星 五星级', '五星 五星级 五点', '五星级 五点 五脏', '五点 五脏 亚运村', '五脏 亚运村 交涉', '亚运村 交涉 交警', '交涉 交警 交通', '交警 交通 交通不便', '交通 交通不便 享受', '交通不便 享受 享用', '享受 享用 京都', '享用 京都 亮丽', '京都 亮丽 亲切', '亮丽 亲切 亲和力', '亲切 亲和力 亲善', '亲和力 亲善 人住', '亲善 人住 人员', '人住 人员 人士', '人员 人士 人多时', '人士 人多时 人大', '人多时 人大 人往', '人大 人往 人性化', '人往 人性化 人才', '人性化 人才 人文', '人才 人文 人来', '人文 人来 人民币', '人来 人民币 人民广场', '人民币 人民广场 人气', '人民广场 人气 人管', '人气 人管 人订', '人管 人订 人间', '人订 人间 什刹海', '人间 什刹海 什麼', '什刹海 什麼 仁民', '什麼 仁民 仅憩', '仁民 仅憩 仅猁', '仅憩 仅猁 仅竭', '仅猁 仅竭 今后', '仅竭 今后 今天', '今后 今天 今年', '今天 今年 今晚', '今年 今晚 介绍', '今晚 介绍 仍会', '介绍 仍会 从事', '仍会 从事 从容', '从事 从容 仔细', '从容 仔细 他們', '仔细 他們 他家', '他們 他家 付款', '他家 付款 付清', '付款 付清 代买', '付清 代买 代步', '代买 代步 令人', '代步 令人 令人满意', '令人 令人满意 以上', '令人满意 以上 以下', '以上 以下 以为', '以下 以为 以内', '以为 以内 以前', '以内 以前 以后', '以前 以后 以外', '以后 以外 以往', '以外 以往 以掛', '以往 以掛 以此', '以掛 以此 以禮', '以此 以禮 价优', '以禮 价优 价位', '价优 价位 价值', '价位 价值 价廉', '价值 价廉 价廉物美', '价廉 价廉物美 价格', '价廉物美 价格 价格便宜', '价格 价格便宜 价格合理', '价格便宜 价格合理 价格比', '价格合理 价格比 价钱', '价格比 价钱 任食', '价钱 任食 休息', '任食 休息 休闲', '休息 休闲 休闲游', '休闲 休闲游 众口', '休闲游 众口 众多', '众口 众多 优势', '众多 优势 优惠', '优势 优惠 优点', '优惠 优点 优秀', '优点 优秀 优质服务', '优秀 优质服务 优越', '优质服务 优越 优越性', '优越 优越性 优雅', '优越性 优雅 会住', '优雅 会住 会员', '会住 会员 会展', '会员 会展 会展中心', '会展 会展中心 会收', '会展中心 会收 会议', '会收 会议 会选', '会议 会选 传真机', '会选 传真机 传统', '传真机 传统 估计', '传统 估计 伸手不见五指', '估计 伸手不见五指 似乎', '伸手不见五指 似乎 但床', '似乎 但床 但离', '但床 但离 位于', '但离 位于 位置', '位于 位置 低些', '位置 低些 低点', '低些 低点 住入', '低点 住入 住宅', '住入 住宅 住宅区', '住宅 住宅区 住宅楼', '住宅区 住宅楼 住客', '住宅楼 住客 住宿', '住客 住宿 住店', '住宿 住店 住满', '住店 住满 住裕达', '住满 住裕达 住进', '住裕达 住进 住過', '住进 住過 体会', '住過 体会 体现', '体会 体现 体贴', '体现 体贴 体验', '体贴 体验 作用', '体验 作用 你好', '作用 你好 使人', '你好 使人 使用', '使人 使用 使用费', '使用 使用费 供餐', '使用费 供餐 依山傍水', '供餐 依山傍水 依旧', '依山傍水 依旧 侧头', '依旧 侧头 侯车', '侧头 侯车 便于', '侯车 便于 便利', '便于 便利 便利店', '便利 便利店 便宜', '便利店 便宜 便捷', '便宜 便捷 促销价', '便捷 促销价 俄罗斯', '促销价 俄罗斯 保养', '俄罗斯 保养 保安', '保养 保安 保护', '保安 保护 保留', '保护 保留 保险箱', '保留 保险箱 保龄球', '保险箱 保龄球 信息', '保龄球 信息 信用卡', '信息 信用卡 修好', '信用卡 修好 修桥', '修好 修桥 修路', '修桥 修路 俱乐部', '修路 俱乐部 倍儿', '俱乐部 倍儿 倪萍', '倍儿 倪萍 值得', '倪萍 值得 值得一提的是', '值得 值得一提的是 值班员', '值得一提的是 值班员 假期', '值班员 假期 偏低', '假期 偏低 偏僻', '偏低 偏僻 偏小', '偏僻 偏小 偏差', '偏小 偏差 偏贵', '偏差 偏贵 偏高', '偏贵 偏高 做个', '偏高 做个 做事', '做个 做事 做到', '做事 做到 做大', '做到 做大 做好', '做大 做好 做饭', '做好 做饭 停止', '做饭 停止 停满', '停止 停满 停車場', '停满 停車場 停车', '停車場 停车 停车场', '停车 停车场 停车费', '停车场 停车费 停電', '停车费 停電 停靠', '停電 停靠 健身', '停靠 健身 健身房', '健身 健身房 偶有', '健身房 偶有 傅家庄', '偶有 傅家庄 僅僅', '傅家庄 僅僅 像是', '僅僅 像是 價格置', '像是 價格置 儿子', '價格置 儿子 元住', '儿子 元住 元旦', '元住 元旦 充满', '元旦 充满 充电', '充满 充电 充电器', '充电 充电器 先交', '充电器 先交 先前', '先交 先前 先生', '先前 先生 先订', '先生 先订 先进', '先订 先进 光线', '先进 光线 免税店', '光线 免税店 免費', '免税店 免費 免费', '免費 免费 免费打', '免费 免费打 兑成', '免费打 兑成 兜来', '兑成 兜来 入住', '兜来 入住 入住率', '入住 入住率 入口', '入住率 入口 入座', '入口 入座 入时', '入座 入时 入睡', '入时 入睡 全世界', '入睡 全世界 全城', '全世界 全城 全天', '全城 全天 全市', '全天 全市 全是', '全市 全是 全湿', '全是 全湿 全球', '全湿 全球 全程', '全球 全程 全部', '全程 全部 全面', '全部 全面 八折', '全面 八折 八月', '八折 八月 八百多', '八月 八百多 公交', '八百多 公交 公交站', '公交 公交站 公交线路', '公交站 公交线路 公交车', '公交线路 公交车 公交车站', '公交车 公交车站 公司', '公交车站 公司 公园', '公司 公园 公寓楼', '公园 公寓楼 公用', '公寓楼 公用 公路', '公用 公路 公车', '公路 公车 公道', '公车 公道 六个', '公道 六个 六层', '六个 六层 六楼', '六层 六楼 兰桂坊', '六楼 兰桂坊 兰桂枋', '兰桂坊 兰桂枋 兰桂芳', '兰桂枋 兰桂芳 共住', '兰桂芳 共住 共计', '共住 共计 关上', '共计 关上 关掉', '关上 关掉 关注', '关掉 关注 关系', '关注 关系 关键', '关系 关键 关门', '关键 关门 兴趣', '关门 兴趣 其環境', '兴趣 其環境 具全', '其環境 具全 具有', '具全 具有 典雅', '具有 典雅 兼顾', '典雅 兼顾 内地', '兼顾 内地 内部', '内地 内部 内里', '内部 内里 再也', '内里 再也 再住', '再也 再住 再接再厉', '再住 再接再厉 再次', '再接再厉 再次 再续', '再次 再续 再选', '再续 再选 写字楼', '再选 写字楼 写意', '写字楼 写意 写订', '写意 写订 农村', '写订 农村 冤枉', '农村 冤枉 冬天', '冤枉 冬天 冰水', '冬天 冰水 冰箱', '冰水 冰箱 冲剂', '冰箱 冲剂 冲洗', '冲剂 冲洗 冲浪', '冲洗 冲浪 冲澡', '冲浪 冲澡 冲着', '冲澡 冲着 决定', '冲着 决定 冷水', '决定 冷水 冷淡', '冷水 冷淡 冷漠', '冷淡 冷漠 准备', '冷漠 准备 准确', '准备 准确 凉快', '准确 凉快 凉爽', '凉快 凉爽 凌晨', '凉爽 凌晨 凑合', '凌晨 凑合 几个', '凑合 几个 几位', '几个 几位 几分钟', '几位 几分钟 几口', '几分钟 几口 几号楼', '几口 几号楼 几处', '几号楼 几处 几天', '几处 几天 几家', '几天 几家 几年', '几家 几年 几张', '几年 几张 几支', '几张 几支 几文', '几支 几文 几栋', '几文 几栋 几次', '几栋 几次 几步', '几次 几步 几种', '几步 几种 出乎意料', '几种 出乎意料 出于', '出乎意料 出于 出入', '出于 出入 出发', '出入 出发 出口', '出发 出口 出名', '出口 出名 出品', '出名 出品 出家', '出品 出家 出差', '出家 出差 出水', '出差 出水 出租车', '出水 出租车 出行', '出租车 出行 出门', '出行 出门 出门时', '出门 出门时 分别', '出门时 分别 分到', '分别 分到 分离', '分到 分离 分量', '分离 分量 分鐘', '分量 分鐘 分钟', '分鐘 分钟 切身感受', '分钟 切身感受 划算', '切身感受 划算 列入', '划算 列入 刚刚', '列入 刚刚 刚到', '刚刚 刚到 刚去', '刚到 刚去 刚要', '刚去 刚要 刚过', '刚要 刚过 刚进', '刚过 刚进 创意', '刚进 创意 初期', '创意 初期 利用', '初期 利用 利益', '利用 利益 别住', '利益 别住 别具匠心', '别住 别具匠心 别墅', '别具匠心 别墅 别扭', '别墅 别扭 别是', '别扭 别是 别有情趣', '别是 别有情趣 别涨', '别有情趣 别涨 别致', '别涨 别致 刮胡子', '别致 刮胡子 到位', '刮胡子 到位 到弥墩', '到位 到弥墩 到津滨', '到弥墩 到津滨 到达', '到津滨 到达 制服', '到达 制服 刷卡', '制服 刷卡 刻意', '刷卡 刻意 前一天', '刻意 前一天 前住', '前一天 前住 前住過', '前住 前住過 前台', '前住過 前台 前往', '前台 前往 前有', '前往 前有 前端', '前有 前端 前面', '前端 前面 剥落', '前面 剥落 副理', '剥落 副理 办事', '副理 办事 办公台', '办事 办公台 办好', '办公台 办好 办手续', '办好 办手续 办法', '办手续 办法 办理', '办法 办理 功能', '办理 功能 加冰', '功能 加冰 加强', '加冰 加强 加盟店', '加强 加盟店 加装', '加盟店 加装 加钱', '加装 加钱 务必', '加钱 务必 动工', '务必 动工 动物园', '动工 动物园 努力', '动物园 努力 勉强', '努力 勉强 勝在', '勉强 勝在 勤人員', '勝在 勤人員 勤快', '勤人員 勤快 包小包', '勤快 包小包 包括', '包小包 包括 包河', '包括 包河 匆忙', '包河 匆忙 化妆棉', '匆忙 化妆棉 北九水', '化妆棉 北九水 北京', '北九水 北京 北到', '北京 北到 北师大', '北到 北师大 北房', '北师大 北房 北海', '北房 北海 匹萨', '北海 匹萨 匹配', '匹萨 匹配 区别', '匹配 区别 区区小事', '区别 区区小事 区域', '区区小事 区域 区有', '区域 区有 区较', '区有 区较 医院', '区较 医院 十一', '医院 十一 十元', '十一 十元 十全十美', '十元 十全十美 十分', '十全十美 十分 十分钟', '十分 十分钟 十多元', '十分钟 十多元 十月', '十多元 十月 十点', '十月 十点 千万别', '十点 千万别 升为', '千万别 升为 升到', '升为 升到 升旗仪式', '升到 升旗仪式 升级', '升旗仪式 升级 午餐', '升级 午餐 午饭', '午餐 午饭 半个', '午饭 半个 半到', '半个 半到 半夜', '半到 半夜 半天', '半夜 半天 半小时', '半天 半小时 半山', '半小时 半山 半岛', '半山 半岛 半截', '半岛 半截 半日', '半截 半日 半死', '半日 半死 华旗', '半死 华旗 华苑', '华旗 华苑 华融', '华苑 华融 华贵', '华融 华贵 华阳', '华贵 华阳 协程', '华阳 协程 协程定', '协程 协程定 协议', '协程定 协议 协议价', '协议 协议价 协调', '协议价 协调 協助', '协调 協助 单人', '協助 单人 单人间', '单人 单人间 单位', '单人间 单位 单床', '单位 单床 单独', '单床 单独 单行', '单独 单行 单行线', '单行 单行线 单调', '单行线 单调 单间', '单调 单间 卖场', '单间 卖场 卖点', '卖场 卖点 南京', '卖点 南京 南京路', '南京 南京路 南到', '南京路 南到 南北', '南到 南北 南山', '南北 南山 南方', '南山 南方 南普陀', '南方 南普陀 南湖', '南普陀 南湖 博物馆', '南湖 博物馆 博览', '博物馆 博览 占地面积', '博览 占地面积 卡拉', '占地面积 卡拉 卡片', '卡拉 卡片 卫生', '卡片 卫生 卫生条件', '卫生 卫生条件 卫生间', '卫生条件 卫生间 印象', '卫生间 印象 危险', '印象 危险 即可', '危险 即可 却是', '即可 却是 历史', '却是 历史 厉害', '历史 厉害 压抑', '厉害 压抑 厕所', '压抑 厕所 厕纸', '厕所 厕纸 厚实', '厕纸 厚实 厚度', '厚实 厚度 原先', '厚度 原先 原因', '原先 原因 原来', '原因 原来 原色', '原来 原色 厦大', '原色 厦大 厦门', '厦大 厦门 去处', '厦门 去处 去年', '去处 去年 去年底', '去年 去年底 去过', '去年底 去过 县城', '去过 县城 参加', '县城 参加 参展', '参加 参展 参观', '参展 参观 又续', '参观 又续 及时', '又续 及时 友善', '及时 友善 友好', '友善 友好 双人房', '友好 双人房 双人间', '双人房 双人间 双层', '双人间 双层 双床', '双层 双床 双早', '双床 双早 双标', '双早 双标 反应', '双标 反应 反应速度', '反应 反应速度 反映', '反应速度 反映 反正', '反映 反正 反馈', '反正 反馈 发呆', '反馈 发呆 发现', '发呆 发现 发生', '发现 发生 发觉', '发生 发觉 发车', '发觉 发车 发送', '发车 发送 发霉', '发送 发霉 取境', '发霉 取境 取暖', '取境 取暖 取来', '取暖 取来 取款机', '取来 取款机 取消', '取款机 取消 取阶', '取消 取阶 取静', '取阶 取静 受不了', '取静 受不了 受到', '受不了 受到 受宠若惊', '受到 受宠若惊 受骗', '受宠若惊 受骗 变化', '受骗 变化 变成', '变化 变成 口味', '变成 口味 口袋', '口味 口袋 古典', '口袋 古典 古城', '古典 古城 古都', '古城 古都 另一家', '古都 另一家 另人', '另一家 另人 另加', '另人 另加 另有', '另加 另有 只住', '另有 只住 只值', '只住 只值 只好', '只值 只好 只敢', '只好 只敢 只求', '只敢 只求 只能', '只求 只能 只花', '只能 只花 叫口', '只花 叫口 叫车', '叫口 叫车 召开', '叫车 召开 叮叮', '召开 叮叮 叮当声', '叮叮 叮当声 可乘', '叮当声 可乘 可买', '可乘 可买 可住', '可买 可住 可口', '可住 可口 可否', '可口 可否 可怕', '可否 可怕 可怜', '可怕 可怜 可惜', '可怜 可惜 可爱', '可惜 可爱 可至', '可爱 可至 可言', '可至 可言 可说', '可言 可说 可谓', '可说 可谓 台借', '可谓 台借 台前', '台借 台前 台湾', '台前 台湾 台盆', '台湾 台盆 右边', '台盆 右边 号数', '右边 号数 号楼', '号数 号楼 号称', '号楼 号称 司机', '号称 司机 吃住行', '司机 吃住行 吃过饭', '吃住行 吃过饭 吃饭', '吃过饭 吃饭 各地', '吃饭 各地 各处', '各地 各处 各有特色', '各处 各有特色 各类', '各有特色 各类 各项', '各类 各项 合力', '各项 合力 合口', '合力 合口 合并', '合口 合并 合庆', '合并 合庆 合格', '合庆 合格 合理', '合格 合理 合算', '合理 合算 合适', '合算 合适 吉之島', '合适 吉之島 同一', '吉之島 同一 同事', '同一 同事 同价位', '同事 同价位 同去', '同价位 同去 同学', '同去 同学 同志', '同学 同志 同意', '同志 同意 同感', '同意 同感 同样', '同感 同样 同级', '同样 同级 同胞', '同级 同胞 同行', '同胞 同行 名不虚传', '同行 名不虚传 名义', '名不虚传 名义 名人', '名义 名人 名字', '名人 名字 名气', '名字 名气 名牌', '名气 名牌 名过其实', '名牌 名过其实 后山', '名过其实 后山 后悔', '后山 后悔 后海', '后悔 后海 后者', '后海 后者 后要', '后者 后要 后边', '后要 后边 后门', '后边 后门 后面', '后门 后面 吐出来', '后面 吐出来 向下', '吐出来 向下 向前', '向下 向前 向海', '向前 向海 吓人', '向海 吓人 吝啬', '吓人 吝啬 含早', '吝啬 含早 听到', '含早 听到 听取', '听到 听取 听说', '听取 听说 启动', '听说 启动 吵醒', '启动 吵醒 吵闹', '吵醒 吵闹 吸取', '吵闹 吸取 吸尘', '吸取 吸尘 吸尘器', '吸尘 吸尘器 吸引', '吸尘器 吸引 吸烟', '吸引 吸烟 吸烟区', '吸烟 吸烟区 吹风机', '吸烟区 吹风机 告知', '吹风机 告知 告诉', '告知 告诉 员工', '告诉 员工 周全', '员工 周全 周到', '周全 周到 周四', '周到 周四 周围', '周四 周围 周围环境', '周围 周围环境 周日', '周围环境 周日 周末', '周日 周末 周边', '周末 周边 周边环境', '周边 周边环境 周遭', '周边环境 周遭 周邊', '周遭 周邊 味美', '周邊 味美 味道', '味美 味道 呵呵', '味道 呵呵 呼叫', '呵呵 呼叫 呼呼', '呼叫 呼呼 和煦', '呼呼 和煦 和蔼', '和煦 和蔼 和蔼可亲', '和蔼 和蔼可亲 咖啡', '和蔼可亲 咖啡 咖啡厅', '咖啡 咖啡厅 咨询', '咖啡厅 咨询 咳嗽', '咨询 咳嗽 咳嗽声', '咳嗽 咳嗽声 咸涩', '咳嗽声 咸涩 咽炎', '咸涩 咽炎 品位', '咽炎 品位 品尝', '品位 品尝 品牌', '品尝 品牌 品种', '品牌 品种 品质', '品种 品质 哈哈哈', '品质 哈哈哈 哈哈哈哈', '哈哈哈 哈哈哈哈 哈尔滨', '哈哈哈哈 哈尔滨 响得', '哈尔滨 响得 售完', '响得 售完 唯一', '售完 唯一 商业中心', '唯一 商业中心 商业区', '商业中心 商业区 商务', '商业区 商务 商务中心', '商务 商务中心 商务人士', '商务中心 商务人士 商务旅行', '商务人士 商务旅行 商务酒店', '商务旅行 商务酒店 商品', '商务酒店 商品 商场', '商品 商场 商城', '商场 商城 商店', '商城 商店 商旅', '商店 商旅 商業區', '商旅 商業區 商铺', '商業區 商铺 問題', '商铺 問題 啤酒', '問題 啤酒 啤酒节', '啤酒 啤酒节 喜庆', '啤酒节 喜庆 喜欢', '喜庆 喜欢 喜歡', '喜欢 喜歡 喝点', '喜歡 喝点 喝热', '喝点 喝热 喧闹', '喝热 喧闹 喷头', '喧闹 喷头 喷泉', '喷头 喷泉 嘈杂', '喷泉 嘈杂 嘉福', '嘈杂 嘉福 嘉逸', '嘉福 嘉逸 嘿嘿', '嘉逸 嘿嘿 噪声', '嘿嘿 噪声 噪音', '噪声 噪音 四十分钟', '噪音 四十分钟 四大', '四十分钟 四大 四天', '四大 四天 四星', '四天 四星 四星级', '四星 四星级 四晚', '四星级 四晚 四楼', '四晚 四楼 四次', '四楼 四次 四通八达', '四次 四通八达 四道', '四通八达 四道 四面', '四道 四面 回事', '四面 回事 回到', '回事 回到 回去', '回到 回去 回头一看', '回去 回头一看 回家', '回头一看 回家 回应', '回家 回应 回来', '回应 回来 回程', '回来 回程 回答', '回程 回答 回选', '回答 回选 回顾', '回选 回顾 因在', '回顾 因在 因為', '因在 因為 因离', '因為 因离 因要', '因离 因要 团队', '因要 团队 困扰', '团队 困扰 困难', '困扰 困难 围挡', '困难 围挡 国内', '围挡 国内 国内长途', '国内 国内长途 国外', '国内长途 国外 国家', '国外 国家 国宾', '国家 国宾 国宾馆', '国宾 国宾馆 国庆', '国宾馆 国庆 国贸', '国庆 国贸 国际', '国贸 国际 国际品牌', '国际 国际品牌 国际展览中心', '国际品牌 国际展览中心 在外', '国际展览中心 在外 在意', '在外 在意 在我看来', '在意 在我看来 地为', '在我看来 地为 地区', '地为 地区 地名', '地区 地名 地图', '地名 地图 地址', '地图 地址 地处', '地址 地处 地头', '地处 地头 地带', '地头 地带 地方', '地带 地方 地板', '地方 地板 地段', '地板 地段 地毯', '地段 地毯 地漏', '地毯 地漏 地点', '地漏 地点 地理', '地点 地理 地理位置', '地理 地理位置 地角', '地理位置 地角 地道', '地角 地道 地铁', '地道 地铁 地铁站', '地铁 地铁站 均匀', '地铁站 均匀 坐在', '均匀 坐在 坐地铁', '坐在 坐地铁 坐得', '坐地铁 坐得 坐惯', '坐得 坐惯 坐火车', '坐惯 坐火车 坐船', '坐火车 坐船 坐落', '坐船 坐落 坐车', '坐落 坐车 块钱', '坐车 块钱 坚定不移', '块钱 坚定不移 垂下来', '坚定不移 垂下来 型号', '垂下来 型号 城市', '型号 城市 城门', '城市 城门 培养', '城门 培养 培訓', '培养 培訓 培训', '培訓 培训 堂皇', '培训 堂皇 堅持', '堂皇 堅持 堪称', '堅持 堪称 堵塞', '堪称 堵塞 堵水', '堵塞 堵水 堵车', '堵水 堵车 塌塌米', '堵车 塌塌米 塑料薄膜', '塌塌米 塑料薄膜 塔尔寺', '塑料薄膜 塔尔寺 填写', '塔尔寺 填写 墙上', '填写 墙上 墙壁', '墙上 墙壁 壁纸', '墙壁 壁纸 壮观', '壁纸 壮观 声明', '壮观 声明 声音', '声明 声音 处于', '声音 处于 处在', '处于 处在 处理', '处在 处理 处理速度', '处理 处理速度 夏利车', '处理速度 夏利车 夏天', '夏利车 夏天 夏日', '夏天 夏日 外出', '夏日 外出 外国', '外出 外国 外国人', '外国 外国人 外墙', '外国人 外墙 外套', '外墙 外套 外宾', '外套 外宾 外有', '外宾 外有 外望', '外有 外望 外表', '外望 外表 外观', '外表 外观 外资', '外观 外资 外边', '外资 外边 外部', '外边 外部 外部环境', '外部 外部环境 外面', '外部环境 外面 多一晚', '外面 多一晚 多一点', '多一晚 多一点 多人', '多一点 多人 多余', '多人 多余 多元', '多余 多元 多功能', '多元 多功能 多加', '多功能 多加 多拉', '多加 多拉 多数', '多拉 多数 多样', '多数 多样 多点', '多样 多点 多能', '多点 多能 夜床', '多能 夜床 夜总会', '夜床 夜总会 夜晚', '夜总会 夜晚 夜景', '夜晚 夜景 夜色', '夜景 夜色 夜里', '夜色 夜里 夜间', '夜里 夜间 够得上', '夜间 够得上 够星', '够得上 够星 大上', '够星 大上 大众化', '大上 大众化 大佛', '大众化 大佛 大便', '大佛 大便 大厅', '大便 大厅 大厦', '大厅 大厦 大商', '大厦 大商 大块头', '大商 大块头 大型', '大块头 大型 大型超市', '大型 大型超市 大堂', '大型超市 大堂 大大的', '大堂 大大的 大家乐', '大大的 大家乐 大小', '大家乐 大小 大巴', '大小 大巴 大巴车', '大巴 大巴车 大年初一', '大巴车 大年初一 大床', '大年初一 大床 大房', '大床 大房 大打折扣', '大房 大打折扣 大方', '大打折扣 大方 大明湖', '大方 大明湖 大楼', '大明湖 大楼 大气', '大楼 大气 大海', '大气 大海 大润发', '大海 大润发 大片', '大润发 大片 大理', '大片 大理 大碍', '大理 大碍 大窗', '大碍 大窗 大而无当', '大窗 大而无当 大街', '大而无当 大街 大观园', '大街 大观园 大连', '大观园 大连 大连港', '大连 大连港 大道', '大连港 大道 大酒店', '大道 大酒店 大酒点', '大酒店 大酒点 大门口', '大酒点 大门口 大陆', '大门口 大陆 大雨', '大陆 大雨 大面積', '大雨 大面積 大饭店', '大面積 大饭店 天天', '大饭店 天天 天文', '天天 天文 天星', '天文 天星 天桥', '天星 天桥 天气', '天桥 天气 天河城', '天气 天河城 天津', '天河城 天津 天然', '天津 天然 天色已晚', '天然 天色已晚 天花板', '天色已晚 天花板 太低', '天花板 太低 太偏', '太低 太偏 太冷', '太偏 太冷 太原', '太冷 太原 太原市', '太原 太原市 太吵', '太原市 太吵 太多', '太吵 太多 太大', '太多 太大 太太', '太大 太太 太好', '太太 太好 太子', '太好 太子 太小', '太子 太小 太少', '太小 太少 太差', '太少 太差 太开', '太差 太开 太慢', '太开 太慢 太挤', '太慢 太挤 太旧', '太挤 太旧 太早', '太旧 太早 太有', '太早 太有 太湖', '太有 太湖 太滑', '太湖 太滑 太短', '太滑 太短 太老', '太短 太老 太贵', '太老 太贵 太软', '太贵 太软 太远', '太软 太远 太长', '太远 太长 太高', '太长 太高 失望', '太高 失望 头一回', '失望 头一回 头上', '头一回 头上 头发', '头上 头发 头衔', '头发 头衔 夸张', '头衔 夸张 夹被', '夸张 夹被 奇怪', '夹被 奇怪 奇怪的是', '奇怪 奇怪的是 奇贵', '奇怪的是 奇贵 奉來', '奇贵 奉來 套房', '奉來 套房 套装', '套房 套装 套间', '套装 套间 套餐', '套间 套餐 奢侈', '套餐 奢侈 奢华', '奢侈 奢华 奥运', '奢华 奥运 奥迪', '奥运 奥迪 女士', '奥迪 女士 女孩', '女士 女孩 女性', '女孩 女性 好不好', '女性 好不好 好不容易', '好不好 好不容易 好久', '好不容易 好久 好些', '好久 好些 好像', '好些 好像 好几个', '好像 好几个 好几年', '好几个 好几年 好去处', '好几年 好去处 好又多', '好去处 好又多 好友', '好又多 好友 好吃', '好友 好吃 好听', '好吃 好听 好多', '好听 好多 好太多', '好多 好太多 好奇', '好太多 好奇 好好', '好奇 好好 好容易', '好好 好容易 好小叻', '好容易 好小叻 好心', '好小叻 好心 好找', '好心 好找 好歹', '好找 好歹 好看', '好歹 好看 好觉', '好看 好觉 好评', '好觉 好评 好象', '好评 好象 好酒', '好象 好酒 好长', '好酒 好长 好长时间', '好长 好长时间 好闻', '好长时间 好闻 如同', '好闻 如同 如家', '如同 如家 如心', '如家 如心 如新', '如心 如新 如是', '如新 如是 如能', '如是 如能 委實', '如能 委實 委屈', '委實 委屈 姜汤', '委屈 姜汤 威海', '姜汤 威海 威海市', '威海 威海市 娱乐', '威海市 娱乐 嫌小', '娱乐 嫌小 子太硬', '嫌小 子太硬 存包', '子太硬 存包 存在', '存包 存在 存放', '存在 存放 学校', '存放 学校 孩子', '学校 孩子 宁夏', '孩子 宁夏 安全', '宁夏 安全 安庆', '安全 安庆 安徽', '安庆 安徽 安排', '安徽 安排 安逸', '安排 安逸 安静', '安逸 安静 完全', '安静 完全 完善', '完全 完善 完备', '完善 完备 完好', '完备 完好 完成', '完好 完成 完璧', '完成 完璧 完美', '完璧 完美 宏基', '完美 宏基 定位', '宏基 定位 定单', '定位 定单 定去', '定单 定去 定园', '定去 定园 定点', '定园 定点 宝宝', '定点 宝宝 实在', '宝宝 实在 实地', '实在 实地 实惠', '实地 实惠 实用', '实惠 实用 实际', '实用 实际 实际上', '实际 实际上 客人', '实际上 客人 客户', '客人 客户 客户关系', '客户 客户关系 客户经理', '客户关系 客户经理 客房', '客户经理 客房 客房部', '客房 客房部 客气', '客房部 客气 客观', '客气 客观 客运站', '客观 客运站 宣传', '客运站 宣传 室内', '宣传 室内 室内环境', '室内 室内环境 室温', '室内环境 室温 害得', '室温 害得 家人', '害得 家人 家具', '家人 家具 家庭', '家具 家庭 家近', '家庭 家近 容易', '家近 容易 宽大', '容易 宽大 宽带', '宽大 宽带 宽敞', '宽带 宽敞 宾至如归', '宽敞 宾至如归 宾馆', '宾至如归 宾馆 寄存', '宾馆 寄存 密码', '寄存 密码 富丽华', '密码 富丽华 富豪', '富丽华 富豪 寒山寺', '富豪 寒山寺 寒磣', '寒山寺 寒磣 对不起', '寒磣 对不起 对外', '对不起 对外 对待', '对外 对待 对得起', '对待 对得起 对此', '对得起 对此 对比', '对此 对比 对海', '对比 对海 对门', '对海 对门 对面', '对门 对面 对骂', '对面 对骂 导致', '对骂 导致 封门', '导致 封门 将园', '封门 将园 專業', '将园 專業 小且', '專業 小且 小东西', '小且 小东西 小些', '小东西 小些 小伙', '小些 小伙 小伙子', '小伙 小伙子 小便', '小伙子 小便 小卖部', '小便 小卖部 小吃', '小卖部 小吃 小吃店', '小吃 小吃店 小吃街', '小吃店 小吃街 小型', '小吃街 小型 小姐', '小型 小姐 小孩', '小姐 小孩 小孩子', '小孩 小孩子 小小', '小孩子 小小 小小的', '小小 小小的 小屋', '小小的 小屋 小山', '小屋 小山 小岛', '小山 小岛 小巴', '小岛 小巴 小店', '小巴 小店 小弟', '小店 小弟 小得', '小弟 小得 小心', '小得 小心 小时', '小心 小时 小时候', '小时 小时候 小是', '小时候 小是 小有名气', '小是 小有名气 小朋友', '小有名气 小朋友 小河', '小朋友 小河 小点', '小河 小点 小点心', '小点 小点心 小片', '小点心 小片 小盘', '小片 小盘 小童', '小盘 小童 小米粥', '小童 小米粥 小花', '小米粥 小花 小贵', '小花 小贵 小费', '小贵 小费 小资', '小费 小资 小路', '小资 小路 小车', '小路 小车 小轮', '小车 小轮 小雨', '小轮 小雨 小青岛', '小雨 小青岛 小食店', '小青岛 小食店 少有', '小食店 少有 少量', '少有 少量 尖东', '少量 尖东 尖沙咀', '尖东 尖沙咀 尚佳', '尖沙咀 尚佳 尚可', '尚佳 尚可 尚差', '尚可 尚差 尚需', '尚差 尚需 尝尝', '尚需 尝尝 尝试', '尝尝 尝试 尤其', '尝试 尤其 就可以看', '尤其 就可以看 就行', '就可以看 就行 就要', '就行 就要 就餐', '就要 就餐 尴尬', '就餐 尴尬 尺度', '尴尬 尺度 尼敦路', '尺度 尼敦路 尽兴', '尼敦路 尽兴 尽收眼底', '尽兴 尽收眼底 尾数', '尽收眼底 尾数 层后', '尾数 层后 层次', '层后 层次 居住', '层次 居住 居民', '居住 居民 居民区', '居民 居民区 屈臣氏', '居民区 屈臣氏 屋外', '屈臣氏 屋外 屋子', '屋外 屋子 屋里', '屋子 屋里 展会', '屋里 展会 展览会', '展会 展览会 展馆', '展览会 展馆 属于', '展馆 属于 屯门', '属于 屯门 山上', '屯门 山上 山东', '山上 山东 山庄', '山东 山庄 山景', '山庄 山景 山水', '山景 山水 山脚', '山水 山脚 山西', '山脚 山西 山顶', '山西 山顶 峨眉', '山顶 峨眉 崩溃', '峨眉 崩溃 川妹子', '崩溃 川妹子 川沙', '川妹子 川沙 巡逻', '川沙 巡逻 工人', '巡逻 工人 工作', '工人 工作 工作人员', '工作 工作人员 工作失误', '工作人员 工作失误 工作效率', '工作失误 工作效率 工号', '工作效率 工号 工地', '工号 工地 工夫', '工地 工夫 工程师', '工夫 工程师 左右', '工程师 左右 左手边', '左右 左手边 巧克力', '左手边 巧克力 差一', '巧克力 差一 差不太远', '差一 差不太远 差异', '差不太远 差异 差得远', '差异 差得远 差悦华', '差得远 差悦华 差点', '差悦华 差点 差距', '差点 差距 己经', '差距 己经 已帮', '己经 已帮 已显', '已帮 已显 已有', '已显 已有 已算', '已有 已算 已經', '已算 已經 已经', '已經 已经 巴士', '已经 巴士 巴士站', '巴士 巴士站 市中心', '巴士站 市中心 市内电话', '市中心 市内电话 市区', '市内电话 市区 市场', '市区 市场 市委', '市场 市委 市政府', '市委 市政府 市景', '市政府 市景 市民', '市景 市民 布局', '市民 布局 布置', '布局 布置 希尔顿', '布置 希尔顿 希望', '希尔顿 希望 帐号', '希望 帐号 帝京', '帐号 帝京 带个', '帝京 带个 带些', '带个 带些 带够', '带些 带够 带来', '带够 带来 带给', '带来 带给 带路', '带给 带路 席梦丝', '带路 席梦丝 帮助', '席梦丝 帮助 帮忙', '帮助 帮忙 帮送', '帮忙 帮送 常住', '帮送 常住 常客', '常住 常客 常驻', '常客 常驻 幕顶', '常驻 幕顶 干净', '幕顶 干净 干洗', '干净 干洗 干活', '干洗 干活 平台', '干活 平台 平吧', '平台 平吧 平常', '平吧 平常 平平', '平常 平平 平心', '平平 平心 平方', '平心 平方 平时', '平方 平时 平米', '平时 平米 平肝', '平米 平肝 年代', '平肝 年代 年前', '年代 年前 年纪', '年前 年纪 年终', '年纪 年终 年轻人', '年终 年轻人 年青', '年轻人 年青 并不大', '年青 并不大 并未', '并不大 并未 幸亏', '并未 幸亏 幸无', '幸亏 幸无 幸运', '幸无 幸运 幽静', '幸运 幽静 幾分鐘', '幽静 幾分鐘 幾十到', '幾分鐘 幾十到 幾度陽', '幾十到 幾度陽 广场', '幾度陽 广场 广州', '广场 广州 广泛', '广州 广泛 床上', '广泛 床上 床上用品', '床上 床上用品 床位', '床上用品 床位 床单', '床位 床单 床垫', '床单 床垫 床房', '床垫 床房 床有', '床房 床有 床沿', '床有 床沿 床间', '床沿 床间 庐山', '床间 庐山 应是', '庐山 应是 应有尽有', '应是 应有尽有 应该', '应有尽有 应该 底部', '应该 底部 店到', '底部 店到 店前', '店到 店前 店去', '店前 店去 店离', '店去 店离 店里', '店离 店里 度假', '店里 度假 度假型', '度假 度假型 度假村', '度假型 度假村 座位', '度假村 座位 庭院', '座位 庭院 康乐', '庭院 康乐 延住', '康乐 延住 延期', '延住 延期 延路', '延期 延路 延长', '延路 延长 建材', '延长 建材 建筑', '建材 建筑 建議', '建筑 建議 建议', '建議 建议 建设', '建议 建设 开业', '建设 开业 开了个', '开业 开了个 开关', '开了个 开关 开冷', '开关 开冷 开发区', '开冷 开发区 开封', '开发区 开封 开得', '开封 开得 开心', '开得 开心 开放', '开心 开放 开水', '开放 开水 开穿', '开水 开穿 开窗', '开穿 开窗 开箱', '开窗 开箱 开线', '开箱 开线 开车', '开线 开车 开通', '开车 开通 开门', '开通 开门 开阔', '开门 开阔 异味', '开阔 异味 异国情调', '异味 异国情调 异常', '异国情调 异常 异物', '异常 异物 引发', '异物 引发 引导', '引发 引导 弟兄们', '引导 弟兄们 张小床', '弟兄们 张小床 张床', '张小床 张床 张裕', '张床 张裕 弥敦道', '张裕 弥敦道 弥补', '弥敦道 弥补 強求', '弥补 強求 弹簧', '強求 弹簧 强化', '弹簧 强化 强烈建议', '强化 强烈建议 强烈推荐', '强烈建议 强烈推荐 归照', '强烈推荐 归照 归航', '归照 归航 当地', '归航 当地 当地人', '当地 当地人 当大', '当地人 当大 当天', '当大 当天 当局', '当天 当局 当心', '当局 当心 当日', '当心 当日 当时', '当日 当时 当晚', '当时 当晚 当面', '当晚 当面 形容', '当面 形容 形形色色', '形容 形形色色 形象大使', '形形色色 形象大使 彩条', '形象大使 彩条 影响', '彩条 影响 往下', '影响 往下 往前走', '往下 往前走 往来', '往前走 往来 往来于', '往来 往来于 往返', '往来于 往返 待人', '往返 待人 待遇', '待人 待遇 很会', '待遇 很会 很值', '很会 很值 很厚', '很值 很厚 很多年', '很厚 很多年 很大', '很多年 很大 很小', '很大 很小 很差', '很小 很差 很强', '很差 很强 很快', '很强 很快 很怪', '很快 很怪 很早以前', '很怪 很早以前 很旺', '很早以前 很旺 很棒', '很旺 很棒 很气', '很棒 很气 很漂亮', '很气 很漂亮 很灵', '很漂亮 很灵 很破', '很灵 很破 很累', '很破 很累 很脏', '很累 很脏 很贵', '很脏 很贵 很足', '很贵 很足 很近', '很足 很近 很长', '很近 很长 很难', '很长 很难 徒步', '很难 徒步 得出', '徒步 得出 得到', '得出 得到 得来', '得到 得来 得知', '得来 得知 得象', '得知 得象 得闲', '得象 得闲 微笑', '得闲 微笑 心中', '微笑 心中 心地', '心中 心地 心差', '心地 心差 心态', '心差 心态 心情', '心态 心情 心態', '心情 心態 心有余悸', '心態 心有余悸 心理准备', '心有余悸 心理准备 心里', '心理准备 心里 必住', '心里 必住 必答', '必住 必答 必要', '必答 必要 忍忍', '必要 忍忍 忍无可忍', '忍忍 忍无可忍 忘带', '忍无可忍 忘带 忘记', '忘带 忘记 忙碌', '忘记 忙碌 快捷', '忙碌 快捷 快樂', '快捷 快樂 快活', '快樂 快活 快线', '快活 快线 快轨', '快线 快轨 快递', '快轨 快递 快餐店', '快递 快餐店 忽冷忽热', '快餐店 忽冷忽热 忽略', '忽冷忽热 忽略 怀疑', '忽略 怀疑 态度', '怀疑 态度 怡东', '态度 怡东 怡和', '怡东 怡和 怡情', '怡和 怡情 急忙', '怡情 急忙 性价比', '急忙 性价比 性價', '性价比 性價 怪味', '性價 怪味 总体', '怪味 总体 总体水平', '总体 总体水平 总体而言', '总体水平 总体而言 总共', '总体而言 总共 总台', '总共 总台 总在', '总台 总在 总店', '总在 总店 总是', '总店 总是 总机', '总是 总机 总理', '总机 总理 总的来讲', '总理 总的来讲 总站', '总的来讲 总站 总算', '总站 总算 总经理', '总算 总经理 总结', '总经理 总结 总能', '总结 总能 总部', '总能 总部 恐怖', '总部 恐怖 恒基', '恐怖 恒基 恰當', '恒基 恰當 恶心', '恰當 恶心 悄悄', '恶心 悄悄 悦华', '悄悄 悦华 悦来', '悦华 悦来 悬崖', '悦来 悬崖 情侣', '悬崖 情侣 情况', '情侣 情况 情况不明', '情况 情况不明 情愿', '情况不明 情愿 情景', '情愿 情景 情调', '情景 情调 惊喜', '情调 惊喜 惊扰', '惊喜 惊扰 惊讶', '惊扰 惊讶 惟独', '惊讶 惟独 惠康', '惟独 惠康 惡劣', '惠康 惡劣 惨不忍睹', '惡劣 惨不忍睹 惬意', '惨不忍睹 惬意 想不到', '惬意 想不到 想不通', '想不到 想不通 想像中', '想不通 想像中 想到', '想像中 想到 想必', '想到 想必 想想', '想必 想想 想法', '想想 想法 想要', '想法 想要 想象', '想要 想象 想起', '想象 想起 愉快', '想起 愉快 意义', '愉快 意义 意外', '意义 意外 意思', '意外 意思 意见', '意思 意见 意识', '意见 意识 感冒', '意识 感冒 感到', '感冒 感到 感动', '感到 感动 感动不已', '感动 感动不已 感動', '感动不已 感動 感受', '感動 感受 感受一下', '感受 感受一下 感同身受', '感受一下 感同身受 感想', '感同身受 感想 感覺', '感想 感覺 感觉', '感覺 感觉 感觉得到', '感觉 感觉得到 感触', '感觉得到 感触 感谢', '感触 感谢 愧对', '感谢 愧对 愿意', '愧对 愿意 態度', '愿意 態度 慢性', '態度 慢性 憋屈', '慢性 憋屈 應該', '憋屈 應該 成为', '應該 成为 成就', '成为 成就 成标间', '成就 成标间 成正比', '成标间 成正比 成熟', '成正比 成熟 我們', '成熟 我們 我加', '我們 我加 我姐', '我加 我姐 我定', '我姐 我定 我带', '我定 我带 我来', '我带 我来 我要', '我来 我要 我订', '我要 我订 我过', '我订 我过 或茵胆', '我过 或茵胆 户外', '或茵胆 户外 房价', '户外 房价 房前', '房价 房前 房务', '房前 房务 房卡', '房务 房卡 房型', '房卡 房型 房大', '房型 房大 房子', '房大 房子 房屋', '房子 房屋 房床', '房屋 房床 房时', '房床 房时 房给', '房时 房给 房订', '房给 房订 房费', '房订 房费 房里', '房费 房里 房間', '房里 房間 房门', '房間 房门 房间', '房门 房间 房间内', '房间 房间内 房难订', '房间内 房难订 所急', '房难订 所急 所有', '所急 所有 所说', '所有 所说 所谓', '所说 所谓 所驱', '所谓 所驱 手机', '所驱 手机 手机号', '手机 手机号 手机电池', '手机号 手机电池 手续', '手机电池 手续 才定', '手续 才定 打不开', '才定 打不开 打个', '打不开 打个 打出', '打个 打出 打开', '打出 打开 打扫', '打开 打扫 打扫卫生', '打扫 打扫卫生 打扮', '打扫卫生 打扮 打扰', '打扮 打扰 打招呼', '打扰 打招呼 打死', '打招呼 打死 打法', '打死 打法 打渔', '打法 打渔 打烊', '打渔 打烊 打理', '打烊 打理 打电话', '打理 打电话 打算', '打电话 打算 打表', '打算 打表 打车', '打表 打车 打高尔夫', '打车 打高尔夫 执勤', '打高尔夫 执勤 找到', '执勤 找到 找遍', '找到 找遍 承认', '找遍 承认 技術', '承认 技術 把守', '技術 把守 把握', '把守 把握 投入', '把握 投入 折算', '投入 折算 抢钱', '折算 抢钱 护国寺', '抢钱 护国寺 报刊', '护国寺 报刊 报国寺', '报刊 报国寺 报摊', '报国寺 报摊 报纸', '报摊 报纸 披巾', '报纸 披巾 抱怨', '披巾 抱怨 抱有', '抱怨 抱有 抱歉', '抱有 抱歉 抵价券', '抱歉 抵价券 抹杀', '抵价券 抹杀 押金', '抹杀 押金 担保', '押金 担保 担心', '担保 担心 拆迁', '担心 拆迁 拉上', '拆迁 拉上 拉开', '拉上 拉开 拉開', '拉开 拉開 拍摄', '拉開 拍摄 拐右', '拍摄 拐右 拐角处', '拐右 拐角处 拒绝', '拐角处 拒绝 拖延', '拒绝 拖延 拖拉', '拖延 拖拉 拖鞋', '拖拉 拖鞋 招呼', '拖鞋 招呼 招商', '招呼 招商 招待所', '招商 招待所 拜访', '招待所 拜访 拥堵', '拜访 拥堵 拥挤', '拥堵 拥挤 拼成', '拥挤 拼成 拼车', '拼成 拼车 拿出', '拼车 拿出 拿来', '拿出 拿来 挂牌', '拿来 挂牌 指定', '挂牌 指定 指示', '指定 指示 按摩', '指示 按摩 挑剔', '按摩 挑剔 挑选', '挑剔 挑选 挥之不去', '挑选 挥之不去 挺不错', '挥之不去 挺不错 挺全', '挺不错 挺全 挺大', '挺全 挺大 挺好吃', '挺大 挺好吃 挺快', '挺好吃 挺快 挺火', '挺快 挺火 挺热', '挺火 挺热 挺舒服', '挺热 挺舒服 挺远', '挺舒服 挺远 换乘', '挺远 换乘 换到', '换乘 换到 换后', '换到 换后 换房', '换后 换房 换楼', '换房 换楼 换气', '换楼 换气 换汇', '换气 换汇 换算', '换汇 换算 授权', '换算 授权 掉线', '授权 掉线 掏钱', '掉线 掏钱 排档', '掏钱 排档 排水', '排档 排水 排队', '排水 排队 排除', '排队 排除 接到', '排除 接到 接受', '接到 接受 接客', '接受 接客 接待', '接客 接待 接收', '接待 接收 接机', '接收 接机 接水', '接机 接水 接站', '接水 接站 接线板', '接站 接线板 接车', '接线板 接车 接近', '接车 接近 接送', '接近 接送 接送车', '接送 接送车 推介', '接送车 推介 推开', '推介 推开 推荐', '推开 推荐 提了', '推荐 提了 提交', '提了 提交 提供', '提交 提供 提出', '提供 提出 提前', '提出 提前 提升', '提前 提升 提着', '提升 提着 提示', '提着 提示 提醒', '提示 提醒 提高', '提醒 提高 插头', '提高 插头 插座', '插头 插座 搞定', '插座 搞定 搞错', '搞定 搞错 携城', '搞错 携城 携带', '携城 携带 携程', '携带 携程 携程网', '携程 携程网 摄影', '携程网 摄影 摆在', '摄影 摆在 摆放', '摆在 摆放 摆设', '摆放 摆设 摊主', '摆设 摊主 摔了一跤', '摊主 摔了一跤 摩登', '摔了一跤 摩登 撑开', '摩登 撑开 操作', '撑开 操作 攜程', '操作 攜程 支付', '攜程 支付 支持', '支付 支持 支架', '支持 支架 收入', '支架 收入 收到', '收入 收到 收取', '收到 收取 收好', '收取 收好 收拾', '收好 收拾 收看', '收拾 收看 收视', '收看 收视 收费', '收视 收费 收走', '收费 收走 收钱', '收走 收钱 收银', '收钱 收银 改住', '收银 改住 改变', '改住 改变 改名', '改变 改名 改善', '改名 改善 改水单', '改善 改水单 改过来', '改水单 改过来 改进', '改过来 改进 放下', '改进 放下 放在', '放下 放在 放心', '放在 放心 放手', '放心 放手 放新', '放手 放新 放松', '放新 放松 放水', '放松 放水 放眼望去', '放水 放眼望去 政府', '放眼望去 政府 故障', '政府 故障 效果', '故障 效果 效率', '效果 效率 敏感', '效率 敏感 教唆', '敏感 教唆 敞亮', '教唆 敞亮 敞舒適', '敞亮 敞舒適 散奥祥', '敞舒適 散奥祥 散散步', '散奥祥 散散步 散步', '散散步 散步 敦煌', '散步 敦煌 敬业', '敦煌 敬业 数字电视', '敬业 数字电视 数码产品', '数字电视 数码产品 数码港', '数码产品 数码港 敲诈', '数码港 敲诈 敲门', '敲诈 敲门 整个', '敲门 整个 整体', '整个 整体 整套', '整体 整套 整整齐齐', '整套 整整齐齐 整洁', '整整齐齐 整洁 整点', '整洁 整点 整理', '整点 整理 整齐', '整理 整齐 文件', '整齐 文件 文化', '文件 文化 文字', '文化 文字 文庙', '文字 文庙 料理', '文庙 料理 斜对面', '料理 斜对面 新华', '斜对面 新华 新城', '新华 新城 新城区', '新城 新城区 新大陆', '新城区 新大陆 新开', '新大陆 新开 新来', '新开 新来 新界', '新来 新界 新翼', '新界 新翼 新街口', '新翼 新街口 新装', '新街口 新装 新装修', '新装 新装修 新鲜', '新装修 新鲜 方便', '新鲜 方便 方便面', '方便 方便面 方向', '方便面 方向 方式', '方向 方式 方方面面', '方式 方方面面 方法', '方方面面 方法 方面', '方法 方面 施工', '方面 施工 旁边', '施工 旁边 旅友', '旁边 旅友 旅客', '旅友 旅客 旅店', '旅客 旅店 旅游', '旅店 旅游 旅游景点', '旅游 旅游景点 旅行', '旅游景点 旅行 旅行团', '旅行 旅行团 旅行者', '旅行团 旅行者 旋转', '旅行者 旋转 旗下', '旋转 旗下 无人不知', '旗下 无人不知 无处可去', '无人不知 无处可去 无太大', '无处可去 无太大 无意', '无太大 无意 无意间', '无意 无意间 无愧于', '无意间 无愧于 无所谓', '无愧于 无所谓 无扬', '无所谓 无扬 无敌', '无扬 无敌 无法', '无敌 无法 无法忍受', '无法 无法忍受 无烟', '无法忍受 无烟 无疑', '无烟 无疑 无知', '无疑 无知 无线', '无知 无线 无论是', '无线 无论是 无证', '无论是 无证 无话可说', '无证 无话可说 无锡', '无话可说 无锡 日住', '无锡 日住 日出', '日住 日出 日小假', '日出 日小假 日常', '日小假 日常 日文', '日常 日文 日期', '日文 日期 日本', '日期 日本 日用品', '日本 日用品 日至', '日用品 日至 旧些', '日至 旧些 旧旧', '旧些 旧旧 旧款', '旧旧 旧款 早上', '旧款 早上 早上好', '早上 早上好 早就', '早上好 早就 早已', '早就 早已 早晚', '早已 早晚 早晨', '早晚 早晨 早点', '早晨 早点 早睡', '早点 早睡 早茶', '早睡 早茶 早起', '早茶 早起 早醒', '早起 早醒 早餐', '早醒 早餐 早饭', '早餐 早饭 时代广场', '早饭 时代广场 时住', '时代广场 时住 时光', '时住 时光 时冷时热', '时光 时冷时热 时刻', '时冷时热 时刻 时尚', '时刻 时尚 时想', '时尚 时想 时才', '时想 时才 时有', '时才 时有 时机', '时有 时机 时段', '时机 时段 时用', '时段 时用 时要', '时用 时要 时说', '时要 时说 时问', '时说 时问 时间', '时问 时间 时间延迟', '时间 时间延迟 时隔', '时间延迟 时隔 旺季', '时隔 旺季 旺角', '旺季 旺角 昆明', '旺角 昆明 明亮', '昆明 明亮 明天', '明亮 明天 明年', '明天 明年 明日', '明年 明日 明明', '明日 明明 明显', '明明 明显 明牌', '明显 明牌 明白', '明牌 明白 昏暗', '明白 昏暗 星光', '昏暗 星光 星星', '星光 星星 星期一', '星星 星期一 星期六', '星期一 星期六 星湖', '星期六 星湖 星級', '星湖 星級 星级', '星級 星级 星级宾馆', '星级 星级宾馆 星要', '星级宾馆 星要 星里', '星要 星里 春暖花开', '星里 春暖花开 春节', '春暖花开 春节 是不是', '春节 是不是 是否', '是不是 是否 是因为', '是否 是因为 是非', '是因为 是非 显得', '是非 显得 显然', '显得 显然 显示器', '显然 显示器 显示屏', '显示器 显示屏 時候', '显示屏 時候 晃荡', '時候 晃荡 晒太阳', '晃荡 晒太阳 晓得', '晒太阳 晓得 晚上', '晓得 晚上 晚安', '晚上 晚安 晚点', '晚安 晚点 晚间', '晚点 晚间 晚餐', '晚间 晚餐 普通', '晚餐 普通 普通话', '普通 普通话 景区', '普通话 景区 景房', '景区 景房 景点', '景房 景点 景美', '景点 景美 景色', '景美 景色 景观', '景色 景观 景象', '景观 景象 暂时', '景象 暂时 暑假', '暂时 暑假 暖和', '暑假 暖和 暖气', '暖和 暖气 暖气片', '暖气 暖气片 暗暗', '暖气片 暗暗 暗示', '暗暗 暗示 更上一层楼', '暗示 更上一层楼 更不愁', '更上一层楼 更不愁 更好', '更不愁 更好 更换', '更好 更换 更新', '更换 更新 更是', '更新 更是 更近', '更是 更近 曾住', '更近 曾住 曾经', '曾住 曾经 替个', '曾经 替个 替代', '替个 替代 最后', '替代 最后 最多', '最后 最多 最大', '最多 最大 最好', '最大 最好 最新', '最好 最新 最深', '最新 最深 最深处', '最深 最深处 最绝', '最深处 最绝 最美', '最绝 最美 最贵', '最美 最贵 最赞', '最贵 最赞 最起码', '最赞 最起码 最近', '最起码 最近 最长', '最近 最长 最高', '最长 最高 月份', '最高 月份 月初', '月份 月初 月底', '月初 月底 有个', '月底 有个 有人', '有个 有人 有吉之岛', '有人 有吉之岛 有名', '有吉之岛 有名 有大', '有名 有大 有大床', '有大 有大床 有天', '有大床 有天 有如', '有天 有如 有家', '有如 有家 有山', '有家 有山 有待', '有山 有待 有所提高', '有待 有所提高 有所改善', '有所提高 有所改善 有效率', '有所改善 有效率 有方', '有效率 有方 有时', '有方 有时 有晨泳', '有时 有晨泳 有景', '有晨泳 有景 有梅', '有景 有梅 有段', '有梅 有段 有求', '有段 有求 有没有', '有求 有没有 有油点', '有没有 有油点 有海', '有油点 有海 有点', '有海 有点 有点像', '有点 有点像 有点累', '有点像 有点累 有着', '有点累 有着 有礼', '有着 有礼 有禮地', '有礼 有禮地 有种', '有禮地 有种 有股', '有种 有股 有误', '有股 有误 有车', '有误 有车 有轨电车', '有车 有轨电车 有过', '有轨电车 有过 有重', '有过 有重 有静', '有重 有静 有飘窗', '有静 有飘窗 有點', '有飘窗 有點 朋友', '有點 朋友 朋友家', '朋友 朋友家 服务', '朋友家 服务 服务业', '服务 服务业 服务中心', '服务业 服务中心 服务台', '服务中心 服务台 服务员', '服务台 服务员 服务周到', '服务员 服务周到 服务态度', '服务周到 服务态度 服务水平', '服务态度 服务水平 服务生', '服务水平 服务生 服务行业', '服务生 服务行业 服务设施', '服务行业 服务设施 服务质量', '服务设施 服务质量 服务费', '服务质量 服务费 服務', '服务费 服務 服務員', '服務 服務員 服務員為', '服務員 服務員為 服務員還', '服務員為 服務員還 服務態度', '服務員還 服務態度 服用', '服務態度 服用 朗庭', '服用 朗庭 望远镜', '朗庭 望远镜 朝南', '望远镜 朝南 朝右', '朝南 朝右 朝向', '朝右 朝向 朝阳', '朝向 朝阳 朝鲜', '朝阳 朝鲜 期间', '朝鲜 期间 木头', '期间 木头 木板', '木头 木板 木炭', '木板 木炭 未眠', '木炭 未眠 未退', '未眠 未退 本来', '未退 本来 本次', '本来 本次 朱熔基', '本次 朱熔基 朴实', '朱熔基 朴实 机会', '朴实 机会 机关', '机会 机关 机器声', '机关 机器声 机场', '机器声 机场 机票', '机场 机票 机车', '机票 机车 杂志', '机车 杂志 李南滨路', '杂志 李南滨路 李朝', '李南滨路 李朝 条件', '李朝 条件 来到', '条件 来到 来回', '来到 来回 来电', '来回 来电 来自', '来电 来自 来说', '来自 来说 松软', '来说 松软 板上', '松软 板上 极力推荐', '板上 极力推荐 极差', '极力推荐 极差 极贵', '极差 极贵 枕头', '极贵 枕头 果汁', '枕头 果汁 果盘', '果汁 果盘 果篮', '果盘 果篮 某某', '果篮 某某 柜台', '某某 柜台 柜后', '柜台 柜后 柠檬茶', '柜后 柠檬茶 查找', '柠檬茶 查找 查看', '查找 查看 查询', '查看 查询 标准', '查询 标准 标准配置', '标准 标准配置 标准间', '标准配置 标准间 标志', '标准间 标志 标房', '标志 标房 标示', '标房 标示 标间', '标示 标间 栈桥', '标间 栈桥 树立', '栈桥 树立 样子', '树立 样子 核实', '样子 核实 根本', '核实 根本 格调', '根本 格调 桌上', '格调 桌上 桌子', '桌上 桌子 桌椅', '桌子 桌椅 桑拿', '桌椅 桑拿 档次', '桑拿 档次 桥到', '档次 桥到 桶装', '桥到 桶装 桶装水', '桶装 桶装水 检查', '桶装水 检查 森林', '检查 森林 椅子', '森林 椅子 植得', '椅子 植得 植物园', '植得 植物园 楼上', '植物园 楼上 楼下', '楼上 楼下 楼层', '楼下 楼层 楼市', '楼层 楼市 楼梯', '楼市 楼梯 楼道', '楼梯 楼道 楼顶', '楼道 楼顶 概念', '楼顶 概念 榴莲', '概念 榴莲 標準', '榴莲 標準 横向', '標準 横向 機構', '横向 機構 橡木', '機構 橡木 檔次', '橡木 檔次 欠缺', '檔次 欠缺 次住', '欠缺 次住 次日', '次住 次日 次晨泳', '次日 次晨泳 欢迎', '次晨泳 欢迎 欣赏', '欢迎 欣赏 欧式', '欣赏 欧式 款式', '欧式 款式 歌舞', '款式 歌舞 正中', '歌舞 正中 正在', '正中 正在 正大', '正在 正大 正好', '正大 正好 正宗', '正好 正宗 正对', '正宗 正对 正常', '正对 正常 正式', '正常 正式 正是', '正式 正是 正朝', '正是 正朝 正赶上', '正朝 正赶上 正门', '正赶上 正门 此次', '正门 此次 此起彼伏', '此次 此起彼伏 步行', '此起彼伏 步行 步行街', '步行 步行街 步骤', '步行街 步骤 歧视', '步骤 歧视 死板', '歧视 死板 殊堪嘉許', '死板 殊堪嘉許 残留', '殊堪嘉許 残留 殡仪馆', '残留 殡仪馆 殷勤', '殡仪馆 殷勤 每个', '殷勤 每个 每人', '每个 每人 每位', '每人 每位 每周三', '每位 每周三 每天', '每周三 每天 每天晚上', '每天 每天晚上 每家', '每天晚上 每家 每年', '每家 每年 每房', '每年 每房 每晚', '每房 每晚 每月', '每晚 每月 每次', '每月 每次 每间房', '每次 每间房 比不上', '每间房 比不上 比住', '比不上 比住 比做', '比住 比做 比悦华', '比做 比悦华 比标间', '比悦华 比标间 比汉庭', '比标间 比汉庭 比較', '比汉庭 比較 比较', '比較 比较 比较复杂', '比较 比较复杂 比较满意', '比较复杂 比较满意 毛巾', '比较满意 毛巾 毛病', '毛巾 毛病 毛笔', '毛病 毛笔 毛衣', '毛笔 毛衣 毛裤', '毛衣 毛裤 民居', '毛裤 民居 民族风情', '民居 民族风情 气味', '民族风情 气味 气息', '气味 气息 气愤', '气息 气愤 气氛', '气愤 气氛 气派', '气氛 气派 气韵', '气派 气韵 水仙花', '气韵 水仙花 水准', '水仙花 水准 水力', '水准 水力 水壶', '水力 水壶 水平', '水壶 水平 水散', '水平 水散 水果', '水散 水果 水果摊', '水果 水果摊 水果盘', '水果摊 水果盘 水温', '水果盘 水温 水量', '水温 水量 水龙头', '水量 水龙头 永远', '水龙头 永远 汉口', '永远 汉口 汕头', '汉口 汕头 江苏', '汕头 江苏 江边', '江苏 江边 污渍', '江边 污渍 污迹', '污渍 污迹 汤山', '污迹 汤山 汽车', '汤山 汽车 汽车站', '汽车 汽车站 沈阳', '汽车站 沈阳 沐浴', '沈阳 沐浴 沐浴露', '沐浴 沐浴露 沒有', '沐浴露 沒有 沒泡', '沒有 沒泡 沙发', '沒泡 沙发 沙发床', '沙发 沙发床 沙嘴', '沙发床 沙嘴 沙滩', '沙嘴 沙滩 沙田', '沙滩 沙田 沙發', '沙田 沙發 沟通', '沙發 沟通 没买成', '沟通 没买成 没事', '没买成 没事 没人', '没事 没人 没什么', '没人 没什么 没住', '没什么 没住 没关', '没住 没关 没到', '没关 没到 没大床', '没到 没大床 没套', '没大床 没套 没得说', '没套 没得说 没想到', '没得说 没想到 没房', '没想到 没房 没睡', '没房 没睡 没说的', '没睡 没说的 河南', '没说的 河南 河畔', '河南 河畔 河鲜', '河畔 河鲜 油污', '河鲜 油污 油漆', '油污 油漆 油麻', '油漆 油麻 沿海', '油麻 沿海 沿途', '沿海 沿途 泉城', '沿途 泉城 泉州', '泉城 泉州 泉州市', '泉州 泉州市 泉酒', '泉州市 泉酒 泊车', '泉酒 泊车 法式', '泊车 法式 泛海', '法式 泛海 泡吧', '泛海 泡吧 泡面', '泡吧 泡面 注意', '泡面 注意 注明', '注意 注明 注重', '注明 注重 泳池', '注重 泳池 洁净', '泳池 洁净 洋货', '洁净 洋货 洋酒', '洋货 洋酒 洗个', '洋酒 洗个 洗发膏', '洗个 洗发膏 洗发露', '洗发膏 洗发露 洗完', '洗发露 洗完 洗手间', '洗完 洗手间 洗漱', '洗手间 洗漱 洗漱间', '洗漱 洗漱间 洗澡', '洗漱间 洗澡 洗澡水', '洗澡 洗澡水 洗澡间', '洗澡水 洗澡间 洗脸盆', '洗澡间 洗脸盆 洗衣', '洗脸盆 洗衣 洗衣店', '洗衣 洗衣店 洗衣服', '洗衣店 洗衣服 洗面盆', '洗衣服 洗面盆 洛阳', '洗面盆 洛阳 洲际', '洛阳 洲际 活动', '洲际 活动 活该', '活动 活该 流畅', '活该 流畅 浅水湾', '流畅 浅水湾 济南', '浅水湾 济南 浓烈', '济南 浓烈 浓重', '浓烈 浓重 浙江', '浓重 浙江 浪漫', '浙江 浪漫 浪费', '浪漫 浪费 浴室', '浪费 浴室 浴室用品', '浴室 浴室用品 浴缸', '浴室用品 浴缸 浴袍', '浴缸 浴袍 海天', '浴袍 海天 海宁', '海天 海宁 海带', '海宁 海带 海景', '海带 海景 海景房', '海景 海景房 海标', '海景房 海标 海水', '海标 海水 海河', '海水 海河 海洋公园', '海河 海洋公园 海港', '海洋公园 海港 海滩', '海港 海滩 海边', '海滩 海边 海逸', '海边 海逸 海都', '海逸 海都 海风', '海都 海风 海鲜', '海风 海鲜 海鲜城', '海鲜 海鲜城 海鲜酒楼', '海鲜城 海鲜酒楼 涂个', '海鲜酒楼 涂个 消夜', '涂个 消夜 消毒', '消夜 消毒 消费', '消毒 消费 消费水平', '消费 消费水平 涉嫌', '消费水平 涉嫌 润肤霜', '涉嫌 润肤霜 涨潮', '润肤霜 涨潮 液晶', '涨潮 液晶 液晶屏', '液晶 液晶屏 液晶电脑', '液晶屏 液晶电脑 液晶电视', '液晶电脑 液晶电视 淋坏', '液晶电视 淋坏 淋浴', '淋坏 淋浴 淋浴房', '淋浴 淋浴房 淑女', '淋浴房 淑女 淡季', '淑女 淡季 深刻', '淡季 深刻 混乱', '深刻 混乱 清凉', '混乱 清凉 清凉寺', '清凉 清凉寺 清幽', '清凉寺 清幽 清新', '清幽 清新 清早', '清新 清早 清晰', '清早 清晰 清楚', '清晰 清楚 清泥洼', '清楚 清泥洼 清洁', '清泥洼 清洁 清洁工', '清洁 清洁工 清清楚楚', '清洁工 清清楚楚 清澈', '清清楚楚 清澈 清爽', '清澈 清爽 清理', '清爽 清理 清醒', '清理 清醒 清静', '清醒 清静 清香', '清静 清香 渔港', '清香 渔港 渡假', '渔港 渡假 温和', '渡假 温和 温度', '温和 温度 温情', '温度 温情 温暖', '温情 温暖 温泉', '温暖 温泉 温泉水', '温泉 温泉水 温馨', '温泉水 温馨 港元', '温馨 港元 港币', '港元 港币 港澳', '港币 港澳 游个泳', '港澳 游个泳 游回来', '游个泳 游回来 游客', '游回来 游客 游泳', '游客 游泳 游泳池', '游泳 游泳池 游泳馆', '游泳池 游泳馆 游玩', '游泳馆 游玩 游艇', '游玩 游艇 游览', '游艇 游览 湖州', '游览 湖州 湖州市', '湖州 湖州市 湖景大床', '湖州市 湖景大床 湖笔', '湖景大床 湖笔 湖边', '湖笔 湖边 湮散', '湖边 湮散 準間', '湮散 準間 溫文', '準間 溫文 溫泉', '溫文 溫泉 滇腔', '溫泉 滇腔 满好', '滇腔 满好 满意', '满好 满意 满足', '满意 满足 滿意', '满足 滿意 漂亮', '滿意 漂亮 漂浮', '漂亮 漂浮 漏水', '漂浮 漏水 演奏', '漏水 演奏 漫步', '演奏 漫步 漳州', '漫步 漳州 潮气', '漳州 潮气 火车', '潮气 火车 火车票', '火车 火车票 火车站', '火车票 火车站 火锅', '火车站 火锅 灭蚊器', '火锅 灭蚊器 灯光', '灭蚊器 灯光 灯光设计', '灯光 灯光设计 灵活', '灯光设计 灵活 炮台', '灵活 炮台 点到', '炮台 点到 点前', '点到 点前 点名', '点前 点名 点多', '点名 点多 点多到', '点多 点多到 点心', '点多到 点心 点点', '点心 点点 点至', '点点 点至 点评', '点至 点评 点钟', '点评 点钟 烘干', '点钟 烘干 烟台', '烘干 烟台 烟台山', '烟台 烟台山 烟味', '烟台山 烟味 烟酒', '烟味 烟酒 烧来', '烟酒 烧来 烧水', '烧来 烧水 烧烤', '烧水 烧烤 热得', '烧烤 热得 热心', '热得 热心 热情', '热心 热情 热情周到', '热情 热情周到 热水', '热情周到 热水 热水器', '热水 热水器 热水袋', '热水器 热水袋 热醒', '热水袋 热醒 热闹', '热醒 热闹 热风', '热闹 热风 焦点', '热风 焦点 照常', '焦点 照常 照相机', '照常 照相机 照顾', '照相机 照顾 熄灯', '照顾 熄灯 熟悉', '熄灯 熟悉 熱情', '熟悉 熱情 熱茶', '熱情 熱茶 燕窝', '熱茶 燕窝 爆慢', '燕窝 爆慢 爱人', '爆慢 爱人 爱理不理', '爱人 爱理不理 父女', '爱理不理 父女 片仔癀', '父女 片仔癀 牌号', '片仔癀 牌号 牌子', '牌号 牌子 牙刷', '牌子 牙刷 牛奶', '牙刷 牛奶 牛气', '牛奶 牛气 牛肉', '牛气 牛肉 牡丹', '牛肉 牡丹 物价', '牡丹 物价 物品', '物价 物品 物有所值', '物品 物有所值 物美', '物有所值 物美 物美价廉', '物美 物美价廉 物超所值', '物美价廉 物超所值 牵强', '物超所值 牵强 特产', '牵强 特产 特别', '特产 特别 特别强调', '特别 特别强调 特别感谢', '特别强调 特别感谢 特地', '特别感谢 特地 特多', '特地 特多 特意', '特多 特意 特点', '特意 特点 特色', '特点 特色 特色小吃', '特色 特色小吃 特色菜', '特色小吃 特色菜 特质', '特色菜 特质 犹豫', '特质 犹豫 狂喜', '犹豫 狂喜 狠心', '狂喜 狠心 独立', '狠心 独立 狭小', '独立 狭小 狼狈', '狭小 狼狈 王一品', '狼狈 王一品 王府井', '王一品 王府井 王杰', '王府井 王杰 玩得', '王杰 玩得 玩耍', '玩得 玩耍 玫瑰', '玩耍 玫瑰 环境', '玫瑰 环境 环境优美', '环境 环境优美 环境保护', '环境优美 环境保护 现代', '环境保护 现代 现在', '现代 现在 现象', '现在 现象 现金', '现象 现金 玻璃', '现金 玻璃 玻璃幕墙', '玻璃 玻璃幕墙 班机', '玻璃幕墙 班机 班次', '班机 班次 班车', '班次 班车 理念', '班车 理念 理想', '理念 理想 理由', '理想 理由 理解', '理由 理解 瑕疵', '理解 瑕疵 瑜珈', '瑕疵 瑜珈 環境', '瑜珈 環境 甜品', '環境 甜品 甜品店', '甜品 甜品店 甜美', '甜品店 甜美 生动', '甜美 生动 生就', '生动 生就 生意', '生就 生意 生日', '生意 生日 生活', '生日 生活 生记', '生活 生记 用具', '生记 用具 用品', '用具 用品 用手', '用品 用手 用过', '用手 用过 用餐', '用过 用餐 田园', '用餐 田园 申明', '田园 申明 申请', '申明 申请 电冰箱', '申请 电冰箱 电吹风', '电冰箱 电吹风 电器', '电吹风 电器 电控', '电器 电控 电梯', '电控 电梯 电梯间', '电梯 电梯间 电脑', '电梯间 电脑 电脑桌', '电脑 电脑桌 电视', '电脑桌 电视 电视塔', '电视 电视塔 电视机', '电视塔 电视机 电话', '电视机 电话 电话费', '电话 电话费 电车', '电话费 电车 电车站', '电车 电车站 畅谈', '电车站 畅谈 畅通', '畅谈 畅通 留下', '畅通 留下 留园', '留下 留园 留在', '留园 留在 留好', '留在 留好 留意', '留好 留意 留言', '留意 留言 略显', '留言 略显 當然', '略显 當然 疑惑', '當然 疑惑 疑祥', '疑惑 疑祥 疑问请', '疑祥 疑问请 疲劳', '疑问请 疲劳 痊愈', '疲劳 痊愈 痛苦', '痊愈 痛苦 登記時', '痛苦 登記時 登记', '登記時 登记 發電外', '登记 發電外 發電機', '發電外 發電機 白天', '發電機 白天 白问', '白天 白问 百佳', '白问 百佳 百元', '百佳 百元 百叶窗', '百元 百叶窗 百家', '百叶窗 百家 百樂來', '百家 百樂來 百米', '百樂來 百米 百货商场', '百米 百货商场 百问不厌', '百货商场 百问不厌 的士', '百问不厌 的士 的紅', '的士 的紅 的關', '的紅 的關 皇冠', '的關 皇冠 皇后', '皇冠 皇后 皇帝', '皇后 皇帝 皇潮', '皇帝 皇潮 皮夹', '皇潮 皮夹 皱着眉头', '皮夹 皱着眉头 盆在', '皱着眉头 盆在 盛开', '盆在 盛开 目前', '盛开 目前 盯上', '目前 盯上 直到', '盯上 直到 直接', '直到 直接 直白', '直接 直白 直达', '直白 直达 直达车', '直达 直达车 直面', '直达车 直面 相信', '直面 相信 相关', '相信 相关 相对', '相关 相对 相对来说', '相对 相对来说 相差', '相对来说 相差 相应', '相差 相应 相当', '相应 相当 相当于', '相当 相当于 相比', '相当于 相比 相符', '相比 相符 相送', '相符 相送 相邻', '相送 相邻 省事', '相邻 省事 省点', '省事 省点 省钱', '省点 省钱 看不到', '省钱 看不到 看出', '看不到 看出 看到', '看出 看到 看得出', '看到 看得出 看得出来', '看得出 看得出来 看海', '看得出来 看海 看电视', '看海 看电视 看看', '看电视 看看 看着', '看看 看着 看见', '看着 看见 看过', '看见 看过 真不叫', '看过 真不叫 真不错', '真不叫 真不错 真切', '真不错 真切 真实', '真切 真实 真心诚意', '真实 真心诚意 真是', '真心诚意 真是 真是太', '真是 真是太 真有', '真是太 真有 真正', '真有 真正 真爽', '真正 真爽 真的', '真爽 真的 真诚', '真的 真诚 眼光', '真诚 眼光 眼睛', '眼光 眼睛 着想', '眼睛 着想 睡不着', '着想 睡不着 睡得', '睡不着 睡得 睡懒觉', '睡得 睡懒觉 睡眠', '睡懒觉 睡眠 睡着', '睡眠 睡着 睡觉', '睡着 睡觉 知名度', '睡觉 知名度 知道', '知名度 知道 短信', '知道 短信 短途', '短信 短途 石家庄', '短途 石家庄 矿泉水', '石家庄 矿泉水 码头', '矿泉水 码头 破例', '码头 破例 破旧', '破例 破旧 破烂', '破旧 破烂 破财', '破烂 破财 破败', '破财 破败 硬件', '破败 硬件 确实', '硬件 确实 确认', '确实 确认 碧波', '确认 碧波 碰到', '碧波 碰到 確實', '碰到 確實 磨砂玻璃', '確實 磨砂玻璃 礼品', '磨砂玻璃 礼品 礼宾', '礼品 礼宾 礼拜', '礼宾 礼拜 礼貌', '礼拜 礼貌 福州', '礼貌 福州 福建', '福州 福建 禮儀', '福建 禮儀 离上', '禮儀 离上 离东百', '离上 离东百 离后', '离东百 离后 离太', '离后 离太 离店', '离太 离店 离开', '离店 离开 离新', '离开 离新 离海', '离新 离海 离琶洲', '离海 离琶洲 离门', '离琶洲 离门 私人', '离门 私人 私密', '私人 私密 种类', '私密 种类 科学馆', '种类 科学馆 秦皇岛', '科学馆 秦皇岛 积水', '秦皇岛 积水 积水潭', '积水 积水潭 称为', '积水潭 称为 称作', '称为 称作 称赞', '称作 称赞 稍差', '称赞 稍差 稍微', '稍差 稍微 稍慢', '稍微 稍慢 稍旧', '稍慢 稍旧 稍贵', '稍旧 稍贵 稍远', '稍贵 稍远 稳定', '稍远 稳定 空气', '稳定 空气 空气流通', '空气 空气流通 空气清新', '空气流通 空气清新 空調', '空气清新 空調 空调', '空調 空调 空间', '空调 空间 穿梭', '空间 穿梭 穿过', '穿梭 穿过 突出', '穿过 突出 窗口', '突出 窗口 窗台上', '窗口 窗台上 窗外', '窗台上 窗外 窗头', '窗外 窗头 窗子', '窗头 窗子 窗帘', '窗子 窗帘 窗户', '窗帘 窗户 窗簾', '窗户 窗簾 窗边', '窗簾 窗边 窝心', '窗边 窝心 立即', '窝心 立即 立着', '立即 立着 竞争力', '立着 竞争力 竭船', '竞争力 竭船 端庄', '竭船 端庄 竹炭', '端庄 竹炭 笑容', '竹炭 笑容 笑脸', '笑容 笑脸 笔记本', '笑脸 笔记本 符合', '笔记本 符合 第一', '符合 第一 第一天', '第一 第一天 第一条', '第一天 第一条 第一次', '第一条 第一次 第一流', '第一次 第一流 第三', '第一流 第三 第二天', '第三 第二天 第二次', '第二天 第二次 第四', '第二次 第四 笼头', '第四 笼头 等于', '笼头 等于 等候', '等于 等候 等待', '等候 等待 答复', '等待 答复 答案', '答复 答案 签约', '答案 签约 简但', '签约 简但 简单', '简但 简单 简洁', '简单 简洁 简约', '简洁 简约 简陋', '简约 简陋 算了', '简陋 算了 算大', '算了 算大 算好', '算大 算好 算新', '算好 算新 算是', '算新 算是 算高', '算是 算高 管家', '算高 管家 管理', '管家 管理 管理水平', '管理 管理水平 箱包', '管理水平 箱包 簡直', '箱包 簡直 粤式', '簡直 粤式 粥品', '粤式 粥品 精神', '粥品 精神 精致', '精神 精致 糖浆', '精致 糖浆 糟糕', '糖浆 糟糕 系统', '糟糕 系统 素菜', '系统 素菜 素质', '素菜 素质 索取', '素质 索取 索菲特', '索取 索菲特 紧张', '索菲特 紧张 紧靠', '紧张 紧靠 累个', '紧靠 累个 給人', '累个 給人 綠化', '給人 綠化 緊張', '綠化 緊張 繁华', '緊張 繁华 红头', '繁华 红头 红旗路', '红头 红旗路 红灯笼', '红旗路 红灯笼 红砖', '红灯笼 红砖 红茶', '红砖 红茶 级别', '红茶 级别 纸鹤', '级别 纸鹤 线路', '纸鹤 线路 练习场', '线路 练习场 细察', '练习场 细察 细心', '细察 细心 细致', '细心 细致 细节', '细致 细节 终点', '细节 终点 经历', '终点 经历 经济', '经历 经济 经济型', '经济 经济型 经理', '经济型 经理 经营', '经理 经营 经贸', '经营 经贸 经路', '经贸 经路 经路店', '经路 经路店 经验', '经路店 经验 结帐', '经验 结帐 结束', '结帐 结束 结构', '结束 结构 结账', '结构 结账 给予', '结账 给予 给我发', '给予 给我发 络腮胡子', '给我发 络腮胡子 绝佳', '络腮胡子 绝佳 继续', '绝佳 继续 续订', '继续 续订 维修', '续订 维修 维多利亚', '维修 维多利亚 维护', '维多利亚 维护 维港', '维护 维港 综合', '维港 综合 绿豆汤', '综合 绿豆汤 缆车', '绿豆汤 缆车 编写', '缆车 编写 缘故', '编写 缘故 缺乏', '缘故 缺乏 缺少', '缺乏 缺少 缺点', '缺少 缺点 网上', '缺点 网上 网友', '网上 网友 网吧', '网友 网吧 网络', '网吧 网络 网评', '网络 网评 网速', '网评 网速 网速慢', '网速 网速慢 网页', '网速慢 网页 罗湖', '网页 罗湖 罢工', '罗湖 罢工 羊杂', '罢工 羊杂 美中不足', '羊杂 美中不足 美丽', '美中不足 美丽 美味', '美丽 美味 美国', '美味 美国 美好', '美国 美好 美心', '美好 美心 美景', '美心 美景 美极了', '美景 美极了 美梦', '美极了 美梦 美的', '美梦 美的 美食', '美的 美食 美食街', '美食 美食街 群山', '美食街 群山 羽绒被', '群山 羽绒被 翻新', '羽绒被 翻新 老人', '翻新 老人 老先生', '老人 老先生 老公', '老先生 老公 老化', '老公 老化 老城区', '老化 老城区 老外', '老城区 老外 老妈', '老外 老妈 老婆', '老妈 老婆 老字号', '老婆 老字号 老实', '老字号 老实 老年', '老实 老年 老式', '老年 老式 老态', '老式 老态 老旧', '老态 老旧 老款', '老旧 老款 老爷爷', '老款 老爷爷 老牌', '老爷爷 老牌 老虎滩', '老牌 老虎滩 考察', '老虎滩 考察 考慮', '考察 考慮 考虑', '考慮 考虑 考虑一下', '考虑 考虑一下 而論', '考虑一下 而論 耐心', '而論 耐心 耽搁', '耐心 耽搁 耽误时间', '耽搁 耽误时间 聊天', '耽误时间 聊天 职业化', '聊天 职业化 联系', '职业化 联系 聚会', '联系 聚会 肇庆', '聚会 肇庆 肇庆市', '肇庆 肇庆市 肉片', '肇庆市 肉片 肥皂', '肉片 肥皂 肯定', '肥皂 肯定 胃病', '肯定 胃病 胃药', '胃病 胃药 胃黏膜', '胃药 胃黏膜 背山面', '胃黏膜 背山面 胡同', '背山面 胡同 胶囊', '胡同 胶囊 能住', '胶囊 能住 能力', '能住 能力 能否', '能力 能否 能回', '能否 能回 能够', '能回 能够 能比', '能够 能比 脚面', '能比 脚面 腿脚', '脚面 腿脚 膏药', '腿脚 膏药 自动扶梯', '膏药 自动扶梯 自助', '自动扶梯 自助 自助游', '自助 自助游 自助餐', '自助游 自助餐 自助餐厅', '自助餐 自助餐厅 自带', '自助餐厅 自带 自然', '自带 自然 自然环境', '自然 自然环境 自然风', '自然环境 自然风 自由', '自然风 自由 自行车', '自由 自行车 自驾', '自行车 自驾 自驾游', '自驾 自驾游 自驾车', '自驾游 自驾车 臭气熏天', '自驾车 臭气熏天 至上', '臭气熏天 至上 至少', '至上 至少 致命', '至少 致命 舍得', '致命 舍得 舒心', '舍得 舒心 舒服', '舒心 舒服 舒畅', '舒服 舒畅 舒适', '舒畅 舒适 航班', '舒适 航班 航空', '航班 航空 船票', '航空 船票 船腔挲', '船票 船腔挲 船菜', '船腔挲 船菜 良好', '船菜 良好 色调', '良好 色调 艺术性', '色调 艺术性 艾美', '艺术性 艾美 节假日', '艾美 节假日 花园', '节假日 花园 花园式', '花园 花园式 花园街', '花园式 花园街 花園', '花园街 花園 花样', '花園 花样 花洒', '花样 花洒 花生米', '花洒 花生米 花盆', '花生米 花盆 花花', '花盆 花花 花花草草', '花花 花花草草 苍蝇', '花花草草 苍蝇 苦心', '苍蝇 苦心 英国', '苦心 英国 英式', '英国 英式 范围', '英式 范围 茶水', '范围 茶水 茶餐厅', '茶水 茶餐厅 荃湾', '茶餐厅 荃湾 荒凉', '荃湾 荒凉 药店', '荒凉 药店 药片', '药店 药片 莫高窟', '药片 莫高窟 莲香楼', '莫高窟 莲香楼 获赠', '莲香楼 获赠 菜品', '获赠 菜品 菜市场', '菜品 菜市场 菜汤', '菜市场 菜汤 菜肴', '菜汤 菜肴 营业', '菜肴 营业 营业时间', '营业 营业时间 落伍', '营业时间 落伍 落地窗', '落伍 落地窗 落差', '落地窗 落差 著作', '落差 著作 著名', '著作 著名 葡萄酒', '著名 葡萄酒 董事长', '葡萄酒 董事长 蒙蒙细雨', '董事长 蒙蒙细雨 蓝天', '蒙蒙细雨 蓝天 蔚蓝', '蓝天 蔚蓝 蔡陆线', '蔚蓝 蔡陆线 藏独', '蔡陆线 藏独 蘑菇', '藏独 蘑菇 虎丘', '蘑菇 虎丘 號和', '虎丘 號和 號樓', '號和 號樓 虹口', '號樓 虹口 虽不像', '虹口 虽不像 虽小', '虽不像 虽小 虽达', '虽小 虽达 蚊子', '虽达 蚊子 蛋糕', '蚊子 蛋糕 蛮高', '蛋糕 蛮高 蜜月旅行', '蛮高 蜜月旅行 行带', '蜜月旅行 行带 行政', '行带 行政 行李', '行政 行李 行李房', '行李 行李房 行李架', '行李房 行李架 行程', '行李架 行程 行走', '行程 行走 街上', '行走 街上 街口', '街上 街口 街头', '街口 街头 街道', '街头 街道 衛生潔淨', '街道 衛生潔淨 衛生間', '衛生潔淨 衛生間 衡量', '衛生間 衡量 衢州', '衡量 衢州 衣服', '衢州 衣服 衣柜', '衣服 衣柜 补上', '衣柜 补上 表扬', '补上 表扬 表演', '表扬 表演 表现', '表演 表现 表示歉意', '表现 表示歉意 被动', '表示歉意 被动 被单', '被动 被单 被子', '被单 被子 被扣', '被子 被扣 被褥', '被扣 被褥 装修', '被褥 装修 装备', '装修 装备 装潢', '装备 装潢 装璜', '装潢 装璜 装袋', '装璜 装袋 装设', '装袋 装设 装饰', '装设 装饰 裝修', '装饰 裝修 裝修過', '裝修 裝修過 裡用', '裝修過 裡用 裤兜', '裡用 裤兜 西到', '裤兜 西到 西北', '西到 西北 西单', '西北 西单 西南', '西单 西南 西四', '西南 西四 西坝', '西四 西坝 西宁', '西坝 西宁 西宁市', '西宁 西宁市 西式', '西宁市 西式 西方', '西式 西方 西楼', '西方 西楼 西环', '西楼 西环 西直门', '西环 西直门 西藏', '西直门 西藏 西街', '西藏 西街 西路', '西街 西路 西门子', '西路 西门子 西餐', '西门子 西餐 西餐厅', '西餐 西餐厅 要不得', '西餐厅 要不得 要出', '要不得 要出 要定', '要出 要定 要收', '要定 要收 要求', '要收 要求 要花费', '要求 要花费 覆盖', '要花费 覆盖 視野空間', '覆盖 視野空間 親切', '視野空間 親切 覺得', '親切 覺得 见不着', '覺得 见不着 见到', '见不着 见到 见效', '见到 见效 观景', '见效 观景 观看电视', '观景 观看电视 规定', '观看电视 规定 规模', '规定 规模 规范', '规模 规范 视而不见', '规范 视而不见 视野', '视而不见 视野 觉得', '视野 觉得 角度', '觉得 角度 角落', '角度 角落 解决', '角落 解决 解决困难', '解决 解决困难 解决问题', '解决困难 解决问题 解放北路', '解决问题 解放北路 解渴', '解放北路 解渴 解答', '解渴 解答 言语', '解答 言语 設備', '言语 設備 設施', '設備 設施 調試', '設施 調試 謝謝', '調試 謝謝 警察', '謝謝 警察 警惕', '警察 警惕 警觉性', '警惕 警觉性 计较', '警觉性 计较 订一晚', '计较 订一晚 订单', '订一晚 订单 订如家', '订单 订如家 订房', '订如家 订房 订票', '订房 订票 订过', '订票 订过 订餐', '订过 订餐 认为', '订餐 认为 认真', '认为 认真 认识', '认真 认识 讨厌', '认识 讨厌 训练有素', '讨厌 训练有素 记住', '训练有素 记住 记录', '记住 记录 记得', '记录 记得 记性', '记得 记性 讲究', '记性 讲究 许多', '讲究 许多 设备', '许多 设备 设施', '设备 设施 设有', '设施 设有 设法', '设有 设法 设置', '设法 设置 设计', '设置 设计 访客', '设计 访客 证明', '访客 证明 评价', '证明 评价 评论', '评价 评论 试图', '评论 试图 试试', '试图 试试 试试看', '试试 试试看 询问', '试试看 询问 该店', '询问 该店 该换', '该店 该换 该死', '该换 该死 详细', '该死 详细 语气', '详细 语气 诱导', '语气 诱导 说不过去', '诱导 说不过去 说个', '说不过去 说个 说声', '说个 说声 说好', '说声 说好 说实话', '说好 说实话 说得过去', '说实话 说得过去 说明', '说得过去 说明 说离', '说明 说离 说话', '说离 说话 说起', '说话 说起 请勿打扰', '说起 请勿打扰 诸多', '请勿打扰 诸多 调到', '诸多 调到 调整', '调到 调整 调节', '调整 调节 调解', '调节 调解 谈不上', '调解 谈不上 谈谈', '谈不上 谈谈 谢谢', '谈谈 谢谢 豁口', '谢谢 豁口 豆腐', '豁口 豆腐 豆腐干', '豆腐 豆腐干 象个', '豆腐干 象个 豪华', '象个 豪华 豪華標', '豪华 豪華標 購物區', '豪華標 購物區 负责', '購物區 负责 质数', '负责 质数 质素', '质数 质素 质量', '质素 质量 购买', '质量 购买 购物', '购买 购物 购物中心', '购物 购物中心 购物点', '购物中心 购物点 贴心', '购物点 贴心 贴着', '贴心 贴着 贵上', '贴着 贵上 贵在', '贵上 贵在 贵太', '贵在 贵太 贵宾楼', '贵太 贵宾楼 费时', '贵宾楼 费时 费用', '费时 费用 资料', '费用 资料 赏心悦目', '资料 赏心悦目 赘述', '赏心悦目 赘述 赚钱', '赘述 赚钱 赠送', '赚钱 赠送 赤柱', '赠送 赤柱 赫赫', '赤柱 赫赫 走上', '赫赫 走上 走出', '走上 走出 走动', '走出 走动 走廊', '走动 走廊 走法', '走廊 走法 走走', '走法 走走 走路', '走走 走路 走过', '走路 走过 走进', '走过 走进 赶上', '走进 赶上 赶巧', '赶上 赶巧 赶紧', '赶巧 赶紧 起到', '赶紧 起到 起床', '起到 起床 起步', '起床 起步 起步价', '起步 起步价 起码', '起步价 起码 超一流', '起码 超一流 超值', '超一流 超值 超出', '超值 超出 超前', '超出 超前 超多', '超前 超多 超大', '超多 超大 超好', '超大 超好 超市', '超好 超市 超慢', '超市 超慢 超爽', '超慢 超爽 超级', '超爽 超级 超赞', '超级 超赞 超软', '超赞 超软 超过', '超软 超过 超近', '超过 超近 足够', '超近 足够 足夠', '足够 足夠 跑上来', '足夠 跑上来 跑马', '跑上来 跑马 跑马地', '跑马 跑马地 距离', '跑马地 距离 跟不上', '距离 跟不上 跟前', '跟不上 跟前 路上车', '跟前 路上车 路况', '路上车 路况 路到', '路况 路到 路口', '路到 路口 路标', '路口 路标 路段', '路标 路段 路程', '路段 路程 路窄', '路程 路窄 路线', '路窄 路线 路线图', '路线 路线图 路费', '路线图 路费 路车', '路费 路车 路边', '路车 路边 路过', '路边 路过 路面', '路过 路面 跳闸', '路面 跳闸 踏實', '跳闸 踏實 身体', '踏實 身体 躺上去', '身体 躺上去 車程', '躺上去 車程 车位', '車程 车位 车到', '车位 车到 车场', '车到 车场 车头', '车场 车头 车库', '车头 车库 车快', '车库 车快 车接', '车快 车接 车程', '车接 车程 车站', '车程 车站 车费', '车站 车费 车里', '车费 车里 车门', '车里 车门 轨道交通', '车门 轨道交通 转角', '轨道交通 转角 转身', '转角 转身 轮渡', '转身 轮渡 软件', '轮渡 软件 软硬', '软件 软硬 软饮', '软硬 软饮 轻声', '软饮 轻声 较为简单', '轻声 较为简单 较全', '较为简单 较全 较大', '较全 较大 较差', '较大 较差 较散', '较差 较散 较晚', '较散 较晚 较近', '较晚 较近 较远', '较近 较远 辉映', '较远 辉映 辉煌', '辉映 辉煌 输错', '辉煌 输错 边上', '输错 边上 边能', '边上 边能 达到', '边能 达到 达车', '达到 达车 迅速', '达车 迅速 过厅', '迅速 过厅 过去', '过厅 过去 过夜', '过去 过夜 过得去', '过夜 过得去 过时', '过得去 过时 过来', '过时 过来 过节', '过来 过节 过账', '过节 过账 过车', '过账 过车 迎宾', '过车 迎宾 迎面', '迎宾 迎面 运动', '迎面 运动 运气', '运动 运气 近在咫尺', '运气 近在咫尺 近期', '近在咫尺 近期 近海', '近期 近海 近火車', '近海 近火車 还会', '近火車 还会 还会来', '还会 还会来 还会订', '还会来 还会订 还会选', '还会订 还会选 还好', '还会选 还好 还算', '还好 还算 还给', '还算 还给 还花', '还给 还花 还要', '还花 还要 还贵', '还要 还贵 还过得去', '还贵 还过得去 还选', '还过得去 还选 这位', '还选 这位 这家', '这位 这家 这才', '这家 这才 这方面', '这才 这方面 这是', '这方面 这是 这次', '这是 这次 这段', '这次 这段 这点', '这段 这点 这种', '这点 这种 这间', '这种 这间 这项', '这间 这项 进一步', '这项 进一步 进入', '进一步 进入 进出', '进入 进出 进口', '进出 进口 进屋', '进口 进屋 进步', '进屋 进步 进站', '进步 进站 进行', '进站 进行 进门', '进行 进门 进餐', '进门 进餐 远不如', '进餐 远不如 远处', '远不如 远处 远洲', '远处 远洲 远点', '远洲 远点 远眺', '远点 远眺 远远', '远眺 远远 连卡佛', '远远 连卡佛 连接', '连卡佛 连接 迟到', '连接 迟到 迟钝', '迟到 迟钝 迪士尼', '迟钝 迪士尼 迪斯尼', '迪士尼 迪斯尼 迷你', '迪斯尼 迷你 迷宫', '迷你 迷宫 迷糊', '迷宫 迷糊 退房', '迷糊 退房 送上', '退房 送上 送入', '送上 送入 送到', '送入 送到 送机', '送到 送机 送来', '送机 送来 送餐', '送来 送餐 适中', '送餐 适中 适合', '适中 适合 适时地', '适合 适时地 选了', '适时地 选了 选在', '选了 选在 选择', '选在 选择 透过', '选择 透过 這一項', '透过 這一項 這家', '這一項 這家 這次', '這家 這次 通常', '這次 通常 通病', '通常 通病 通知', '通病 通知 通话', '通知 通话 通达', '通话 通达 通风', '通达 通风 通风管道', '通风 通风管道 逛街', '通风管道 逛街 逛逛', '逛街 逛逛 速度', '逛逛 速度 速度慢', '速度 速度慢 造成', '速度慢 造成 遇上', '造成 遇上 遇到', '遇上 遇到 過於用', '遇到 過於用 道歉', '過於用 道歉 道理', '道歉 道理 道路', '道理 道路 道逢', '道路 道逢 遗憾', '道逢 遗憾 遗漏', '遗憾 遗漏 遥控器', '遗漏 遥控器 遥远', '遥控器 遥远 適中', '遥远 適中 遺憾', '適中 遺憾 避免', '遺憾 避免 避暑', '避免 避暑 還是', '避暑 還是 還有', '還是 還有 那一刻', '還有 那一刻 那位', '那一刻 那位 那天', '那位 那天 那条', '那天 那条 那片', '那条 那片 那种', '那片 那种 邮件', '那种 邮件 邮局', '邮件 邮局 邻湖', '邮局 邻湖 邻近', '邻湖 邻近 郁闷', '邻近 郁闷 郊区', '郁闷 郊区 郑州', '郊区 郑州 部分', '郑州 部分 都市', '部分 都市 配套', '都市 配套 配有', '配套 配有 配置', '配有 配置 配送', '配置 配送 酒吧', '配送 酒吧 酒吧街', '酒吧 酒吧街 酒家', '酒吧街 酒家 酒巴', '酒家 酒巴 酒店', '酒巴 酒店 酒店设备', '酒店 酒店设备 酒店设施', '酒店设备 酒店设施 酒楼', '酒店设施 酒楼 酒气', '酒楼 酒气 酸酸的', '酒气 酸酸的 醉醺醺', '酸酸的 醉醺醺 醒目', '醉醺醺 醒目 采光', '醒目 采光 采用', '采光 采用 里外', '采用 里外 里头', '里外 里头 里望', '里头 里望 里面', '里望 里面 重庆', '里面 重庆 重新', '重庆 重新 重装', '重新 重装 重要', '重装 重要 重视', '重要 重视 野外', '重视 野外 野花', '野外 野花 金华', '野花 金华 金卡', '金华 金卡 金嗓子喉宝', '金卡 金嗓子喉宝 金水路', '金嗓子喉宝 金水路 金玉', '金水路 金玉 金紫荆', '金玉 金紫荆 金融中心', '金紫荆 金融中心 金钟', '金融中心 金钟 金门', '金钟 金门 金额', '金门 金额 针线包', '金额 针线包 钓鱼', '针线包 钓鱼 钟头', '钓鱼 钟头 钢琴演奏', '钟头 钢琴演奏 钥匙', '钢琴演奏 钥匙 铜锣湾', '钥匙 铜锣湾 银子', '铜锣湾 银子 银川', '银子 银川 银座', '银川 银座 银联', '银座 银联 银联卡', '银联 银联卡 销售部', '银联卡 销售部 锁好', '销售部 锁好 错误', '锁好 错误 锦江', '错误 锦江 键盘', '锦江 键盘 镜子', '键盘 镜子 长住', '镜子 长住 长廊', '长住 长廊 长时间', '长廊 长时间 长春', '长时间 长春 长江', '长春 长江 长话', '长江 长话 长途', '长话 长途 长途电话', '长途 长途电话 长途车', '长途电话 长途车 開心', '长途车 開心 门前', '開心 门前 门卫', '门前 门卫 门口', '门卫 门口 门外', '门口 门外 门童', '门外 门童 门铃', '门童 门铃 问一答', '门铃 问一答 问候', '问一答 问候 问卷调查', '问候 问卷调查 问路', '问卷调查 问路 问过', '问路 问过 问问', '问过 问问 问题', '问问 问题 间隔', '问题 间隔 闹中取静', '间隔 闹中取静 闹市', '闹中取静 闹市 闹市区', '闹市 闹市区 阳台', '闹市区 阳台 阳朔', '阳台 阳朔 阴霾', '阳朔 阴霾 阿三', '阴霾 阿三 阿姨', '阿三 阿姨 阿拉', '阿姨 阿拉 附近', '阿拉 附近 陆家嘴', '附近 陆家嘴 陈列', '陆家嘴 陈列 陈旧', '陈列 陈旧 降低', '陈旧 降低 降雪', '降低 降雪 陽朔', '降雪 陽朔 随便', '陽朔 随便 随口', '随便 随口 随叫随到', '随口 随叫随到 随处可见', '随叫随到 随处可见 随时', '随处可见 随时 隔壁', '随时 隔壁 隔开', '隔壁 隔开 隔海', '隔开 隔海 隔离', '隔海 隔离 隔音', '隔离 隔音 隧道', '隔音 隧道 难以', '隧道 难以 难吃', '难以 难吃 难看', '难吃 难看 难闻', '难看 难闻 难题', '难闻 难题 雄厚实力', '难题 雄厚实力 集团', '雄厚实力 集团 集散', '集团 集散 雖然', '集散 雖然 離大', '雖然 離大 雨伞', '離大 雨伞 雨水', '雨伞 雨水 雪茄', '雨水 雪茄 零距离', '雪茄 零距离 零食', '零距离 零食 電力', '零食 電力 需求', '電力 需求 需要', '需求 需要 震撼', '需要 震撼 霉味', '震撼 霉味 露台', '霉味 露台 露天', '露台 露天 青山绿水', '露天 青山绿水 青岛', '青山绿水 青岛 青年会', '青岛 青年会 青春', '青年会 青春 青海', '青春 青海 青菜', '青海 青菜 静心', '青菜 静心 非常感谢', '静心 非常感谢 非常适合', '非常感谢 非常适合 非常高兴', '非常适合 非常高兴 靠山', '非常高兴 靠山 靠江', '靠山 靠江 靠海', '靠江 靠海 靠近', '靠海 靠近 面临', '靠近 面临 面向', '面临 面向 面对', '面向 面对 面巾纸', '面对 面巾纸 面带微笑', '面巾纸 面带微笑 面是', '面带微笑 面是 面海', '面是 面海 面积', '面海 面积 面積', '面积 面積 韩国', '面積 韩国 韩式', '韩国 韩式 音乐', '韩式 音乐 顧客', '音乐 顧客 顶楼', '顧客 顶楼 项链', '顶楼 项链 顺便', '项链 顺便 顺利', '顺便 顺利 顺道', '顺利 顺道 顾客', '顺道 顾客 预先', '顾客 预先 预定', '预先 预定 预期', '预定 预期 预留', '预期 预留 预订', '预留 预订 预订单', '预订 预订单 领导人', '预订单 领导人 领略', '领导人 领略 领走', '领略 领走 颜色', '领走 颜色 额外', '颜色 额外 颠倒黑白', '额外 颠倒黑白 風景', '颠倒黑白 風景 風機給', '風景 風機給 风光', '風機給 风光 风吹', '风光 风吹 风味', '风吹 风味 风大则', '风味 风大则 风扇', '风大则 风扇 风景', '风扇 风景 风格', '风景 风格 风范', '风格 风范 风趣', '风范 风趣 风采', '风趣 风采 飘飘', '风采 飘飘 飞天', '飘飘 飞天 飞快', '飞天 飞快 飞机', '飞快 飞机 飞机场', '飞机 飞机场 飞机票', '飞机场 飞机票 食品', '飞机票 食品 食物', '食品 食物 餐具', '食物 餐具 餐券', '餐具 餐券 餐厅', '餐券 餐厅 餐点', '餐厅 餐点 餐饮', '餐点 餐饮 餐饮部', '餐饮 餐饮部 餐馆', '餐饮部 餐馆 饭店', '餐馆 饭店 饭菜', '饭店 饭菜 饮料', '饭菜 饮料 饮用水', '饮料 饮用水 饮茶', '饮用水 饮茶 饼干', '饮茶 饼干 馊臭', '饼干 馊臭 首场', '馊臭 首场 首屈一指', '首场 首屈一指 首日', '首屈一指 首日 首选', '首日 首选 香格里拉', '首选 香格里拉 香港', '香格里拉 香港 香港站', '香港 香港站 香港艺术馆', '香港站 香港艺术馆 香舌', '香港艺术馆 香舌 马可', '香舌 马可 马桶', '马可 马桶 马自达', '马桶 马自达 马路', '马自达 马路 马路上', '马路 马路上 马马虎虎', '马路上 马马虎虎 驴友', '马马虎虎 驴友 驶向', '驴友 驶向 驾车', '驶向 驾车 驾车者', '驾车 驾车者 骗人', '驾车者 骗人 骚扰', '骗人 骚扰 骚扰电话', '骚扰 骚扰电话 高些', '骚扰电话 高些 高兴', '高些 高兴 高尔夫', '高兴 高尔夫 高尔夫球场', '高尔夫 高尔夫球场 高尚', '高尔夫球场 高尚 高峰', '高尚 高峰 高效率', '高峰 高效率 高登', '高效率 高登 高级', '高登 高级 高速', '高级 高速 高高', '高速 高高 高高的', '高高 高高的 鲜花', '高高的 鲜花 鳕鱼', '鲜花 鳕鱼 鸟瞰', '鳕鱼 鸟瞰 鸡尾酒', '鸟瞰 鸡尾酒 麦凯乐', '鸡尾酒 麦凯乐 麦当劳', '麦凯乐 麦当劳 麻烦', '麦当劳 麻烦 黄山', '麻烦 黄山 黄河', '黄山 黄河 黄金周', '黄河 黄金周 黑椒', '黄金周 黑椒 黑车', '黑椒 黑车 點就', '黑车 點就 鼓励', '點就 鼓励 鼓浪屿', '鼓励 鼓浪屿 齐全', '鼓浪屿 齐全 齐备', '齐全 齐备 龙城', '齐备 龙城 龙头', '龙城 龙头 龙门石窟']\n"
     ]
    }
   ],
   "source": [
    "ngrams = _word_ngrams(features)\n",
    "print(features)\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 这里结束传统的基于词频的表达方法，开始介绍基于预测的表达方法。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代嵌入方法\n",
    "我们在上面介绍了基于SVD的词嵌入方法。通过共生矩阵以及SVD算法，独热法表示的单词之间的关系得到抽象，并映射到较低维度的致密空间中。但是这种方法基于全局信息，对存储量需求大。我们现在介绍一种迭代学习的方法来将单词映射到一个新的包含了上下文关系的空间中。这种方法的典型代表叫word2vec。在word2vec这个方法中需要引入两个概念“中心词”（center word）和“上下文”（context）\n",
    "\n",
    "以“资产富裕的人爱投资股票”这句话为例，其经过处理后得到如下的单词：\\[ '资产','富裕'，'人', '爱', '投资', '股票' \\]。如果选定*‘富裕’*这个单词，在模型中其被称为“中心词”，而其上下文就是前后的\\[ '资产','人', '爱', '投资', '股票' \\]。一个中心词的上下文被word2vec这个算法用来衡量其含义。如果我们在大量的文本中都发现类似于“资产”，“财富”，“投资”这样的词经常性地出现在*“富裕”*这个词的周边，就能推断*“富裕”*的含义。有相似上下文的词就在word2vec这个模型里具备相似的含义，可以被视作是同义词，其对应的词向量则应该距离上接近。\n",
    "\n",
    "当然，在实践中，上下文通常被定义为中心词左右对称给定长度的窗口覆盖的词，如下图所示：\n",
    "\n",
    "<img src=\"./pics/Chapter1-1.png\" width=\"400\">\n",
    "\"中心词与上下文的独热表示\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在word2vec中，词向量本身就是模型的参数，通过对数据的建模可以获得参数的值。word2vec包含两种不同的子模型：\n",
    "1. 连续型模型（Continuous Bag Of Words Model, CBOW Model）\n",
    "2. 跳跃型模型（Skip-Gram Model）\n",
    "\n",
    "下面分别介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 连续型模型 （CBOW） **\n",
    "\n",
    "在CBOW中，模型是根据上下文单词来预测中心词。其基本步骤如下：\n",
    "\n",
    "\n",
    "其架构如下图所示（图源自于：\"Deep learning for sentence classification\"）。图中标识分别为：\n",
    "1. $x_{ik}$为独热表示的上下文单词\n",
    "2. $W_{V \\times N}$为输入层的权重矩阵，大小为$V \\times N$，其中V是词典大小，而N是设定的词向量维度\n",
    "3. $h_i$是由$x_{ik}$与权重矩阵$W$相乘的到的隐含层结果，大小为$1 \\times N$的向量\n",
    "4. $W^{'}_{N \\times V}$为输出层的权重矩阵。注意，这里的$W^{'}$不是$W$矩阵的转置，而是另外一个全新的矩阵。\n",
    "5. $y_j$为待预测的中心词的独热表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./pics/Chapter1-CBOW.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW的计算过程比较直接：\n",
    "\n",
    "1. 首先，对于给定窗口长度m，上下文$x^{(c)}$用相应的独热法表示，对于待预测的中心词$y^{(c)}$也用相应的独热编码表示，那么我们的输入数据为：$(x^{(c-m)},...,x^{(c-1)}, x^{(c+1)},..., x^{(c+m)} )$\n",
    "2. 其次，对于上述上下文单词，与输入层权重矩阵相乘，得到嵌入向量$v_{c-m} = Wx^{(c-m)}, v_{c-m+1} = Wx^{(c-m+1)}, ....$\n",
    "3. 将上述嵌入向量取平均：$\\bar(v) = \\frac{\\sum_{-m}^{m}v_{c+j}}{2m}$\n",
    "4. 将平均的嵌入向量与输出层权重矩阵相乘，得到输出打分向量$z = W{'}\\bar{v}$。相似的单词该得分应该更高；\n",
    "5. 应用softmax函数将上述打分向量变为概率输出$y=\\textrm{softmax}(z)$。如果预测准确的话，那么概率向量$y$会在独热编码为1的地方具备最高的概率值。\n",
    "\n",
    "word2vec模型就是要在迭代的过程中，通过不断优化$W$和$W'$两个权重矩阵使得我们的语言模型尽可能地接近实际的数据表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 跳跃型模型 （Skip-Gram） **\n",
    "\n",
    "Skip-Gram模型与CBOW正好相反，模型是根据中心词来预测上下文。其基本步骤如下：\n",
    "\n",
    "\n",
    "其架构如下图所示（图源自于：\"Deep learning for sentence classification\"）。图中标识分别为：\n",
    "1. $x_{ik}$为独热表示的中心词\n",
    "2. $W_{V \\times N}$为输入层的权重矩阵，大小为$V \\times N$，其中V是词典大小，而N是设定的词向量维度\n",
    "3. $h_i$是由$x_{ik}$与权重矩阵$W$相乘的到的隐含层结果，大小为$1 \\times N$的向量\n",
    "4. $W^{'}_{N \\times V}$为输出层的权重矩阵。注意，这里的$W^{'}$不是$W$矩阵的转置，而是另外一个全新的矩阵。\n",
    "5. $y_{Cj}$为待预测的上下文词的独热表示\n",
    "\n",
    "<img src=\"./pics/Chapter1-SkipGram.png\" width=\"400\">\n",
    "\n",
    "Initialization\n",
    "Step 1\n",
    "\n",
    "    Fix the hyperparameters such as window size (2 * n + 1), the size of feature vectors (N), learning rate, number of epochs etc.\n",
    "    Initialize other parameters such as the connection weights between the input layer and hidden layer, and hidden layer and the softmax layers (can be random initialization).\n",
    "\n",
    "Step 2\n",
    "\n",
    "From each sentence in the input file, form a multi-set which will be a collection of every possible contiguous sub-sequence of size (2 * n + 1). Union of all such multi-sets (corresponding to each sentence) will be our training corpus (which is also a multi-set of windows).\n",
    "Step 3\n",
    "\n",
    "Make a vocabulary by collecting all possible distinct words. Let the Vocabulary be V.\n",
    "Step 4 [redundant step added for clarity in understanding]\n",
    "\n",
    "To each word in dictionary assign a random feature vector. If x is the word then Vec[x] represents the feature vector. The ith row of weight matrix between the input layer and hidden layer stores the feature vector for ith word in the vocabulary, hence in step 1 we have already initialized the word vectors for each word in the dictionary.\n",
    "One Training Step\n",
    "\n",
    "Input: Given a single window  w-n  …  w-1  x  w1  ….  wn  from the training corpus.\n",
    "Forward Step\n",
    "\n",
    " \n",
    "\n",
    "Input Layer\n",
    "\n",
    "    Activation Function: Identity\n",
    "    Input: One hot representation of word x\n",
    "    Weight Matrix Size: [V * N]\n",
    "    Objective: Select vector Vec[x] corresponding to x\n",
    "\n",
    "By feeding one hot representation of word x, the input vector to the hidden layer will be the feature vector corresponding to the word x.\n",
    "\n",
    "Note: The ith row of the hidden weight matrix is the word vector of the ith word in the vocabulary.\n",
    "\n",
    " \n",
    "Hidden Layer\n",
    "\n",
    "    Activation Function: Identity\n",
    "    Input: Word vector corresponding to x\n",
    "    Weight Matrix Size: [N * V] (for each of 2 * n softmax unit)\n",
    "\n",
    "There are 2 * n softmax units (each having |V| nodes) in the output layer. Let the softmax units be S-n … S-1 ,S1  …. Sn. Feed Vec[x] to each of the softmax unit (each with its own weight matrix). zth node of softmax unit i tries to predict the probability of zth word in dictionary appearing in context position i with respect to the current context. Let P(i, z) be the output of zth node of the ith softmax unit.\n",
    "\n",
    " \n",
    "Output Layer\n",
    "\n",
    "The following bullet points are with respect to a single softmax unit (say ith) unit in the output layer:\n",
    "\n",
    "    Input : Output of hidden layer.\n",
    "    Objective (Redundant): zth node of softmax unit i tries to predict the probability of zth word in dictionary appearing in context position i with respect to the current context.\n",
    "\n",
    "Crucial Step: For each context position in set P, add the log of the output of each corresponding context word’s node. So let S = $latex \\sum_{i = -n, i \\neq 0}^{i = n} \\log P(i, wi) $ where  wi is the  ith context word and i ∈ P (Objective here is to maximize this log likelihood of the observation).\n",
    "Backward Step (Back-Propagation Step):\n",
    "\n",
    "Objective: Try to maximize S (log likelihood of observation as defined above).\n",
    "\n",
    "S is a function of weights of the model, all words in vocabulary and the word vector corresponding to x. Using back propagation we tune weights of the model (specifically all weight between hidden layer and output layer) and improve the feature vectors word x (which is also embodied in model in the form of weight between input layer and hidden layer), so as to maximize S. This is same as minimizing the negative log likelihood of the observation.\n",
    "\n",
    "Redundant Note: During one training step, in a window where x forms the middle word, only the weights between hidden layer and output layer, and feature vector of x will be improved. Feature vectors of all other words will not change (Do some math yourself :p). From the next training instance, the modified feature vector of x will be used as its feature vector. In this way, a feature vector gets incrementally.\n",
    "Training\n",
    "\n",
    "Run the training step on the training corpus for several epochs.\n",
    "Output VS Outcome\n",
    "\n",
    "Output (of the model): Given a window (a training instance), we get the output as the values which we get at the output nodes. The output of the nodes (of output layer) tries to estimate probabilities. These probabilities can be useful for language modeling, though it is generally not used.\n",
    "\n",
    "Outcome: After the model is trained completely, the  ith rows of the weight matrix between input layer and hidden layer is the feature vector for the ith word in the dictionary. These feature vectors for each word in dictionary are the outcome of the model. And Word2vec is famous good feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们在keras中来实现基于CBOW算法的word2vec模型。我们需要进行如下的设计：\n",
    "1. 首先我们要将原始输入的文字进行标注化（tokenize），并用下标代表每一个单词；\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-aadac1bded9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'accuracy'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import accuracy\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Lambda, Dense, merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD\n",
    "from keras.objectives import mse\n",
    "\n",
    "import global_settings as G\n",
    "from sentences_generator import Sentences\n",
    "import vocab_generator as V_gen\n",
    "import save_embeddings as S\n",
    "\n",
    "k = G.window_size # context windows size\n",
    "context_size = 2*k\n",
    "\n",
    "# Creating a sentence generator from demo file\n",
    "sentences = Sentences(\"test_file.txt\")\n",
    "vocabulary = dict()\n",
    "V_gen.build_vocabulary(vocabulary, sentences)\n",
    "V_gen.filter_vocabulary_based_on(vocabulary, G.min_count)\n",
    "reverse_vocabulary = V_gen.generate_inverse_vocabulary_lookup(vocabulary, \"vocab.txt\")\n",
    "\n",
    "# generate embedding matrix with all values between -1/2d, 1/2d\n",
    "embedding = np.random.uniform(-1.0/2.0/G.embedding_dimension, 1.0/2.0/G.embedding_dimension, (G.vocab_size+3, G.embedding_dimension))\n",
    "\n",
    "# Creating CBOW model\n",
    "# Model has 3 inputs\n",
    "# Current word index, context words indexes and negative sampled word indexes\n",
    "word_index = Input(shape=(1,))\n",
    "context = Input(shape=(context_size,))\n",
    "negative_samples = Input(shape=(G.negative,))\n",
    "# All the inputs are processed through a common embedding layer\n",
    "shared_embedding_layer = Embedding(input_dim=(G.vocab_size+3), output_dim=G.embedding_dimension, weights=[embedding])\n",
    "word_embedding = shared_embedding_layer(word_index)\n",
    "context_embeddings = shared_embedding_layer(context)\n",
    "negative_words_embedding = shared_embedding_layer(negative_samples)\n",
    "# Now the context words are averaged to get the CBOW vector\n",
    "cbow = Lambda(lambda x: K.mean(x, axis=1), output_shape=(G.embedding_dimension,))(context_embeddings)\n",
    "# The context is multiplied (dot product) with current word and negative sampled words\n",
    "word_context_product = merge([word_embedding, cbow], mode='dot')\n",
    "negative_context_product = merge([negative_words_embedding, cbow], mode='dot', concat_axis=-1)\n",
    "# The dot products are outputted\n",
    "model = Model(input=[word_index, context, negative_samples], output=[word_context_product, negative_context_product])\n",
    "# binary crossentropy is applied on the output\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "print(model.summary())\n",
    "\n",
    "# model.fit_generator(V_gen.pretraining_batch_generator(sentences, vocabulary, reverse_vocabulary), samples_per_epoch=G.train_words, nb_epoch=1)\n",
    "model.fit_generator(V_gen.pretraining_batch_generator(sentences, vocabulary, reverse_vocabulary), samples_per_epoch=10, nb_epoch=1)\n",
    "# Save the trained embedding\n",
    "S.save_embeddings(\"embedding.txt\", shared_embedding_layer.get_weights()[0], vocabulary)\n",
    "\n",
    "# input_context = np.random.randint(10, size=(1, context_size))\n",
    "# input_word = np.random.randint(10, size=(1,))\n",
    "# input_negative = np.random.randint(10, size=(1, G.negative))\n",
    "\n",
    "# print \"word, context, negative samples\"\n",
    "# print input_word.shape, input_word\n",
    "# print input_context.shape, input_context\n",
    "# print input_negative.shape, input_negative\n",
    "\n",
    "# output_dot_product, output_negative_product = model.predict([input_word, input_context, input_negative])\n",
    "# print \"word cbow dot product\"\n",
    "# print output_dot_product.shape, output_dot_product\n",
    "# print \"cbow negative dot product\"\n",
    "# print output_negative_product.shape, output_negative_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile, os, urllib\n",
    "\n",
    "def maybe_download(filename, url, expected_bytes):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urllib.request.urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', filename)\n",
    "    else:\n",
    "        print(statinfo.st_size)\n",
    "        raise Exception(\n",
    "            'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "    return filename\n",
    "\n",
    "url = 'http://mattmahoney.net/dc/'\n",
    "filename = maybe_download('text8.zip', url, 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Read the data into a list of strings.\n",
    "def read_data(filename):\n",
    "    \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "    return data\n",
    "\n",
    "vocabulary = read_data(filename)\n",
    "print(vocabulary[:7])\n",
    "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', '商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', '早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。', '宾馆在小街道上，不大好找，但还好北京热心同胞很多~']\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "stopword = []\n",
    "datafile = './nlp_data/hotel_reviews_data/1000_pos.txt'\n",
    "stopwordfile = './nlp_data/hotel_reviews_data/stopWord.txt'\n",
    "\n",
    "# 先读入stopword\n",
    "#fo=open(stopwordfile, encoding='UTF-8')\n",
    "with open(stopwordfile, encoding='UTF-8') as fo:\n",
    "    for line in fo:\n",
    "       stopword.append(line.strip('\\n'))\n",
    "\n",
    "#print(stopword[70:87])\n",
    "\n",
    "# 再读入原始评论文档\n",
    "#fo=open(datafile, encoding='UTF-8')\n",
    "with open(datafile, encoding='UTF-8') as fo:\n",
    "    for line in fo:\n",
    "       documents.append(line.strip('\\n'))\n",
    "    \n",
    "print(documents[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "data, count, dictionary, reversed_dictionary = build_dataset(vocabulary, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7fb1e96e7005>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mword_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindecs_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcn_text_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-7fb1e96e7005>\u001b[0m in \u001b[0;36mcn_text_fit\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mindex_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_docs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mindex_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_docs' is not defined"
     ]
    }
   ],
   "source": [
    "def cn_list_seg(documents, removeDigits=True):\n",
    "    vocabulary = {}\n",
    "    documents_after = []\n",
    "    documents = list(documents)\n",
    "    for doc in documents:\n",
    "        # 每一个文本的分句要单独拎出来进行分词处理，\n",
    "        doc_elements = doc.split(',.，。；')\n",
    "        seg_doc = ''\n",
    "        for element in doc_elements:\n",
    "            result=jieba.tokenize(element)\n",
    "            # 如果分词出来的结果包含数字，就扔掉\n",
    "            for word in result:\n",
    "                if (removeDigits) & bool(re.search('\\d+', word[0])):\n",
    "                    pass\n",
    "                else:\n",
    "                    seg_doc = seg_doc + ' ' + word[0]\n",
    "                    if word in vocabulary.keys():\n",
    "                        vocabulary[word[0]] += 1\n",
    "                    else:\n",
    "                        vocabulary[word[0]] = 1\n",
    "        documents_after.append(seg_doc)    \n",
    "    return documents_after, vocabulary\n",
    "    \n",
    "def cn_text_fit(texts):\n",
    "    word_counts = {}\n",
    "    for text in texts:\n",
    "        seq = text.split(' ')\n",
    "        for w in seq:\n",
    "            if w in word_counts:\n",
    "                word_counts[w] += 1\n",
    "            else:\n",
    "                word_counts[w] = 1           \n",
    "\n",
    "        wcounts = list(word_counts.items())\n",
    "        wcounts.sort(key=lambda x: x[1], reverse=True)\n",
    "        # forcing the oov_token to index 1 if it exists\n",
    "        sorted_voc = []\n",
    "        sorted_voc.extend(wc[0] for wc in wcounts)\n",
    "\n",
    "        # note that index 0 is reserved, never assigned to an existing word\n",
    "        word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))\n",
    "\n",
    "        index_word = dict((c, w) for w, c in word_index.items())\n",
    "\n",
    "        for w, c in list(word_docs.items()):\n",
    "            index_docs[word_index[w]] = c\n",
    "    return word_index, index_word, index_docs\n",
    "        \n",
    "\n",
    "word_index, index_word, indecs_doc = cn_text_fit(documents_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文字符预处理：\n",
    "1. 标注化（tokenizer）\n",
    "2. 序列化\n",
    "3. 建立字典\n",
    "4. 建立正向、反向查阅表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [u'独热编码是对于当前单词表中的单词使用1个向量进行表达的简单方式，独热编码有自身的缺点和有点。', \n",
    "             u'研究者探索了可以解决存储效率和单词之间关系问题的方法', \n",
    "             u'独热编码虽然简单', \n",
    "             u'假如当前的单词表有10个不同的单词，并且每个单词都不一样']\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "def cntext_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',):\n",
    "    translate_dict = dict((c, ' ') for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    words = jieba.tokenize(text)\n",
    "    seq = [w[0] for w in words if w[0]]\n",
    "    return seq\n",
    "\n",
    "def fit_on_cntexts(texts, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
    "    '''\n",
    "    假设输入是一组中文列表\n",
    "    '''\n",
    "    index_docs = defaultdict(int)\n",
    "    word_docs = defaultdict(int)\n",
    "    word_counts = OrderedDict()\n",
    "    word_index = dict()\n",
    "    index_word = dict()\n",
    "    document_count = 0\n",
    "    for text in texts:\n",
    "        document_count += 1\n",
    "        print(text)\n",
    "        \n",
    "        if isinstance(text, list):\n",
    "            longtext = ' '.join(text)           \n",
    "            text = longtext\n",
    "        seq = cntext_to_word_sequence(text, filters)\n",
    "        for w in seq:\n",
    "            if w in word_counts:\n",
    "                word_counts[w] += 1\n",
    "            else:\n",
    "                word_counts[w] = 1\n",
    "        for w in set(seq):\n",
    "        # In how many documents each word occurs\n",
    "           word_docs[w] += 1\n",
    "\n",
    "        wcounts = list(word_counts.items())\n",
    "        wcounts.sort(key=lambda x: x[1], reverse=True)\n",
    "        # forcing the oov_token to index 1 if it exists        \n",
    "        sorted_voc = []\n",
    "        sorted_voc.extend(wc[0] for wc in wcounts)\n",
    "        print(sorted_voc)\n",
    "\n",
    "        # note that index 0 is reserved, never assigned to an existing word\n",
    "        word_index = dict(\n",
    "            list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1))))\n",
    "        )\n",
    "\n",
    "        index_word = dict((c, w) for w, c in word_index.items())\n",
    "\n",
    "        for w, c in list(word_docs.items()):\n",
    "            index_docs[word_index[w]] = c\n",
    "\n",
    "    return seq, word_index, index_word, word_docs, index_docs, word_counts, document_count\n",
    "    \n",
    "def cntexts_to_sequences(texts, num_words, oov_token, document_count, filters, word_index ):\n",
    "    \"\"\"Transforms each text in texts to a sequence of integers.\n",
    "    Only top `num_words-1` most frequent words will be taken into account.\n",
    "    Only words known by the tokenizer will be taken into account.\n",
    "    # Arguments\n",
    "        texts: A list of texts (strings).\n",
    "    # Returns\n",
    "        A list of sequences.\n",
    "    \"\"\"\n",
    "    return list(cntexts_to_sequences_generator(texts, num_words, oov_token, document_count, filters, word_index))    \n",
    "\n",
    "\n",
    "def cntexts_to_sequences_generator(texts, num_words, oov_token, document_count, filters, word_index ):\n",
    "    \"\"\"Transforms each text in `texts` to a sequence of integers.\n",
    "    Each item in texts can also be a list,\n",
    "    in which case we assume each item of that list to be a token.\n",
    "    Only top `num_words-1` most frequent words will be taken into account.\n",
    "    Only words known by the tokenizer will be taken into account.\n",
    "    # Arguments\n",
    "        texts: A list of texts (strings).\n",
    "    # Yields\n",
    "        Yields individual sequences.\n",
    "    \"\"\"\n",
    "    num_words = num_words\n",
    "    oov_token_index = word_index.get(oov_token)\n",
    "    for text in texts:\n",
    "        document_count += 1\n",
    "        print(text)\n",
    "\n",
    "        if isinstance(text, list):\n",
    "            longtext = ' '.join(text)           \n",
    "            text = longtext\n",
    "        seq = cntext_to_word_sequence(text, filters)\n",
    "        print(seq, '\\n')\n",
    "                \n",
    "        vect = []\n",
    "        temp = []\n",
    "        for w in seq:\n",
    "            i = word_index.get(w)\n",
    "            temp.append(i)\n",
    "            if i is not None:\n",
    "                if num_words and i >= num_words:\n",
    "                    if oov_token_index is not None:\n",
    "                        vect.append(oov_token_index)\n",
    "                else:\n",
    "                    vect.append(i)\n",
    "            elif oov_token is not None:\n",
    "                vect.append(oov_token_index)\n",
    "        print(temp)\n",
    "        print('-------------')\n",
    "        yield vect       \n",
    "\n",
    "        \n",
    "class Tokenizer(object):\n",
    "    \"\"\"Text tokenization utility class.\n",
    "    This class allows to vectorize a text corpus, by turning each\n",
    "    text into either a sequence of integers (each integer being the index\n",
    "    of a token in a dictionary) or into a vector where the coefficient\n",
    "    for each token could be binary, based on word count, based on tf-idf...\n",
    "    # Arguments\n",
    "        num_words: the maximum number of words to keep, based\n",
    "            on word frequency. Only the most common `num_words-1` words will\n",
    "            be kept.\n",
    "        filters: a string where each element is a character that will be\n",
    "            filtered from the texts. The default is all punctuation, plus\n",
    "            tabs and line breaks, minus the `'` character.\n",
    "        lower: boolean. Whether to convert the texts to lowercase.\n",
    "        split: str. Separator for word splitting.\n",
    "        char_level: if True, every character will be treated as a token.\n",
    "        oov_token: if given, it will be added to word_index and used to\n",
    "            replace out-of-vocabulary words during text_to_sequence calls\n",
    "    By default, all punctuation is removed, turning the texts into\n",
    "    space-separated sequences of words\n",
    "    (words maybe include the `'` character). These sequences are then\n",
    "    split into lists of tokens. They will then be indexed or vectorized.\n",
    "    `0` is a reserved index that won't be assigned to any word.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_words=None,\n",
    "                 filters='!\"#$%&()*+，。；,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                 lower=True,\n",
    "                 split=' ',\n",
    "                 char_level=False,\n",
    "                 oov_token=None,\n",
    "                 document_count=0,\n",
    "                 **kwargs):\n",
    "        # Legacy support\n",
    "        if 'nb_words' in kwargs:\n",
    "            warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
    "                          'has been renamed `num_words`.')\n",
    "            num_words = kwargs.pop('nb_words')\n",
    "        if kwargs:\n",
    "            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n",
    "\n",
    "        self.word_counts = OrderedDict()\n",
    "        self.word_docs = defaultdict(int)\n",
    "        self.filters = filters\n",
    "        self.split = split\n",
    "        self.lower = lower\n",
    "        self.num_words = num_words\n",
    "        self.document_count = document_count\n",
    "        self.char_level = char_level\n",
    "        self.oov_token = oov_token\n",
    "        self.index_docs = defaultdict(int)\n",
    "        self.word_index = dict()\n",
    "        self.index_word = dict()\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        \"\"\"Updates internal vocabulary based on a list of texts.\n",
    "        In the case where texts contains lists,\n",
    "        we assume each entry of the lists to be a token.\n",
    "        Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
    "        # Arguments\n",
    "            texts: can be a list of strings,\n",
    "                a generator of strings (for memory-efficiency),\n",
    "                or a list of list of strings.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            self.document_count += 1\n",
    "            if self.char_level or isinstance(text, list):\n",
    "                if self.lower:\n",
    "                    if isinstance(text, list):\n",
    "                        text = [text_elem.lower() for text_elem in text]\n",
    "                    else:\n",
    "                        text = text.lower()\n",
    "                seq = text\n",
    "            else:\n",
    "                seq = text_to_word_sequence(text,\n",
    "                                            self.filters,\n",
    "                                            self.lower,\n",
    "                                            self.split)\n",
    "            for w in seq:\n",
    "                if w in self.word_counts:\n",
    "                    self.word_counts[w] += 1\n",
    "                else:\n",
    "                    self.word_counts[w] = 1\n",
    "            for w in set(seq):\n",
    "                # In how many documents each word occurs\n",
    "                self.word_docs[w] += 1\n",
    "\n",
    "        wcounts = list(self.word_counts.items())\n",
    "        wcounts.sort(key=lambda x: x[1], reverse=True)\n",
    "        # forcing the oov_token to index 1 if it exists\n",
    "        if self.oov_token is None:\n",
    "            sorted_voc = []\n",
    "        else:\n",
    "            sorted_voc = [self.oov_token]\n",
    "        sorted_voc.extend(wc[0] for wc in wcounts)\n",
    "\n",
    "        # note that index 0 is reserved, never assigned to an existing word\n",
    "        self.word_index = dict(\n",
    "            list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))\n",
    "\n",
    "        self.index_word = dict((c, w) for w, c in self.word_index.items())\n",
    "\n",
    "        for w, c in list(self.word_docs.items()):\n",
    "            self.index_docs[self.word_index[w]] = c\n",
    "            \n",
    "    def fit_on_cntexts(self, texts):\n",
    "        '''\n",
    "        假设输入是一组中文列表\n",
    "        '''\n",
    "        for text in texts:\n",
    "            self.document_count += 1\n",
    "\n",
    "            if isinstance(text, list):\n",
    "                longtext = ' '.join(text)           \n",
    "                text = longtext\n",
    "            seq = cntext_to_word_sequence(text, self.filters)\n",
    "            for w in seq:\n",
    "                if w in self.word_counts:\n",
    "                    self.word_counts[w] += 1\n",
    "                else:\n",
    "                    self.word_counts[w] = 1\n",
    "            for w in set(seq):\n",
    "            # In how many documents each word occurs\n",
    "               self.word_docs[w] += 1\n",
    "\n",
    "        wcounts = list(word_counts.items())\n",
    "        wcounts.sort(key=lambda x: x[1], reverse=True)\n",
    "        # forcing the oov_token to index 1 if it exists        \n",
    "        if self.oov_token is None:\n",
    "            sorted_voc = []\n",
    "        else:\n",
    "            sorted_voc = [self.oov_token]\n",
    "        sorted_voc.extend(wc[0] for wc in wcounts)\n",
    "\n",
    "        # note that index 0 is reserved, never assigned to an existing word\n",
    "        self.word_index = dict(\n",
    "                list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1))))\n",
    "        )\n",
    "\n",
    "        self.index_word = dict((c, w) for w, c in self.word_index.items())\n",
    "\n",
    "        for w, c in list(word_docs.items()):\n",
    "            self.index_docs[self.word_index[w]] = c\n",
    "\n",
    "    def fit_on_sequences(self, sequences):\n",
    "        \"\"\"Updates internal vocabulary based on a list of sequences.\n",
    "        Required before using `sequences_to_matrix`\n",
    "        (if `fit_on_texts` was never called).\n",
    "        # Arguments\n",
    "            sequences: A list of sequence.\n",
    "                A \"sequence\" is a list of integer word indices.\n",
    "        \"\"\"\n",
    "        self.document_count += len(sequences)\n",
    "        for seq in sequences:\n",
    "            seq = set(seq)\n",
    "            for i in seq:\n",
    "                self.index_docs[i] += 1\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        \"\"\"Transforms each text in texts to a sequence of integers.\n",
    "        Only top `num_words-1` most frequent words will be taken into account.\n",
    "        Only words known by the tokenizer will be taken into account.\n",
    "        # Arguments\n",
    "            texts: A list of texts (strings).\n",
    "        # Returns\n",
    "            A list of sequences.\n",
    "        \"\"\"\n",
    "        return list(self.texts_to_sequences_generator(texts))\n",
    "    \n",
    "    def cntexts_to_sequences(self, texts):\n",
    "        \"\"\"Transforms each text in texts to a sequence of integers.\n",
    "        Only top `num_words-1` most frequent words will be taken into account.\n",
    "        Only words known by the tokenizer will be taken into account.\n",
    "        # Arguments\n",
    "            texts: A list of texts (strings).\n",
    "        # Returns\n",
    "            A list of sequences.\n",
    "        \"\"\"\n",
    "        return list(self.cntexts_to_sequences_generator(texts))    \n",
    "\n",
    "    def texts_to_sequences_generator(self, texts):\n",
    "        \"\"\"Transforms each text in `texts` to a sequence of integers.\n",
    "        Each item in texts can also be a list,\n",
    "        in which case we assume each item of that list to be a token.\n",
    "        Only top `num_words-1` most frequent words will be taken into account.\n",
    "        Only words known by the tokenizer will be taken into account.\n",
    "        # Arguments\n",
    "            texts: A list of texts (strings).\n",
    "        # Yields\n",
    "            Yields individual sequences.\n",
    "        \"\"\"\n",
    "        num_words = self.num_words\n",
    "        oov_token_index = self.word_index.get(self.oov_token)\n",
    "        \n",
    "        for text in texts:\n",
    "            if self.char_level or isinstance(text, list):\n",
    "                if self.lower:\n",
    "                    if isinstance(text, list):\n",
    "                        text = [text_elem.lower() for text_elem in text]\n",
    "                    else:\n",
    "                        text = text.lower()\n",
    "                seq = text\n",
    "            else:\n",
    "                seq = text_to_word_sequence(text,\n",
    "                                            self.filters,\n",
    "                                            self.lower,\n",
    "                                            self.split)\n",
    "            vect = []\n",
    "            for w in seq:\n",
    "                i = self.word_index.get(w)\n",
    "                if i is not None:\n",
    "                    if num_words and i >= num_words:\n",
    "                        if oov_token_index is not None:\n",
    "                            vect.append(oov_token_index)\n",
    "                    else:\n",
    "                        vect.append(i)\n",
    "                elif self.oov_token is not None:\n",
    "                    vect.append(oov_token_index)\n",
    "            yield vect\n",
    "            \n",
    "    def cntexts_to_sequences_generator(self, texts):\n",
    "        \"\"\"Transforms each text in `texts` to a sequence of integers.\n",
    "        Each item in texts can also be a list,\n",
    "        in which case we assume each item of that list to be a token.\n",
    "        Only top `num_words-1` most frequent words will be taken into account.\n",
    "        Only words known by the tokenizer will be taken into account.\n",
    "        # Arguments\n",
    "            texts: A list of texts (strings).\n",
    "        # Yields\n",
    "            Yields individual sequences.\n",
    "        \"\"\"\n",
    "        num_words = self.num_words\n",
    "        oov_token_index = self.word_index.get(self.oov_token)\n",
    "        for text in texts:\n",
    "            self.document_count += 1\n",
    "\n",
    "            if isinstance(text, list):\n",
    "                longtext = ' '.join(text)           \n",
    "                text = longtext\n",
    "            seq = cntext_to_word_sequence(text, self.filters)\n",
    "                    \n",
    "            vect = []\n",
    "            for w in seq:\n",
    "                i = self.word_index.get(w)\n",
    "                if i is not None:\n",
    "                    if num_words and i >= num_words:\n",
    "                        if oov_token_index is not None:\n",
    "                            vect.append(oov_token_index)\n",
    "                    else:\n",
    "                        vect.append(i)\n",
    "                elif self.oov_token is not None:\n",
    "                    vect.append(oov_token_index)\n",
    "            yield vect            \n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        \"\"\"Transforms each sequence into a list of text.\n",
    "        Only top `num_words-1` most frequent words will be taken into account.\n",
    "        Only words known by the tokenizer will be taken into account.\n",
    "        # Arguments\n",
    "            texts: A list of sequences (list of integers).\n",
    "        # Returns\n",
    "            A list of texts (strings)\n",
    "        \"\"\"\n",
    "        return list(self.sequences_to_texts_generator(sequences))\n",
    "\n",
    "    def sequences_to_texts_generator(self, sequences):\n",
    "        \"\"\"Transforms each sequence in `sequences` to a list of texts(strings).\n",
    "        Each sequence has to a list of integers.\n",
    "        In other words, sequences should be a list of sequences\n",
    "        Only top `num_words-1` most frequent words will be taken into account.\n",
    "        Only words known by the tokenizer will be taken into account.\n",
    "        # Arguments\n",
    "            texts: A list of sequences.\n",
    "        # Yields\n",
    "            Yields individual texts.\n",
    "        \"\"\"\n",
    "        num_words = self.num_words\n",
    "        oov_token_index = self.word_index.get(self.oov_token)\n",
    "        for seq in sequences:\n",
    "            vect = []\n",
    "            for num in seq:\n",
    "                word = self.index_word.get(num)\n",
    "                if word is not None:\n",
    "                    if num_words and num >= num_words:\n",
    "                        if oov_token_index is not None:\n",
    "                            vect.append(self.index_word[oov_token_index])\n",
    "                    else:\n",
    "                        vect.append(word)\n",
    "                elif self.oov_token is not None:\n",
    "                    vect.append(self.index_word[oov_token_index])\n",
    "            vect = ' '.join(vect)\n",
    "            yield vect\n",
    "\n",
    "    def texts_to_matrix(self, texts, mode='binary'):\n",
    "        \"\"\"Convert a list of texts to a Numpy matrix.\n",
    "        # Arguments\n",
    "            texts: list of strings.\n",
    "            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
    "        # Returns\n",
    "            A Numpy matrix.\n",
    "        \"\"\"\n",
    "        sequences = self.texts_to_sequences(texts)\n",
    "        return self.sequences_to_matrix(sequences, mode=mode)\n",
    "\n",
    "    def sequences_to_matrix(self, sequences, mode='binary'):\n",
    "        \"\"\"Converts a list of sequences into a Numpy matrix.\n",
    "        # Arguments\n",
    "            sequences: list of sequences\n",
    "                (a sequence is a list of integer word indices).\n",
    "            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
    "        # Returns\n",
    "            A Numpy matrix.\n",
    "        # Raises\n",
    "            ValueError: In case of invalid `mode` argument,\n",
    "                or if the Tokenizer requires to be fit to sample data.\n",
    "        \"\"\"\n",
    "        if not self.num_words:\n",
    "            if self.word_index:\n",
    "                num_words = len(self.word_index) + 1\n",
    "            else:\n",
    "                raise ValueError('Specify a dimension (`num_words` argument), '\n",
    "                                 'or fit on some text data first.')\n",
    "        else:\n",
    "            num_words = self.num_words\n",
    "\n",
    "        if mode == 'tfidf' and not self.document_count:\n",
    "            raise ValueError('Fit the Tokenizer on some data '\n",
    "                             'before using tfidf mode.')\n",
    "\n",
    "        x = np.zeros((len(sequences), num_words))\n",
    "        for i, seq in enumerate(sequences):\n",
    "            if not seq:\n",
    "                continue\n",
    "            counts = defaultdict(int)\n",
    "            for j in seq:\n",
    "                if j >= num_words:\n",
    "                    continue\n",
    "                counts[j] += 1\n",
    "            for j, c in list(counts.items()):\n",
    "                if mode == 'count':\n",
    "                    x[i][j] = c\n",
    "                elif mode == 'freq':\n",
    "                    x[i][j] = c / len(seq)\n",
    "                elif mode == 'binary':\n",
    "                    x[i][j] = 1\n",
    "                elif mode == 'tfidf':\n",
    "                    # Use weighting scheme 2 in\n",
    "                    # https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "                    tf = 1 + np.log(c)\n",
    "                    idf = np.log(1 + self.document_count /\n",
    "                                 (1 + self.index_docs.get(j, 0)))\n",
    "                    x[i][j] = tf * idf\n",
    "                else:\n",
    "                    raise ValueError('Unknown vectorization mode:', mode)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        '''Returns the tokenizer configuration as Python dictionary.\n",
    "        The word count dictionaries used by the tokenizer get serialized\n",
    "        into plain JSON, so that the configuration can be read by other\n",
    "        projects.\n",
    "        # Returns\n",
    "            A Python dictionary with the tokenizer configuration.\n",
    "        '''\n",
    "        json_word_counts = json.dumps(self.word_counts)\n",
    "        json_word_docs = json.dumps(self.word_docs)\n",
    "        json_index_docs = json.dumps(self.index_docs)\n",
    "        json_word_index = json.dumps(self.word_index)\n",
    "        json_index_word = json.dumps(self.index_word)\n",
    "\n",
    "        return {\n",
    "            'num_words': self.num_words,\n",
    "            'filters': self.filters,\n",
    "            'lower': self.lower,\n",
    "            'split': self.split,\n",
    "            'char_level': self.char_level,\n",
    "            'oov_token': self.oov_token,\n",
    "            'document_count': self.document_count,\n",
    "            'word_counts': json_word_counts,\n",
    "            'word_docs': json_word_docs,\n",
    "            'index_docs': json_index_docs,\n",
    "            'index_word': json_index_word,\n",
    "            'word_index': json_word_index\n",
    "        }\n",
    "\n",
    "    def to_json(self, **kwargs):\n",
    "        \"\"\"Returns a JSON string containing the tokenizer configuration.\n",
    "        To load a tokenizer from a JSON string, use\n",
    "        `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
    "        # Arguments\n",
    "            **kwargs: Additional keyword arguments\n",
    "                to be passed to `json.dumps()`.\n",
    "        # Returns\n",
    "            A JSON string containing the tokenizer configuration.\n",
    "        \"\"\"\n",
    "        config = self.get_config()\n",
    "        tokenizer_config = {\n",
    "            'class_name': self.__class__.__name__,\n",
    "            'config': config\n",
    "        }\n",
    "        return json.dumps(tokenizer_config, **kwargs)\n",
    "\n",
    "\n",
    "def tokenizer_from_json(json_string):\n",
    "    \"\"\"Parses a JSON tokenizer configuration file and returns a\n",
    "    tokenizer instance.\n",
    "    # Arguments\n",
    "        json_string: JSON string encoding a tokenizer configuration.\n",
    "    # Returns\n",
    "        A Keras Tokenizer instance\n",
    "    \"\"\"\n",
    "    tokenizer_config = json.loads(json_string)\n",
    "    config = tokenizer_config.get('config')\n",
    "\n",
    "    word_counts = json.loads(config.pop('word_counts'))\n",
    "    word_docs = json.loads(config.pop('word_docs'))\n",
    "    index_docs = json.loads(config.pop('index_docs'))\n",
    "    # Integer indexing gets converted to strings with json.dumps()\n",
    "    index_docs = {int(k): v for k, v in index_docs.items()}\n",
    "    index_word = json.loads(config.pop('index_word'))\n",
    "    index_word = {int(k): v for k, v in index_word.items()}\n",
    "    word_index = json.loads(config.pop('word_index'))\n",
    "\n",
    "    tokenizer = Tokenizer(**config)\n",
    "    tokenizer.word_counts = word_counts\n",
    "    tokenizer.word_docs = word_docs\n",
    "    tokenizer.index_docs = index_docs\n",
    "    tokenizer.word_index = word_index\n",
    "    tokenizer.index_word = index_word\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "独热编码是对于当前单词表中的单词使用1个向量进行表达的简单方式，独热编码有自身的缺点和有点。\n",
      "['的', '独热', '编码', '是', '对于', '当前', '单词表', '中', '单词', '使用', '1', '个', '向量', '进行', '表达', '简单', '方式', '，', '有', '自身', '缺点', '和', '有点', '。']\n",
      "研究者探索了可以解决存储效率和单词之间关系问题的方法\n",
      "['的', '独热', '编码', '单词', '和', '是', '对于', '当前', '单词表', '中', '使用', '1', '个', '向量', '进行', '表达', '简单', '方式', '，', '有', '自身', '缺点', '有点', '。', '研究者', '探索', '了', '可以', '解决', '存储', '效率', '之间', '关系', '问题', '方法']\n",
      "独热编码虽然简单\n",
      "['的', '独热', '编码', '单词', '简单', '和', '是', '对于', '当前', '单词表', '中', '使用', '1', '个', '向量', '进行', '表达', '方式', '，', '有', '自身', '缺点', '有点', '。', '研究者', '探索', '了', '可以', '解决', '存储', '效率', '之间', '关系', '问题', '方法', '虽然']\n",
      "假如当前的单词表有10个不同的单词，并且每个单词都不一样\n",
      "['的', '单词', '独热', '编码', '当前', '单词表', '个', '简单', '，', '有', '和', '是', '对于', '中', '使用', '1', '向量', '进行', '表达', '方式', '自身', '缺点', '有点', '。', '研究者', '探索', '了', '可以', '解决', '存储', '效率', '之间', '关系', '问题', '方法', '虽然', '假如', '10', '不同', '并且', '每个', '都', '不', '一样']\n",
      "['假如', '当前', '的', '单词表', '有', '10', '个', '不同', '的', '单词', '，', '并且', '每个', '单词', '都', '不', '一样'] \n",
      "\n",
      "---------------\n",
      "{'的': 1, '单词': 2, '独热': 3, '编码': 4, '当前': 5, '单词表': 6, '个': 7, '简单': 8, '，': 9, '有': 10, '和': 11, '是': 12, '对于': 13, '中': 14, '使用': 15, '1': 16, '向量': 17, '进行': 18, '表达': 19, '方式': 20, '自身': 21, '缺点': 22, '有点': 23, '。': 24, '研究者': 25, '探索': 26, '了': 27, '可以': 28, '解决': 29, '存储': 30, '效率': 31, '之间': 32, '关系': 33, '问题': 34, '方法': 35, '虽然': 36, '假如': 37, '10': 38, '不同': 39, '并且': 40, '每个': 41, '都': 42, '不': 43, '一样': 44} \n",
      "\n",
      "{1: '的', 2: '单词', 3: '独热', 4: '编码', 5: '当前', 6: '单词表', 7: '个', 8: '简单', 9: '，', 10: '有', 11: '和', 12: '是', 13: '对于', 14: '中', 15: '使用', 16: '1', 17: '向量', 18: '进行', 19: '表达', 20: '方式', 21: '自身', 22: '缺点', 23: '有点', 24: '。', 25: '研究者', 26: '探索', 27: '了', 28: '可以', 29: '解决', 30: '存储', 31: '效率', 32: '之间', 33: '关系', 34: '问题', 35: '方法', 36: '虽然', 37: '假如', 38: '10', 39: '不同', 40: '并且', 41: '每个', 42: '都', 43: '不', 44: '一样'}\n",
      "defaultdict(<class 'int'>, {'是': 1, '有': 2, '1': 1, '表达': 1, '向量': 1, '方式': 1, '独热': 2, '使用': 1, '进行': 1, '自身': 1, '对于': 1, '，': 2, '中': 1, '单词': 3, '的': 3, '单词表': 2, '缺点': 1, '编码': 2, '和': 2, '个': 2, '有点': 1, '简单': 2, '当前': 2, '。': 1, '之间': 1, '了': 1, '可以': 1, '研究者': 1, '关系': 1, '问题': 1, '存储': 1, '方法': 1, '解决': 1, '效率': 1, '探索': 1, '虽然': 1, '都': 1, '10': 1, '并且': 1, '每个': 1, '不': 1, '一样': 1, '不同': 1, '假如': 1})\n",
      "defaultdict(<class 'int'>, {4: 2, 19: 1, 11: 2, 15: 1, 13: 1, 17: 1, 2: 3, 10: 2, 14: 1, 20: 1, 5: 2, 18: 1, 8: 2, 9: 2, 1: 3, 7: 2, 21: 1, 3: 2, 22: 1, 12: 1, 23: 1, 16: 1, 6: 2, 24: 1, 32: 1, 27: 1, 28: 1, 25: 1, 33: 1, 34: 1, 30: 1, 35: 1, 29: 1, 31: 1, 26: 1, 36: 1, 42: 1, 38: 1, 40: 1, 41: 1, 43: 1, 44: 1, 39: 1, 37: 1})\n",
      "OrderedDict([('独热', 3), ('编码', 3), ('是', 1), ('对于', 1), ('当前', 2), ('单词表', 2), ('中', 1), ('的', 6), ('单词', 4), ('使用', 1), ('1', 1), ('个', 2), ('向量', 1), ('进行', 1), ('表达', 1), ('简单', 2), ('方式', 1), ('，', 2), ('有', 2), ('自身', 1), ('缺点', 1), ('和', 2), ('有点', 1), ('。', 1), ('研究者', 1), ('探索', 1), ('了', 1), ('可以', 1), ('解决', 1), ('存储', 1), ('效率', 1), ('之间', 1), ('关系', 1), ('问题', 1), ('方法', 1), ('虽然', 1), ('假如', 1), ('10', 1), ('不同', 1), ('并且', 1), ('每个', 1), ('都', 1), ('不', 1), ('一样', 1)])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#corpus = [sentence for sentence in corpus if sentence.count(' ') >= 2]\n",
    "corpus = documents\n",
    "tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_cntexts(corpus)\n",
    "#V = len(tokenizer.word_index) + 1\n",
    "seq, word_index, index_word, word_docs, index_docs, word_counts, document_count = fit_on_cntexts(corpus)\n",
    "print(seq,'\\n')\n",
    "print('---------------')\n",
    "print(word_index, '\\n')\n",
    "print(index_word)\n",
    "print(word_docs)\n",
    "print(index_docs)\n",
    "print(word_counts)\n",
    "print(document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "独热编码是对于当前单词表中的单词使用1个向量进行表达的简单方式，独热编码有自身的缺点和有点。\n",
      "['独热', '编码', '是', '对于', '当前', '单词表', '中', '的', '单词', '使用', '1', '个', '向量', '进行', '表达', '的', '简单', '方式', '，', '独热', '编码', '有', '自身', '的', '缺点', '和', '有点', '。'] \n",
      "\n",
      "[3, 4, 12, 13, 5, 6, 14, 1, 2, 15, 16, 7, 17, 18, 19, 1, 8, 20, 9, 3, 4, 10, 21, 1, 22, 11, 23, 24]\n",
      "-------------\n",
      "研究者探索了可以解决存储效率和单词之间关系问题的方法\n",
      "['研究者', '探索', '了', '可以', '解决', '存储', '效率', '和', '单词', '之间', '关系', '问题', '的', '方法'] \n",
      "\n",
      "[25, 26, 27, 28, 29, 30, 31, 11, 2, 32, 33, 34, 1, 35]\n",
      "-------------\n",
      "独热编码虽然简单\n",
      "['独热', '编码', '虽然', '简单'] \n",
      "\n",
      "[3, 4, 36, 8]\n",
      "-------------\n",
      "假如当前的单词表有10个不同的单词，并且每个单词都不一样\n",
      "['假如', '当前', '的', '单词表', '有', '10', '个', '不同', '的', '单词', '，', '并且', '每个', '单词', '都', '不', '一样'] \n",
      "\n",
      "[37, 5, 1, 6, 10, 38, 7, 39, 1, 2, 9, 40, 41, 2, 42, 43, 44]\n",
      "-------------\n",
      "[[2, 3, 5, 6, 7, 8, 9, 1, 10, 11, 12, 13, 14, 15, 16, 1, 17, 18, 4, 2, 3, 19, 20, 1, 21, 22, 23, 4], [22, 10, 1], [2, 3, 17], [7, 1, 8, 19, 13, 1, 10, 4, 10]]\n"
     ]
    }
   ],
   "source": [
    "num_words = len(word_index) + 1\n",
    "oov_token=None\n",
    "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "cntexts_to_sequences(corpus, num_words, oov_token, document_count, filters, word_index )\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['独热编码是对于当前单词表中的单词使用1个向量进行表达的简单方式，独热编码有自身的缺点和有点。', '研究者探索了可以解决存储效率和单词之间关系问题的方法', '独热编码虽然简单', '假如当前的单词表有10个不同的单词，并且每个单词都不一样']\n",
      "{1: '的', 2: '独热', 3: '编码', 4: ' ', 5: '是', 6: '对于', 7: '当前', 8: '单词表', 9: '中', 10: '单词', 11: '使用', 12: '1', 13: '个', 14: '向量', 15: '进行', 16: '表达', 17: '简单', 18: '方式', 19: '有', 20: '自身', 21: '缺点', 22: '和', 23: '有点'}\n"
     ]
    }
   ],
   "source": [
    "print(documents)\n",
    "print(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "研究者\n",
      "探索\n",
      "了\n",
      "可以\n",
      "解决\n",
      "存储\n",
      "效率\n",
      "和\n",
      "单词\n",
      "之间\n",
      "关系\n",
      "问题\n",
      "的\n",
      "方法\n"
     ]
    }
   ],
   "source": [
    "temp=jieba.tokenize(documents[1])\n",
    "for w in temp:\n",
    "    print(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '的', 2: '独热', 3: '编码', 4: ' ', 5: '是', 6: '对于', 7: '当前', 8: '单词表', 9: '中', 10: '单词', 11: '使用', 12: '1', 13: '个', 14: '向量', 15: '进行', 16: '表达', 17: '简单', 18: '方式', 19: '有', 20: '自身', 21: '缺点', 22: '和', 23: '有点'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "seq, word_index, index_word, word_docs, index_docs, word_counts = fit_on_texts(documents, filters='!\"#$%&()*+,-，。./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "print(index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "V = len(count)\n",
    "data, labels = skipgrams(sequence=data[:10000], vocabulary_size=1000, window_size=5, negative_samples=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先获取单词的索引表和反向索引表\n",
    "2. 其次将原有文字信息用索引值代替\n",
    "3. 再将中心词，上下文作为样本放入模型进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './nlp_data/news_data/finance_news.csv'\n",
    "dmsc=[]\n",
    "with open(file, encoding='UTF-8') as fo:\n",
    "    for i, line in enumerate(fo): \n",
    "        #print(line)\n",
    "        #line = line[1]\n",
    "        if i<=2000 & i>=500:\n",
    "            #print(line)\n",
    "            element = line.split(',')\n",
    "            dmsc.append(element[1])\n",
    "            \n",
    "dmsc_after, vocabulary = cn_list_seg(dmsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n = 1\n",
    "max_n = 1\n",
    "cn_count_model = CountVectorizer(ngram_range=(min_n, max_n), stop_words = stopword) # default unigram model\n",
    "cnX = cn_count_model.fit_transform(dmsc_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_df=pd.DataFrame.from_dict(cn_count_model.vocabulary_, orient='index', columns=['subscription'])\n",
    "vocabulary_df.reset_index(inplace=True)\n",
    "vocabulary_df.sort_values('subscription')\n",
    "vocabulary_df.columns=['values', 'subscription']\n",
    "dictionary = cn_count_model.vocabulary_\n",
    "reverse_dictionary = vocabulary_df.to_dict(orient='record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{69: '主持人',\n",
       " 736: '规定',\n",
       " 733: '要求',\n",
       " 709: '航空公司',\n",
       " 798: '运输',\n",
       " 559: '条件',\n",
       " 65: '中需',\n",
       " 533: '明确',\n",
       " 535: '是否',\n",
       " 488: '提供',\n",
       " 708: '航班',\n",
       " 404: '延误',\n",
       " 730: '补偿',\n",
       " 800: '还要',\n",
       " 248: '取消',\n",
       " 523: '旅客',\n",
       " 548: '服务',\n",
       " 171: '内容',\n",
       " 771: '购票',\n",
       " 624: '环节',\n",
       " 268: '告知',\n",
       " 597: '消费者',\n",
       " 243: '发生',\n",
       " 188: '分钟',\n",
       " 149: '信息',\n",
       " 553: '机上',\n",
       " 825: '通报',\n",
       " 207: '动态',\n",
       " 781: '超过',\n",
       " 371: '小时',\n",
       " 349: '安全',\n",
       " 348: '安保',\n",
       " 155: '允许',\n",
       " 438: '情况',\n",
       " 350: '安排',\n",
       " 867: '飞机',\n",
       " 672: '等待',\n",
       " 880: '高景',\n",
       " 6: '一号',\n",
       " 443: '成功',\n",
       " 237: '发射',\n",
       " 360: '实现',\n",
       " 445: '我国',\n",
       " 289: '国产',\n",
       " 827: '遥感',\n",
       " 223: '卫星',\n",
       " 796: '运营',\n",
       " 565: '模式',\n",
       " 277: '商业化',\n",
       " 663: '突破',\n",
       " 59: '中国',\n",
       " 473: '拥有',\n",
       " 704: '自主',\n",
       " 879: '高分辨率',\n",
       " 511: '数据',\n",
       " 61: '中国航天科技集团',\n",
       " 157: '党群',\n",
       " 383: '工作部',\n",
       " 831: '部长',\n",
       " 776: '贾可',\n",
       " 732: '表示',\n",
       " 762: '谈及',\n",
       " 550: '未来',\n",
       " 428: '徐文',\n",
       " 353: '完成',\n",
       " 591: '测试',\n",
       " 91: '交付',\n",
       " 283: '四维',\n",
       " 590: '测绘',\n",
       " 459: '技术',\n",
       " 547: '有限公司',\n",
       " 35: '下属',\n",
       " 213: '北京航天',\n",
       " 46: '世景',\n",
       " 811: '进行',\n",
       " 486: '推广',\n",
       " 291: '国土资源',\n",
       " 759: '调查',\n",
       " 622: '环境监测',\n",
       " 522: '方面',\n",
       " 120: '优质服务',\n",
       " 527: '日后',\n",
       " 387: '市场',\n",
       " 307: '城市',\n",
       " 407: '建设',\n",
       " 734: '规划',\n",
       " 447: '房地产',\n",
       " 462: '投资',\n",
       " 381: '工业',\n",
       " 749: '设施',\n",
       " 753: '评估',\n",
       " 842: '金融保险',\n",
       " 89: '互联网',\n",
       " 96: '产业',\n",
       " 324: '多个',\n",
       " 329: '大显身手',\n",
       " 725: '行业',\n",
       " 58: '个人消费',\n",
       " 630: '用户',\n",
       " 865: '领域',\n",
       " 509: '数字地球',\n",
       " 258: '合作伙伴',\n",
       " 164: '共同努力',\n",
       " 391: '帮助',\n",
       " 146: '保险公司',\n",
       " 606: '灾害',\n",
       " 431: '快速',\n",
       " 174: '准确',\n",
       " 123: '估算',\n",
       " 479: '损失',\n",
       " 615: '特朗普',\n",
       " 420: '当选',\n",
       " 699: '美国',\n",
       " 435: '总统',\n",
       " 141: '保护主义',\n",
       " 225: '压力',\n",
       " 33: '下会',\n",
       " 180: '出现',\n",
       " 698: '美元',\n",
       " 285: '回流',\n",
       " 783: '趋势',\n",
       " 826: '造成',\n",
       " 299: '国际经贸',\n",
       " 130: '体系',\n",
       " 493: '支付',\n",
       " 599: '清算',\n",
       " 650: '短缺',\n",
       " 617: '状况',\n",
       " 239: '发展中国家',\n",
       " 38: '不利',\n",
       " 571: '此时',\n",
       " 102: '人民币',\n",
       " 806: '进一步',\n",
       " 298: '国际化',\n",
       " 554: '机会',\n",
       " 311: '填补',\n",
       " 803: '这方面',\n",
       " 856: '需求',\n",
       " 117: '企业',\n",
       " 64: '中长期',\n",
       " 150: '信贷',\n",
       " 327: '大增',\n",
       " 422: '形成',\n",
       " 368: '对比',\n",
       " 375: '居民',\n",
       " 108: '仍处',\n",
       " 878: '高位',\n",
       " 226: '去年',\n",
       " 222: '单月',\n",
       " 315: '增量',\n",
       " 851: '降至',\n",
       " 104: '亿元',\n",
       " 175: '减少',\n",
       " 127: '住户',\n",
       " 832: '部门',\n",
       " 848: '长期贷款',\n",
       " 312: '增加',\n",
       " 22: '万亿元',\n",
       " 516: '新增',\n",
       " 579: '比重',\n",
       " 580: '民生银行',\n",
       " 870: '首席',\n",
       " 652: '研究员',\n",
       " 601: '温彬称',\n",
       " 95: '交易量',\n",
       " 37: '下降',\n",
       " 423: '影响',\n",
       " 128: '住房',\n",
       " 477: '按揭',\n",
       " 773: '贷款',\n",
       " 564: '楼市',\n",
       " 758: '调控',\n",
       " 194: '到位',\n",
       " 863: '预计',\n",
       " 578: '比较',\n",
       " 544: '有所',\n",
       " 876: '骗子',\n",
       " 172: '冒充',\n",
       " 787: '车站',\n",
       " 382: '工作人员',\n",
       " 560: '查票',\n",
       " 874: '验票',\n",
       " 563: '检查',\n",
       " 785: '身份证',\n",
       " 875: '骗取',\n",
       " 757: '调换',\n",
       " 786: '车票',\n",
       " 805: '这种',\n",
       " 824: '通常',\n",
       " 849: '长途汽车',\n",
       " 364: '客运站',\n",
       " 838: '里面',\n",
       " 52: '东兴',\n",
       " 751: '证券',\n",
       " 288: '固定',\n",
       " 500: '收益',\n",
       " 186: '分析师',\n",
       " 829: '郑良海',\n",
       " 765: '货币政策',\n",
       " 660: '稳字',\n",
       " 589: '流动性',\n",
       " 795: '过松',\n",
       " 526: '无须',\n",
       " 468: '担忧',\n",
       " 507: '政策',\n",
       " 333: '太紧',\n",
       " 600: '温彬',\n",
       " 106: '今年',\n",
       " 640: '目标',\n",
       " 36: '下调',\n",
       " 60: '中国人民银行',\n",
       " 227: '参事',\n",
       " 638: '盛松成',\n",
       " 569: '此前',\n",
       " 400: '广义',\n",
       " 764: '货币',\n",
       " 132: '供应量',\n",
       " 314: '增速',\n",
       " 609: '热心',\n",
       " 103: '人离',\n",
       " 813: '远点',\n",
       " 424: '往往',\n",
       " 365: '家常',\n",
       " 337: '套出',\n",
       " 57: '个人信息',\n",
       " 247: '取得',\n",
       " 148: '信任',\n",
       " 729: '行骗',\n",
       " 637: '盗窃',\n",
       " 68: '主动',\n",
       " 727: '行李',\n",
       " 718: '获取',\n",
       " 124: '伺机',\n",
       " 728: '行窃',\n",
       " 680: '索尔',\n",
       " 862: '预期',\n",
       " 460: '投向',\n",
       " 562: '核心',\n",
       " 55: '两个',\n",
       " 200: '办法',\n",
       " 485: '推动',\n",
       " 334: '央企',\n",
       " 702: '聚焦',\n",
       " 67: '主业',\n",
       " 166: '关系',\n",
       " 293: '国家',\n",
       " 295: '国民经济',\n",
       " 271: '命脉',\n",
       " 841: '重要',\n",
       " 167: '关键',\n",
       " 840: '重大',\n",
       " 45: '专项',\n",
       " 115: '任务',\n",
       " 853: '集中',\n",
       " 197: '前瞻性',\n",
       " 446: '战略性',\n",
       " 97: '产业链',\n",
       " 881: '高端',\n",
       " 534: '春节',\n",
       " 505: '放假',\n",
       " 331: '天将',\n",
       " 739: '计入',\n",
       " 628: '理由',\n",
       " 818: '退货',\n",
       " 531: '时间',\n",
       " 406: '建议',\n",
       " 861: '顾客',\n",
       " 8: '一家',\n",
       " 632: '电商',\n",
       " 392: '平台',\n",
       " 31: '上开',\n",
       " 403: '店铺',\n",
       " 170: '养生',\n",
       " 272: '品牌',\n",
       " 362: '客服',\n",
       " 100: '人员',\n",
       " 269: '告诉',\n",
       " 747: '记者',\n",
       " 710: '节后',\n",
       " 430: '快递',\n",
       " 275: '售后服务',\n",
       " 437: '恢复正常',\n",
       " 520: '方便',\n",
       " 88: '于昌法',\n",
       " 690: '给出',\n",
       " 16: '一组',\n",
       " 504: '改革',\n",
       " 75: '之前',\n",
       " 574: '每天',\n",
       " 635: '登记',\n",
       " 512: '数是',\n",
       " 393: '平均',\n",
       " 25: '万家',\n",
       " 313: '增幅',\n",
       " 396: '年底',\n",
       " 158: '全国',\n",
       " 359: '实有',\n",
       " 27: '万户',\n",
       " 449: '所有',\n",
       " 388: '市场主体',\n",
       " 278: '商事',\n",
       " 195: '制度',\n",
       " 654: '确实',\n",
       " 837: '释放',\n",
       " 681: '红利',\n",
       " 603: '激发',\n",
       " 326: '大众',\n",
       " 189: '创业',\n",
       " 24: '万众',\n",
       " 190: '创新',\n",
       " 584: '活力',\n",
       " 418: '当前',\n",
       " 703: '能够',\n",
       " 683: '经济',\n",
       " 789: '较大',\n",
       " 873: '驱动',\n",
       " 131: '作用',\n",
       " 208: '动能',\n",
       " 70: '主要',\n",
       " 28: '三个',\n",
       " 12: '一是',\n",
       " 306: '城乡',\n",
       " 4: '一体化',\n",
       " 238: '发展',\n",
       " 85: '二是',\n",
       " 669: '第三产业',\n",
       " 614: '特别',\n",
       " 629: '生产性',\n",
       " 549: '服务业',\n",
       " 29: '三是',\n",
       " 810: '进步',\n",
       " 210: '劳动者',\n",
       " 678: '素质',\n",
       " 491: '提高',\n",
       " 390: '带动',\n",
       " 217: '升级',\n",
       " 639: '目前',\n",
       " 671: '第二个',\n",
       " 241: '发挥',\n",
       " 372: '就业',\n",
       " 316: '增长',\n",
       " 779: '起到',\n",
       " 668: '第三个',\n",
       " 567: '正在',\n",
       " 266: '启动',\n",
       " 205: '加速',\n",
       " 74: '之中',\n",
       " 847: '长期',\n",
       " 801: '这一',\n",
       " 788: '转型',\n",
       " 707: '至关重要',\n",
       " 373: '尽全力',\n",
       " 309: '培育',\n",
       " 476: '指望',\n",
       " 649: '短期内',\n",
       " 532: '明显',\n",
       " 469: '拉动',\n",
       " 427: '很难',\n",
       " 658: '科技',\n",
       " 508: '教育',\n",
       " 857: '需要',\n",
       " 1: '一个',\n",
       " 790: '较长',\n",
       " 659: '积累',\n",
       " 688: '结构',\n",
       " 112: '以新',\n",
       " 495: '支撑',\n",
       " 9: '一小部分',\n",
       " 330: '大部分',\n",
       " 122: '传统',\n",
       " 645: '相比',\n",
       " 667: '第一个',\n",
       " 602: '潜力',\n",
       " 385: '巨大',\n",
       " 90: '亟待',\n",
       " 121: '会议',\n",
       " 489: '提出',\n",
       " 270: '周天勇',\n",
       " 426: '很强',\n",
       " 573: '每个',\n",
       " 860: '项目',\n",
       " 109: '从业人员',\n",
       " 49: '业内',\n",
       " 44: '专家',\n",
       " 162: '公司',\n",
       " 595: '海外',\n",
       " 724: '融资',\n",
       " 621: '环境',\n",
       " 415: '弱化',\n",
       " 230: '参考报',\n",
       " 799: '近日',\n",
       " 242: '发现',\n",
       " 646: '相较',\n",
       " 845: '铁路',\n",
       " 677: '系统',\n",
       " 169: '具有',\n",
       " 691: '统一',\n",
       " 276: '售票',\n",
       " 581: '民航',\n",
       " 185: '分属',\n",
       " 539: '更多人',\n",
       " 819: '选择',\n",
       " 135: '依赖',\n",
       " 137: '便利',\n",
       " 358: '实惠',\n",
       " 670: '第三方',\n",
       " 770: '购买',\n",
       " 555: '机票',\n",
       " 2: '一些',\n",
       " 116: '任性',\n",
       " 34: '下套',\n",
       " 191: '创造',\n",
       " 305: '埋伏',\n",
       " 697: '网购',\n",
       " 338: '套路',\n",
       " 452: '打乱',\n",
       " 830: '部分',\n",
       " 182: '出行',\n",
       " 740: '计划',\n",
       " 465: '折射出',\n",
       " 515: '整治',\n",
       " 81: '乱象',\n",
       " 3: '一位',\n",
       " 79: '乘客',\n",
       " 741: '订单',\n",
       " 859: '页面',\n",
       " 647: '看到',\n",
       " 455: '扣款',\n",
       " 492: '携程',\n",
       " 458: '承诺',\n",
       " 181: '出票',\n",
       " 147: '保障',\n",
       " 317: '声称',\n",
       " 145: '保证',\n",
       " 496: '收到',\n",
       " 525: '无法',\n",
       " 648: '短信',\n",
       " 866: '颇具',\n",
       " 748: '讽刺',\n",
       " 441: '意味',\n",
       " 484: '推出',\n",
       " 662: '突发',\n",
       " 401: '应对',\n",
       " 252: '口碑',\n",
       " 696: '网站',\n",
       " 71: '举例',\n",
       " 524: '旅行网',\n",
       " 114: '价格',\n",
       " 39: '不变',\n",
       " 84: '事实上',\n",
       " 844: '针对',\n",
       " 461: '投诉',\n",
       " 378: '屡见不鲜',\n",
       " 644: '相关',\n",
       " 514: '整改措施',\n",
       " 528: '早已有之',\n",
       " 627: '现状',\n",
       " 78: '乐观',\n",
       " 50: '业内人士',\n",
       " 202: '加强',\n",
       " 636: '监管',\n",
       " 136: '侵权行为',\n",
       " 201: '加大',\n",
       " 319: '处罚',\n",
       " 198: '力度',\n",
       " 692: '维护',\n",
       " 556: '权益',\n",
       " 807: '进入',\n",
       " 593: '浏阳市',\n",
       " 216: '区里',\n",
       " 274: '响起',\n",
       " 19: '一阵',\n",
       " 613: '爆竹声',\n",
       " 308: '城西',\n",
       " 623: '环岛',\n",
       " 828: '那座',\n",
       " 604: '火树银花',\n",
       " 855: '雕塑',\n",
       " 14: '一直',\n",
       " 142: '保持',\n",
       " 694: '绽放',\n",
       " 332: '天际',\n",
       " 343: '姿态',\n",
       " 357: '实体',\n",
       " 196: '前景',\n",
       " 156: '光明',\n",
       " 701: '老徐',\n",
       " 48: '世纪',\n",
       " 394: '年代',\n",
       " 713: '花炮',\n",
       " 726: '行当',\n",
       " 538: '普通',\n",
       " 347: '学徒',\n",
       " 153: '做起',\n",
       " 746: '记得',\n",
       " 439: '情景',\n",
       " 18: '一辆辆',\n",
       " 766: '货车',\n",
       " 642: '直接',\n",
       " 557: '村里',\n",
       " 470: '拉走',\n",
       " 379: '山货',\n",
       " 224: '厂主',\n",
       " 503: '改变',\n",
       " 594: '浙江',\n",
       " 98: '产品',\n",
       " 846: '销路',\n",
       " 301: '地区',\n",
       " 211: '包括',\n",
       " 419: '当地',\n",
       " 86: '二线',\n",
       " 300: '在内',\n",
       " 245: '发达',\n",
       " 42: '不断',\n",
       " 720: '萎缩',\n",
       " 254: '只好',\n",
       " 760: '调转',\n",
       " 521: '方向',\n",
       " 814: '远销',\n",
       " 282: '四川',\n",
       " 772: '贵州',\n",
       " 152: '偏远地区',\n",
       " 178: '几次',\n",
       " 340: '奥运会',\n",
       " 409: '开幕式',\n",
       " 676: '精彩',\n",
       " 731: '表现',\n",
       " 592: '浏阳',\n",
       " 608: '烟花',\n",
       " 297: '国际',\n",
       " 41: '不小',\n",
       " 263: '名头',\n",
       " 292: '国外',\n",
       " 607: '烟火',\n",
       " 612: '燃放',\n",
       " 750: '设有',\n",
       " 199: '办事处',\n",
       " 369: '寻找',\n",
       " 260: '合适',\n",
       " 273: '品种',\n",
       " 836: '采购',\n",
       " 570: '此基础',\n",
       " 616: '特雷莎',\n",
       " 653: '确定',\n",
       " 761: '谈判',\n",
       " 871: '首要',\n",
       " 165: '关注',\n",
       " 377: '展现',\n",
       " 566: '欧盟',\n",
       " 416: '强硬态度',\n",
       " 62: '中将',\n",
       " 839: '重塑',\n",
       " 715: '英国政府',\n",
       " 745: '议会',\n",
       " 551: '本土',\n",
       " 655: '社会',\n",
       " 83: '事务',\n",
       " 664: '立法',\n",
       " 483: '控制权',\n",
       " 351: '完全',\n",
       " 221: '单一',\n",
       " 389: '市场机制',\n",
       " 817: '退出',\n",
       " 253: '另起炉灶',\n",
       " 714: '英国',\n",
       " 76: '之间',\n",
       " 706: '自由',\n",
       " 775: '贸易协定',\n",
       " 370: '寻求',\n",
       " 232: '双方',\n",
       " 774: '贸易',\n",
       " 138: '便利化',\n",
       " 572: '此语',\n",
       " 5: '一出',\n",
       " 325: '多位',\n",
       " 110: '代表',\n",
       " 682: '纷纷',\n",
       " 411: '开腔',\n",
       " 304: '垃圾',\n",
       " 187: '分类',\n",
       " 754: '话题',\n",
       " 376: '展开',\n",
       " 605: '火热',\n",
       " 744: '讨论',\n",
       " 767: '货运',\n",
       " 822: '逐季',\n",
       " 203: '加快',\n",
       " 721: '营业性',\n",
       " 768: '货运量',\n",
       " 105: '亿吨',\n",
       " 261: '同比',\n",
       " 281: '四个',\n",
       " 346: '季度',\n",
       " 183: '分别',\n",
       " 536: '显现',\n",
       " 797: '运行',\n",
       " 432: '态势',\n",
       " 99: '亮点',\n",
       " 0: 'ppp',\n",
       " 209: '助力',\n",
       " 366: '密集',\n",
       " 722: '落地',\n",
       " 10: '一带',\n",
       " 17: '一路',\n",
       " 290: '国内',\n",
       " 118: '优化',\n",
       " 133: '供给',\n",
       " 689: '结构性',\n",
       " 487: '推进',\n",
       " 367: '对外',\n",
       " 665: '竞争力',\n",
       " 490: '提升',\n",
       " 540: '更好',\n",
       " 687: '结合',\n",
       " 54: '东道国',\n",
       " 777: '资本',\n",
       " 791: '输出国',\n",
       " 233: '双赢',\n",
       " 440: '意义',\n",
       " 804: '这是',\n",
       " 161: '全球化',\n",
       " 206: '动力',\n",
       " 380: '岁末',\n",
       " 398: '年饭',\n",
       " 144: '保留项目',\n",
       " 625: '现在',\n",
       " 782: '越来越',\n",
       " 834: '酒店',\n",
       " 864: '预订',\n",
       " 868: '饭时',\n",
       " 583: '注意',\n",
       " 111: '以下',\n",
       " 214: '区别',\n",
       " 356: '定金',\n",
       " 742: '订金',\n",
       " 87: '二者',\n",
       " 552: '本质区别',\n",
       " 395: '年夜饭',\n",
       " 339: '套餐',\n",
       " 478: '挑选',\n",
       " 869: '饭菜',\n",
       " 712: '花哨',\n",
       " 719: '菜名',\n",
       " 816: '迷惑',\n",
       " 412: '弄清',\n",
       " 576: '每道菜',\n",
       " 264: '名称',\n",
       " 737: '规格',\n",
       " 168: '具体',\n",
       " 502: '收费',\n",
       " 705: '自带',\n",
       " 835: '酒水',\n",
       " 545: '有无',\n",
       " 542: '最低',\n",
       " 596: '消费',\n",
       " 410: '开瓶费',\n",
       " 212: '包间',\n",
       " 143: '保留',\n",
       " 656: '票据',\n",
       " 80: '书面',\n",
       " 220: '协议',\n",
       " 497: '收据',\n",
       " 244: '发票',\n",
       " 179: '凭证',\n",
       " 249: '受损',\n",
       " 693: '维权',\n",
       " 246: '发送',\n",
       " 20: '万人次',\n",
       " 262: '同比增加',\n",
       " 159: '全天',\n",
       " 235: '发售',\n",
       " 26: '万张',\n",
       " 450: '手机',\n",
       " 236: '发售量',\n",
       " 463: '投资业',\n",
       " 310: '基金',\n",
       " 218: '协会',\n",
       " 163: '公布',\n",
       " 657: '私募',\n",
       " 743: '认缴',\n",
       " 738: '规模',\n",
       " 792: '达到',\n",
       " 21: '万亿',\n",
       " 501: '收益率',\n",
       " 234: '反降',\n",
       " 433: '性别',\n",
       " 250: '受访者',\n",
       " 561: '校园',\n",
       " 151: '借贷',\n",
       " 481: '接受度',\n",
       " 877: '高于',\n",
       " 480: '接受',\n",
       " 633: '男生',\n",
       " 341: '女生',\n",
       " 854: '集成电路',\n",
       " 66: '为例',\n",
       " 47: '世界',\n",
       " 386: '差距',\n",
       " 425: '很大',\n",
       " 575: '每年',\n",
       " 808: '进口',\n",
       " 651: '石油',\n",
       " 399: '并购',\n",
       " 119: '优质',\n",
       " 453: '打入',\n",
       " 723: '融入',\n",
       " 43: '专业',\n",
       " 674: '管理',\n",
       " 686: '经验',\n",
       " 284: '回来',\n",
       " 513: '整体',\n",
       " 429: '得到',\n",
       " 56: '两会',\n",
       " 444: '成都',\n",
       " 255: '召开',\n",
       " 456: '扩大开放',\n",
       " 257: '合作',\n",
       " 413: '引发',\n",
       " 228: '参会',\n",
       " 101: '人大代表',\n",
       " 506: '政协委员',\n",
       " 287: '围绕',\n",
       " 352: '完善',\n",
       " 113: '价值链',\n",
       " 184: '分层',\n",
       " 354: '定向',\n",
       " 355: '定点',\n",
       " 675: '精准',\n",
       " 408: '开展',\n",
       " 472: '招商引资',\n",
       " 442: '成为',\n",
       " 611: '焦点',\n",
       " 619: '王强',\n",
       " 107: '介绍',\n",
       " 631: '电力',\n",
       " 129: '体制改革',\n",
       " 809: '进展',\n",
       " 695: '缝合',\n",
       " 769: '质量',\n",
       " 793: '达标',\n",
       " 405: '建立',\n",
       " 510: '数家',\n",
       " 384: '工厂',\n",
       " 618: '状况良好',\n",
       " 471: '拒绝',\n",
       " 821: '透露',\n",
       " 756: '详细情况',\n",
       " 421: '形势',\n",
       " 784: '跨境',\n",
       " 778: '资金',\n",
       " 588: '流动',\n",
       " 434: '总体',\n",
       " 303: '均衡',\n",
       " 499: '收敛',\n",
       " 620: '王春英',\n",
       " 417: '强调',\n",
       " 40: '不可否认',\n",
       " 13: '一段',\n",
       " 530: '时期',\n",
       " 160: '全球',\n",
       " 126: '低迷',\n",
       " 344: '存在',\n",
       " 176: '减速',\n",
       " 850: '问题',\n",
       " 763: '财政政策',\n",
       " 661: '空间',\n",
       " 546: '有限',\n",
       " 320: '复苏',\n",
       " 77: '乏力',\n",
       " 323: '外部环境',\n",
       " 700: '美联储',\n",
       " 204: '加息',\n",
       " 286: '因素',\n",
       " 529: '时不时',\n",
       " 457: '扰动',\n",
       " 843: '金融市场',\n",
       " 256: '各国',\n",
       " 475: '持续',\n",
       " 858: '面对',\n",
       " 363: '客观',\n",
       " 518: '新政府',\n",
       " 294: '国新办',\n",
       " 30: '上午',\n",
       " 73: '举行',\n",
       " 519: '新闻',\n",
       " 240: '发布会',\n",
       " 321: '外汇',\n",
       " 498: '收支',\n",
       " 673: '答记者问',\n",
       " 543: '最近',\n",
       " 684: '经济学家',\n",
       " 322: '外汇储备',\n",
       " 23: '万亿美元',\n",
       " 154: '储备',\n",
       " 251: '变化',\n",
       " 517: '新政',\n",
       " 215: '区域',\n",
       " 328: '大户型',\n",
       " 448: '房源',\n",
       " 466: '报价',\n",
       " 335: '央行',\n",
       " 32: '上海',\n",
       " 436: '总部',\n",
       " 467: '披露',\n",
       " 812: '进驻',\n",
       " 577: '比特',\n",
       " 93: '交易平台',\n",
       " 626: '现场',\n",
       " 192: '初步',\n",
       " 780: '超范围',\n",
       " 685: '经营',\n",
       " 815: '违规',\n",
       " 833: '配资',\n",
       " 51: '业务',\n",
       " 464: '投资者',\n",
       " 361: '实行',\n",
       " 345: '存管',\n",
       " 53: '东西',\n",
       " 872: '马云',\n",
       " 402: '应该',\n",
       " 537: '普惠',\n",
       " 794: '过去',\n",
       " 482: '控制',\n",
       " 177: '几位',\n",
       " 296: '国王',\n",
       " 494: '支持',\n",
       " 63: '中小企业',\n",
       " 643: '相信',\n",
       " 568: '正常',\n",
       " 716: '范围',\n",
       " 414: '张瑞东',\n",
       " 94: '交易所',\n",
       " 558: '杠杆',\n",
       " 541: '曾经',\n",
       " 11: '一度',\n",
       " 882: '高达',\n",
       " 802: '这会',\n",
       " 7: '一定',\n",
       " 582: '泡沫',\n",
       " 92: '交易',\n",
       " 587: '活跃度',\n",
       " 302: '场所',\n",
       " 193: '利率',\n",
       " 717: '获利',\n",
       " 451: '手续费',\n",
       " 139: '促进',\n",
       " 586: '活跃',\n",
       " 15: '一种',\n",
       " 823: '途径',\n",
       " 711: '节日',\n",
       " 280: '商家',\n",
       " 454: '打折',\n",
       " 140: '促销',\n",
       " 585: '活动',\n",
       " 374: '层出不穷',\n",
       " 820: '选购',\n",
       " 397: '年货',\n",
       " 125: '低价',\n",
       " 173: '冲昏',\n",
       " 336: '头脑',\n",
       " 641: '盲目',\n",
       " 229: '参加',\n",
       " 755: '详细',\n",
       " 82: '了解',\n",
       " 598: '清楚',\n",
       " 735: '规则',\n",
       " 634: '留意',\n",
       " 852: '限制',\n",
       " 279: '商品',\n",
       " 265: '后要',\n",
       " 679: '索取',\n",
       " 752: '证明',\n",
       " 342: '妥善',\n",
       " 219: '协商',\n",
       " 318: '处理',\n",
       " 231: '及时',\n",
       " 474: '拨打',\n",
       " 72: '举报',\n",
       " 610: '热线',\n",
       " 134: '依法',\n",
       " 259: '合法权益',\n",
       " 267: '吴哲',\n",
       " 666: '符信'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = vocabulary_df.set_index('subscription')\n",
    "reverse_dictionary = rdf.to_dict(orient='dict')\n",
    "reverse_dictionary['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'主持人': 69,\n",
       " '规定': 736,\n",
       " '要求': 733,\n",
       " '航空公司': 709,\n",
       " '运输': 798,\n",
       " '条件': 559,\n",
       " '中需': 65,\n",
       " '明确': 533,\n",
       " '是否': 535,\n",
       " '提供': 488,\n",
       " '航班': 708,\n",
       " '延误': 404,\n",
       " '补偿': 730,\n",
       " '还要': 800,\n",
       " '取消': 248,\n",
       " '旅客': 523,\n",
       " '服务': 548,\n",
       " '内容': 171,\n",
       " '购票': 771,\n",
       " '环节': 624,\n",
       " '告知': 268,\n",
       " '消费者': 597,\n",
       " '发生': 243,\n",
       " '分钟': 188,\n",
       " '信息': 149,\n",
       " '机上': 553,\n",
       " '通报': 825,\n",
       " '动态': 207,\n",
       " '超过': 781,\n",
       " '小时': 371,\n",
       " '安全': 349,\n",
       " '安保': 348,\n",
       " '允许': 155,\n",
       " '情况': 438,\n",
       " '安排': 350,\n",
       " '飞机': 867,\n",
       " '等待': 672,\n",
       " '高景': 880,\n",
       " '一号': 6,\n",
       " '成功': 443,\n",
       " '发射': 237,\n",
       " '实现': 360,\n",
       " '我国': 445,\n",
       " '国产': 289,\n",
       " '遥感': 827,\n",
       " '卫星': 223,\n",
       " '运营': 796,\n",
       " '模式': 565,\n",
       " '商业化': 277,\n",
       " '突破': 663,\n",
       " '中国': 59,\n",
       " '拥有': 473,\n",
       " '自主': 704,\n",
       " '高分辨率': 879,\n",
       " '数据': 511,\n",
       " '中国航天科技集团': 61,\n",
       " '党群': 157,\n",
       " '工作部': 383,\n",
       " '部长': 831,\n",
       " '贾可': 776,\n",
       " '表示': 732,\n",
       " '谈及': 762,\n",
       " '未来': 550,\n",
       " '徐文': 428,\n",
       " '完成': 353,\n",
       " '测试': 591,\n",
       " '交付': 91,\n",
       " '四维': 283,\n",
       " '测绘': 590,\n",
       " '技术': 459,\n",
       " '有限公司': 547,\n",
       " '下属': 35,\n",
       " '北京航天': 213,\n",
       " '世景': 46,\n",
       " '进行': 811,\n",
       " '推广': 486,\n",
       " '国土资源': 291,\n",
       " '调查': 759,\n",
       " '环境监测': 622,\n",
       " '方面': 522,\n",
       " '优质服务': 120,\n",
       " '日后': 527,\n",
       " '市场': 387,\n",
       " '城市': 307,\n",
       " '建设': 407,\n",
       " '规划': 734,\n",
       " '房地产': 447,\n",
       " '投资': 462,\n",
       " '工业': 381,\n",
       " '设施': 749,\n",
       " '评估': 753,\n",
       " '金融保险': 842,\n",
       " '互联网': 89,\n",
       " '产业': 96,\n",
       " '多个': 324,\n",
       " '大显身手': 329,\n",
       " '行业': 725,\n",
       " '个人消费': 58,\n",
       " '用户': 630,\n",
       " '领域': 865,\n",
       " '数字地球': 509,\n",
       " '合作伙伴': 258,\n",
       " '共同努力': 164,\n",
       " '帮助': 391,\n",
       " '保险公司': 146,\n",
       " '灾害': 606,\n",
       " '快速': 431,\n",
       " '准确': 174,\n",
       " '估算': 123,\n",
       " '损失': 479,\n",
       " '特朗普': 615,\n",
       " '当选': 420,\n",
       " '美国': 699,\n",
       " '总统': 435,\n",
       " '保护主义': 141,\n",
       " '压力': 225,\n",
       " '下会': 33,\n",
       " '出现': 180,\n",
       " '美元': 698,\n",
       " '回流': 285,\n",
       " '趋势': 783,\n",
       " '造成': 826,\n",
       " '国际经贸': 299,\n",
       " '体系': 130,\n",
       " '支付': 493,\n",
       " '清算': 599,\n",
       " '短缺': 650,\n",
       " '状况': 617,\n",
       " '发展中国家': 239,\n",
       " '不利': 38,\n",
       " '此时': 571,\n",
       " '人民币': 102,\n",
       " '进一步': 806,\n",
       " '国际化': 298,\n",
       " '机会': 554,\n",
       " '填补': 311,\n",
       " '这方面': 803,\n",
       " '需求': 856,\n",
       " '企业': 117,\n",
       " '中长期': 64,\n",
       " '信贷': 150,\n",
       " '大增': 327,\n",
       " '形成': 422,\n",
       " '对比': 368,\n",
       " '居民': 375,\n",
       " '仍处': 108,\n",
       " '高位': 878,\n",
       " '去年': 226,\n",
       " '单月': 222,\n",
       " '增量': 315,\n",
       " '降至': 851,\n",
       " '亿元': 104,\n",
       " '减少': 175,\n",
       " '住户': 127,\n",
       " '部门': 832,\n",
       " '长期贷款': 848,\n",
       " '增加': 312,\n",
       " '万亿元': 22,\n",
       " '新增': 516,\n",
       " '比重': 579,\n",
       " '民生银行': 580,\n",
       " '首席': 870,\n",
       " '研究员': 652,\n",
       " '温彬称': 601,\n",
       " '交易量': 95,\n",
       " '下降': 37,\n",
       " '影响': 423,\n",
       " '住房': 128,\n",
       " '按揭': 477,\n",
       " '贷款': 773,\n",
       " '楼市': 564,\n",
       " '调控': 758,\n",
       " '到位': 194,\n",
       " '预计': 863,\n",
       " '比较': 578,\n",
       " '有所': 544,\n",
       " '骗子': 876,\n",
       " '冒充': 172,\n",
       " '车站': 787,\n",
       " '工作人员': 382,\n",
       " '查票': 560,\n",
       " '验票': 874,\n",
       " '检查': 563,\n",
       " '身份证': 785,\n",
       " '骗取': 875,\n",
       " '调换': 757,\n",
       " '车票': 786,\n",
       " '这种': 805,\n",
       " '通常': 824,\n",
       " '长途汽车': 849,\n",
       " '客运站': 364,\n",
       " '里面': 838,\n",
       " '东兴': 52,\n",
       " '证券': 751,\n",
       " '固定': 288,\n",
       " '收益': 500,\n",
       " '分析师': 186,\n",
       " '郑良海': 829,\n",
       " '货币政策': 765,\n",
       " '稳字': 660,\n",
       " '流动性': 589,\n",
       " '过松': 795,\n",
       " '无须': 526,\n",
       " '担忧': 468,\n",
       " '政策': 507,\n",
       " '太紧': 333,\n",
       " '温彬': 600,\n",
       " '今年': 106,\n",
       " '目标': 640,\n",
       " '下调': 36,\n",
       " '中国人民银行': 60,\n",
       " '参事': 227,\n",
       " '盛松成': 638,\n",
       " '此前': 569,\n",
       " '广义': 400,\n",
       " '货币': 764,\n",
       " '供应量': 132,\n",
       " '增速': 314,\n",
       " '热心': 609,\n",
       " '人离': 103,\n",
       " '远点': 813,\n",
       " '往往': 424,\n",
       " '家常': 365,\n",
       " '套出': 337,\n",
       " '个人信息': 57,\n",
       " '取得': 247,\n",
       " '信任': 148,\n",
       " '行骗': 729,\n",
       " '盗窃': 637,\n",
       " '主动': 68,\n",
       " '行李': 727,\n",
       " '获取': 718,\n",
       " '伺机': 124,\n",
       " '行窃': 728,\n",
       " '索尔': 680,\n",
       " '预期': 862,\n",
       " '投向': 460,\n",
       " '核心': 562,\n",
       " '两个': 55,\n",
       " '办法': 200,\n",
       " '推动': 485,\n",
       " '央企': 334,\n",
       " '聚焦': 702,\n",
       " '主业': 67,\n",
       " '关系': 166,\n",
       " '国家': 293,\n",
       " '国民经济': 295,\n",
       " '命脉': 271,\n",
       " '重要': 841,\n",
       " '关键': 167,\n",
       " '重大': 840,\n",
       " '专项': 45,\n",
       " '任务': 115,\n",
       " '集中': 853,\n",
       " '前瞻性': 197,\n",
       " '战略性': 446,\n",
       " '产业链': 97,\n",
       " '高端': 881,\n",
       " '春节': 534,\n",
       " '放假': 505,\n",
       " '天将': 331,\n",
       " '计入': 739,\n",
       " '理由': 628,\n",
       " '退货': 818,\n",
       " '时间': 531,\n",
       " '建议': 406,\n",
       " '顾客': 861,\n",
       " '一家': 8,\n",
       " '电商': 632,\n",
       " '平台': 392,\n",
       " '上开': 31,\n",
       " '店铺': 403,\n",
       " '养生': 170,\n",
       " '品牌': 272,\n",
       " '客服': 362,\n",
       " '人员': 100,\n",
       " '告诉': 269,\n",
       " '记者': 747,\n",
       " '节后': 710,\n",
       " '快递': 430,\n",
       " '售后服务': 275,\n",
       " '恢复正常': 437,\n",
       " '方便': 520,\n",
       " '于昌法': 88,\n",
       " '给出': 690,\n",
       " '一组': 16,\n",
       " '改革': 504,\n",
       " '之前': 75,\n",
       " '每天': 574,\n",
       " '登记': 635,\n",
       " '数是': 512,\n",
       " '平均': 393,\n",
       " '万家': 25,\n",
       " '增幅': 313,\n",
       " '年底': 396,\n",
       " '全国': 158,\n",
       " '实有': 359,\n",
       " '万户': 27,\n",
       " '所有': 449,\n",
       " '市场主体': 388,\n",
       " '商事': 278,\n",
       " '制度': 195,\n",
       " '确实': 654,\n",
       " '释放': 837,\n",
       " '红利': 681,\n",
       " '激发': 603,\n",
       " '大众': 326,\n",
       " '创业': 189,\n",
       " '万众': 24,\n",
       " '创新': 190,\n",
       " '活力': 584,\n",
       " '当前': 418,\n",
       " '能够': 703,\n",
       " '经济': 683,\n",
       " '较大': 789,\n",
       " '驱动': 873,\n",
       " '作用': 131,\n",
       " '动能': 208,\n",
       " '主要': 70,\n",
       " '三个': 28,\n",
       " '一是': 12,\n",
       " '城乡': 306,\n",
       " '一体化': 4,\n",
       " '发展': 238,\n",
       " '二是': 85,\n",
       " '第三产业': 669,\n",
       " '特别': 614,\n",
       " '生产性': 629,\n",
       " '服务业': 549,\n",
       " '三是': 29,\n",
       " '进步': 810,\n",
       " '劳动者': 210,\n",
       " '素质': 678,\n",
       " '提高': 491,\n",
       " '带动': 390,\n",
       " '升级': 217,\n",
       " '目前': 639,\n",
       " '第二个': 671,\n",
       " '发挥': 241,\n",
       " '就业': 372,\n",
       " '增长': 316,\n",
       " '起到': 779,\n",
       " '第三个': 668,\n",
       " '正在': 567,\n",
       " '启动': 266,\n",
       " '加速': 205,\n",
       " '之中': 74,\n",
       " '长期': 847,\n",
       " '这一': 801,\n",
       " '转型': 788,\n",
       " '至关重要': 707,\n",
       " '尽全力': 373,\n",
       " '培育': 309,\n",
       " '指望': 476,\n",
       " '短期内': 649,\n",
       " '明显': 532,\n",
       " '拉动': 469,\n",
       " '很难': 427,\n",
       " '科技': 658,\n",
       " '教育': 508,\n",
       " '需要': 857,\n",
       " '一个': 1,\n",
       " '较长': 790,\n",
       " '积累': 659,\n",
       " '结构': 688,\n",
       " '以新': 112,\n",
       " '支撑': 495,\n",
       " '一小部分': 9,\n",
       " '大部分': 330,\n",
       " '传统': 122,\n",
       " '相比': 645,\n",
       " '第一个': 667,\n",
       " '潜力': 602,\n",
       " '巨大': 385,\n",
       " '亟待': 90,\n",
       " '会议': 121,\n",
       " '提出': 489,\n",
       " '周天勇': 270,\n",
       " '很强': 426,\n",
       " '每个': 573,\n",
       " '项目': 860,\n",
       " '从业人员': 109,\n",
       " '业内': 49,\n",
       " '专家': 44,\n",
       " '公司': 162,\n",
       " '海外': 595,\n",
       " '融资': 724,\n",
       " '环境': 621,\n",
       " '弱化': 415,\n",
       " '参考报': 230,\n",
       " '近日': 799,\n",
       " '发现': 242,\n",
       " '相较': 646,\n",
       " '铁路': 845,\n",
       " '系统': 677,\n",
       " '具有': 169,\n",
       " '统一': 691,\n",
       " '售票': 276,\n",
       " '民航': 581,\n",
       " '分属': 185,\n",
       " '更多人': 539,\n",
       " '选择': 819,\n",
       " '依赖': 135,\n",
       " '便利': 137,\n",
       " '实惠': 358,\n",
       " '第三方': 670,\n",
       " '购买': 770,\n",
       " '机票': 555,\n",
       " '一些': 2,\n",
       " '任性': 116,\n",
       " '下套': 34,\n",
       " '创造': 191,\n",
       " '埋伏': 305,\n",
       " '网购': 697,\n",
       " '套路': 338,\n",
       " '打乱': 452,\n",
       " '部分': 830,\n",
       " '出行': 182,\n",
       " '计划': 740,\n",
       " '折射出': 465,\n",
       " '整治': 515,\n",
       " '乱象': 81,\n",
       " '一位': 3,\n",
       " '乘客': 79,\n",
       " '订单': 741,\n",
       " '页面': 859,\n",
       " '看到': 647,\n",
       " '扣款': 455,\n",
       " '携程': 492,\n",
       " '承诺': 458,\n",
       " '出票': 181,\n",
       " '保障': 147,\n",
       " '声称': 317,\n",
       " '保证': 145,\n",
       " '收到': 496,\n",
       " '无法': 525,\n",
       " '短信': 648,\n",
       " '颇具': 866,\n",
       " '讽刺': 748,\n",
       " '意味': 441,\n",
       " '推出': 484,\n",
       " '突发': 662,\n",
       " '应对': 401,\n",
       " '口碑': 252,\n",
       " '网站': 696,\n",
       " '举例': 71,\n",
       " '旅行网': 524,\n",
       " '价格': 114,\n",
       " '不变': 39,\n",
       " '事实上': 84,\n",
       " '针对': 844,\n",
       " '投诉': 461,\n",
       " '屡见不鲜': 378,\n",
       " '相关': 644,\n",
       " '整改措施': 514,\n",
       " '早已有之': 528,\n",
       " '现状': 627,\n",
       " '乐观': 78,\n",
       " '业内人士': 50,\n",
       " '加强': 202,\n",
       " '监管': 636,\n",
       " '侵权行为': 136,\n",
       " '加大': 201,\n",
       " '处罚': 319,\n",
       " '力度': 198,\n",
       " '维护': 692,\n",
       " '权益': 556,\n",
       " '进入': 807,\n",
       " '浏阳市': 593,\n",
       " '区里': 216,\n",
       " '响起': 274,\n",
       " '一阵': 19,\n",
       " '爆竹声': 613,\n",
       " '城西': 308,\n",
       " '环岛': 623,\n",
       " '那座': 828,\n",
       " '火树银花': 604,\n",
       " '雕塑': 855,\n",
       " '一直': 14,\n",
       " '保持': 142,\n",
       " '绽放': 694,\n",
       " '天际': 332,\n",
       " '姿态': 343,\n",
       " '实体': 357,\n",
       " '前景': 196,\n",
       " '光明': 156,\n",
       " '老徐': 701,\n",
       " '世纪': 48,\n",
       " '年代': 394,\n",
       " '花炮': 713,\n",
       " '行当': 726,\n",
       " '普通': 538,\n",
       " '学徒': 347,\n",
       " '做起': 153,\n",
       " '记得': 746,\n",
       " '情景': 439,\n",
       " '一辆辆': 18,\n",
       " '货车': 766,\n",
       " '直接': 642,\n",
       " '村里': 557,\n",
       " '拉走': 470,\n",
       " '山货': 379,\n",
       " '厂主': 224,\n",
       " '改变': 503,\n",
       " '浙江': 594,\n",
       " '产品': 98,\n",
       " '销路': 846,\n",
       " '地区': 301,\n",
       " '包括': 211,\n",
       " '当地': 419,\n",
       " '二线': 86,\n",
       " '在内': 300,\n",
       " '发达': 245,\n",
       " '不断': 42,\n",
       " '萎缩': 720,\n",
       " '只好': 254,\n",
       " '调转': 760,\n",
       " '方向': 521,\n",
       " '远销': 814,\n",
       " '四川': 282,\n",
       " '贵州': 772,\n",
       " '偏远地区': 152,\n",
       " '几次': 178,\n",
       " '奥运会': 340,\n",
       " '开幕式': 409,\n",
       " '精彩': 676,\n",
       " '表现': 731,\n",
       " '浏阳': 592,\n",
       " '烟花': 608,\n",
       " '国际': 297,\n",
       " '不小': 41,\n",
       " '名头': 263,\n",
       " '国外': 292,\n",
       " '烟火': 607,\n",
       " '燃放': 612,\n",
       " '设有': 750,\n",
       " '办事处': 199,\n",
       " '寻找': 369,\n",
       " '合适': 260,\n",
       " '品种': 273,\n",
       " '采购': 836,\n",
       " '此基础': 570,\n",
       " '特雷莎': 616,\n",
       " '确定': 653,\n",
       " '谈判': 761,\n",
       " '首要': 871,\n",
       " '关注': 165,\n",
       " '展现': 377,\n",
       " '欧盟': 566,\n",
       " '强硬态度': 416,\n",
       " '中将': 62,\n",
       " '重塑': 839,\n",
       " '英国政府': 715,\n",
       " '议会': 745,\n",
       " '本土': 551,\n",
       " '社会': 655,\n",
       " '事务': 83,\n",
       " '立法': 664,\n",
       " '控制权': 483,\n",
       " '完全': 351,\n",
       " '单一': 221,\n",
       " '市场机制': 389,\n",
       " '退出': 817,\n",
       " '另起炉灶': 253,\n",
       " '英国': 714,\n",
       " '之间': 76,\n",
       " '自由': 706,\n",
       " '贸易协定': 775,\n",
       " '寻求': 370,\n",
       " '双方': 232,\n",
       " '贸易': 774,\n",
       " '便利化': 138,\n",
       " '此语': 572,\n",
       " '一出': 5,\n",
       " '多位': 325,\n",
       " '代表': 110,\n",
       " '纷纷': 682,\n",
       " '开腔': 411,\n",
       " '垃圾': 304,\n",
       " '分类': 187,\n",
       " '话题': 754,\n",
       " '展开': 376,\n",
       " '火热': 605,\n",
       " '讨论': 744,\n",
       " '货运': 767,\n",
       " '逐季': 822,\n",
       " '加快': 203,\n",
       " '营业性': 721,\n",
       " '货运量': 768,\n",
       " '亿吨': 105,\n",
       " '同比': 261,\n",
       " '四个': 281,\n",
       " '季度': 346,\n",
       " '分别': 183,\n",
       " '显现': 536,\n",
       " '运行': 797,\n",
       " '态势': 432,\n",
       " '亮点': 99,\n",
       " 'ppp': 0,\n",
       " '助力': 209,\n",
       " '密集': 366,\n",
       " '落地': 722,\n",
       " '一带': 10,\n",
       " '一路': 17,\n",
       " '国内': 290,\n",
       " '优化': 118,\n",
       " '供给': 133,\n",
       " '结构性': 689,\n",
       " '推进': 487,\n",
       " '对外': 367,\n",
       " '竞争力': 665,\n",
       " '提升': 490,\n",
       " '更好': 540,\n",
       " '结合': 687,\n",
       " '东道国': 54,\n",
       " '资本': 777,\n",
       " '输出国': 791,\n",
       " '双赢': 233,\n",
       " '意义': 440,\n",
       " '这是': 804,\n",
       " '全球化': 161,\n",
       " '动力': 206,\n",
       " '岁末': 380,\n",
       " '年饭': 398,\n",
       " '保留项目': 144,\n",
       " '现在': 625,\n",
       " '越来越': 782,\n",
       " '酒店': 834,\n",
       " '预订': 864,\n",
       " '饭时': 868,\n",
       " '注意': 583,\n",
       " '以下': 111,\n",
       " '区别': 214,\n",
       " '定金': 356,\n",
       " '订金': 742,\n",
       " '二者': 87,\n",
       " '本质区别': 552,\n",
       " '年夜饭': 395,\n",
       " '套餐': 339,\n",
       " '挑选': 478,\n",
       " '饭菜': 869,\n",
       " '花哨': 712,\n",
       " '菜名': 719,\n",
       " '迷惑': 816,\n",
       " '弄清': 412,\n",
       " '每道菜': 576,\n",
       " '名称': 264,\n",
       " '规格': 737,\n",
       " '具体': 168,\n",
       " '收费': 502,\n",
       " '自带': 705,\n",
       " '酒水': 835,\n",
       " '有无': 545,\n",
       " '最低': 542,\n",
       " '消费': 596,\n",
       " '开瓶费': 410,\n",
       " '包间': 212,\n",
       " '保留': 143,\n",
       " '票据': 656,\n",
       " '书面': 80,\n",
       " '协议': 220,\n",
       " '收据': 497,\n",
       " '发票': 244,\n",
       " '凭证': 179,\n",
       " '受损': 249,\n",
       " '维权': 693,\n",
       " '发送': 246,\n",
       " '万人次': 20,\n",
       " '同比增加': 262,\n",
       " '全天': 159,\n",
       " '发售': 235,\n",
       " '万张': 26,\n",
       " '手机': 450,\n",
       " '发售量': 236,\n",
       " '投资业': 463,\n",
       " '基金': 310,\n",
       " '协会': 218,\n",
       " '公布': 163,\n",
       " '私募': 657,\n",
       " '认缴': 743,\n",
       " '规模': 738,\n",
       " '达到': 792,\n",
       " '万亿': 21,\n",
       " '收益率': 501,\n",
       " '反降': 234,\n",
       " '性别': 433,\n",
       " '受访者': 250,\n",
       " '校园': 561,\n",
       " '借贷': 151,\n",
       " '接受度': 481,\n",
       " '高于': 877,\n",
       " '接受': 480,\n",
       " '男生': 633,\n",
       " '女生': 341,\n",
       " '集成电路': 854,\n",
       " '为例': 66,\n",
       " '世界': 47,\n",
       " '差距': 386,\n",
       " '很大': 425,\n",
       " '每年': 575,\n",
       " '进口': 808,\n",
       " '石油': 651,\n",
       " '并购': 399,\n",
       " '优质': 119,\n",
       " '打入': 453,\n",
       " '融入': 723,\n",
       " '专业': 43,\n",
       " '管理': 674,\n",
       " '经验': 686,\n",
       " '回来': 284,\n",
       " '整体': 513,\n",
       " '得到': 429,\n",
       " '两会': 56,\n",
       " '成都': 444,\n",
       " '召开': 255,\n",
       " '扩大开放': 456,\n",
       " '合作': 257,\n",
       " '引发': 413,\n",
       " '参会': 228,\n",
       " '人大代表': 101,\n",
       " '政协委员': 506,\n",
       " '围绕': 287,\n",
       " '完善': 352,\n",
       " '价值链': 113,\n",
       " '分层': 184,\n",
       " '定向': 354,\n",
       " '定点': 355,\n",
       " '精准': 675,\n",
       " '开展': 408,\n",
       " '招商引资': 472,\n",
       " '成为': 442,\n",
       " '焦点': 611,\n",
       " '王强': 619,\n",
       " '介绍': 107,\n",
       " '电力': 631,\n",
       " '体制改革': 129,\n",
       " '进展': 809,\n",
       " '缝合': 695,\n",
       " '质量': 769,\n",
       " '达标': 793,\n",
       " '建立': 405,\n",
       " '数家': 510,\n",
       " '工厂': 384,\n",
       " '状况良好': 618,\n",
       " '拒绝': 471,\n",
       " '透露': 821,\n",
       " '详细情况': 756,\n",
       " '形势': 421,\n",
       " '跨境': 784,\n",
       " '资金': 778,\n",
       " '流动': 588,\n",
       " '总体': 434,\n",
       " '均衡': 303,\n",
       " '收敛': 499,\n",
       " '王春英': 620,\n",
       " '强调': 417,\n",
       " '不可否认': 40,\n",
       " '一段': 13,\n",
       " '时期': 530,\n",
       " '全球': 160,\n",
       " '低迷': 126,\n",
       " '存在': 344,\n",
       " '减速': 176,\n",
       " '问题': 850,\n",
       " '财政政策': 763,\n",
       " '空间': 661,\n",
       " '有限': 546,\n",
       " '复苏': 320,\n",
       " '乏力': 77,\n",
       " '外部环境': 323,\n",
       " '美联储': 700,\n",
       " '加息': 204,\n",
       " '因素': 286,\n",
       " '时不时': 529,\n",
       " '扰动': 457,\n",
       " '金融市场': 843,\n",
       " '各国': 256,\n",
       " '持续': 475,\n",
       " '面对': 858,\n",
       " '客观': 363,\n",
       " '新政府': 518,\n",
       " '国新办': 294,\n",
       " '上午': 30,\n",
       " '举行': 73,\n",
       " '新闻': 519,\n",
       " '发布会': 240,\n",
       " '外汇': 321,\n",
       " '收支': 498,\n",
       " '答记者问': 673,\n",
       " '最近': 543,\n",
       " '经济学家': 684,\n",
       " '外汇储备': 322,\n",
       " '万亿美元': 23,\n",
       " '储备': 154,\n",
       " '变化': 251,\n",
       " '新政': 517,\n",
       " '区域': 215,\n",
       " '大户型': 328,\n",
       " '房源': 448,\n",
       " '报价': 466,\n",
       " '央行': 335,\n",
       " '上海': 32,\n",
       " '总部': 436,\n",
       " '披露': 467,\n",
       " '进驻': 812,\n",
       " '比特': 577,\n",
       " '交易平台': 93,\n",
       " '现场': 626,\n",
       " '初步': 192,\n",
       " '超范围': 780,\n",
       " '经营': 685,\n",
       " '违规': 815,\n",
       " '配资': 833,\n",
       " '业务': 51,\n",
       " '投资者': 464,\n",
       " '实行': 361,\n",
       " '存管': 345,\n",
       " '东西': 53,\n",
       " '马云': 872,\n",
       " '应该': 402,\n",
       " '普惠': 537,\n",
       " '过去': 794,\n",
       " '控制': 482,\n",
       " '几位': 177,\n",
       " '国王': 296,\n",
       " '支持': 494,\n",
       " '中小企业': 63,\n",
       " '相信': 643,\n",
       " '正常': 568,\n",
       " '范围': 716,\n",
       " '张瑞东': 414,\n",
       " '交易所': 94,\n",
       " '杠杆': 558,\n",
       " '曾经': 541,\n",
       " '一度': 11,\n",
       " '高达': 882,\n",
       " '这会': 802,\n",
       " '一定': 7,\n",
       " '泡沫': 582,\n",
       " '交易': 92,\n",
       " '活跃度': 587,\n",
       " '场所': 302,\n",
       " '利率': 193,\n",
       " '获利': 717,\n",
       " '手续费': 451,\n",
       " '促进': 139,\n",
       " '活跃': 586,\n",
       " '一种': 15,\n",
       " '途径': 823,\n",
       " '节日': 711,\n",
       " '商家': 280,\n",
       " '打折': 454,\n",
       " '促销': 140,\n",
       " '活动': 585,\n",
       " '层出不穷': 374,\n",
       " '选购': 820,\n",
       " '年货': 397,\n",
       " '低价': 125,\n",
       " '冲昏': 173,\n",
       " '头脑': 336,\n",
       " '盲目': 641,\n",
       " '参加': 229,\n",
       " '详细': 755,\n",
       " '了解': 82,\n",
       " '清楚': 598,\n",
       " '规则': 735,\n",
       " '留意': 634,\n",
       " '限制': 852,\n",
       " '商品': 279,\n",
       " '后要': 265,\n",
       " '索取': 679,\n",
       " '证明': 752,\n",
       " '妥善': 342,\n",
       " '协商': 219,\n",
       " '处理': 318,\n",
       " '及时': 231,\n",
       " '拨打': 474,\n",
       " '举报': 72,\n",
       " '热线': 610,\n",
       " '依法': 134,\n",
       " '合法权益': 259,\n",
       " '吴哲': 267,\n",
       " '符信': 666}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
